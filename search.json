[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "온라인에 책을 만들고 싶다는 생각에 배운 것을 정리하는 사이트입니다. 링크트리와 함께 작업한 내용을 정리하고 있습니다."
  },
  {
    "objectID": "about.html#프로젝트",
    "href": "about.html#프로젝트",
    "title": "About",
    "section": "프로젝트",
    "text": "프로젝트\n진행하고 있는 프로젝트를 소개합니다 관심있는 분들은 홈페이지 하단의 이메일로 연락 부탁드립니다.\n\n딥러닝 용어사전\n딥러닝용어사전은 다양한 딥러닝 문서를 한국어 번역하면서 중요한 딥러닝 용어를 한국어로 번역하는 오픈소스 용어사전입니다.\n\n\n공공데이터 시각화\n공공데이터 시각화사이트는 공공 데이터 중 관심있는 데이터를 시각화하는 사이트 입니다. 많은 사람들이 궁금해하는 데이터 또는 공공의 이익 위한 데이터를 고민하고 표현하는 연습을 하는 사이트 입니다.\n\n\nHuggingFace KREW\n허깅페이스 KREW팀은 허깅페이스에 대해 공부하는 사람들의 모임입니다. 초기 허깅페이스 문서번역을 통해서 오픈소스에 기여하는 활동을 시작으로 허깅페이스를 잘 활용하기 위한 여러 가지 스터디를 하고 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20230916.html",
    "href": "blog/posts/2023/20230916.html",
    "title": "Plotly Treemap 만들기",
    "section": "",
    "text": "Plotly로 Treemap을 만드는 방법을 정리합니다. 트래맵차트는 중첩된 직사각형을 이용하여 계층적 데이터를 효과적으로 시각화 할 수 있습니다. 데이터의 계층구조는 섹터와 상단의 경로표시줄리 이동할 수 있습니다. Plotly Express로 Treemap을 구성합니다.\n\nimport plotly.express as px\nimport pandas as pd\nvendors = [\"Apple\", \"Google\", \"Hoo Bank\", \"Foo Investment\", None, \"Nvidia\", \"Meta\", \"Goo Investment\", \"Moo Bank\", None]\nsectors = [\"Tech\", \"Tech\", \"Finance\", \"Finance\", \"Other\",\n           \"Tech\", \"Tech\", \"Finance\", \"Finance\", \"Other\"]\nregions = [\"North\", \"North\", \"North\", \"North\", \"North\",\n           \"South\", \"South\", \"South\", \"South\", \"South\"]\nsales = [100,100, 200, 100, 100, 200, 200, 100, 200, 100]\ndf = pd.DataFrame(\n    dict(vendors=vendors, sectors=sectors, regions=regions, sales=sales)\n)\ndf[\"location\"] = \"all\" # in order to have a single root node\ndf\n\n\n\n\n\n\n\n\nvendors\nsectors\nregions\nsales\nlocation\n\n\n\n\n0\nApple\nTech\nNorth\n100\nall\n\n\n1\nGoogle\nTech\nNorth\n100\nall\n\n\n2\nHoo Bank\nFinance\nNorth\n200\nall\n\n\n3\nFoo Investment\nFinance\nNorth\n100\nall\n\n\n4\nNone\nOther\nNorth\n100\nall\n\n\n5\nNvidia\nTech\nSouth\n200\nall\n\n\n6\nMeta\nTech\nSouth\n200\nall\n\n\n7\nGoo Investment\nFinance\nSouth\n100\nall\n\n\n8\nMoo Bank\nFinance\nSouth\n200\nall\n\n\n9\nNone\nOther\nSouth\n100\nall\n\n\n\n\n\n\n\n테스트를 위해 생성한 데이터프레임의 구조를 알아봅시다. 컬럼은 vendors, sectors, regions, sales, location을 갖고 있습니다. location 컬럼의 모든 값을 all로 변경하여 전체를 표시합니다. 생성하는 Treemap은 sales의 값을 계층정보를 나타내는 컬럼을 sales 정보를 효과적으로 시각화하는 것을 목적으로 합니다. 전체 sales데이터가 region별로 비교하고 각 region안에서 sector별로 비교합니다. sector내무에서는 vencor별 비교를 알 수 있으면 좋겠습니다.\n\nfig = px.treemap(df,\n    path=['location', 'regions', 'sectors',  'vendors'],\n    values='sales')\nfig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\nfig.show()\n\n\n                                                \n\n\n목적에 맞게 시각화한 결과를 확인합니다. 코드를 보면 계층의 순서에 맞춰 컬럼 정보를 path에 전달했습니다. 사각형의 크기를 결정하는 값은 values에 전달하고 sales컬럼 정보를 전달 했습니다. path로 전달된 정보를 확인하면 가장 먼저 location 컬럼이 전달되었습니다.\n가장 큰 사각형에 location 정보가 표시되고 값은 전체 sales정보를 갖습니다. 사각형의 크기는 sales의 값으로 표시됩니다. North의 Finance영역의 크기를 확인하면 각 vendor의 값을 비교할 수 있습니다. Hoo Bank가 ’Foo Investment’보다 sales가 큰 값을 갖는 것을 직관적으로 확인할 수 있습니다. 물론 각 영역을 선택해서 자세한 값을 확인할 수 있습니다.\n\n\n코드에 color 정보를 추가해서 값을 비교하겠습니다. 사각형의 색을 결정할 컬럼을 sales로 선택했습니다. 이제 각 사각형이 색을 갖습니다. 큰 값은 노란색 작은 값은 파란색으로 표시됩니다. South와 North의 sales값을 색으로 확인할 수 있습니다. 사각형의 위치가 멀어서 크기 확인이 어렵다면 색을 추가하여 값의 비교를 쉽게 할 수 있습니다.\n\nfig = px.treemap(df,\n    path=['location', 'regions', 'sectors',  'vendors'],\n    values='sales',\n    color='sales')\nfig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\nfig.show()\n\n\n                                                \n\n\n\n\n\n색상은 다양한 옵션을 지원합니다. color_continuous_scale 정보를 전달해서 다른 색상을 사용합니다. 단색의 경우 색의 채도로 값의 크기를 표현합니다. greens로 정보를 전달해서 초록색의 채도를 이용하여 값을 표현합니다.\n\nfig = px.treemap(df,\n    path=['location', 'regions', 'sectors',  'vendors'],\n    values='sales',\n    color='sales',\n    color_continuous_scale='greens')\nfig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\nfig.show()\n\n\n                                                \n\n\nTreemap은 데이터의 계층 구조와 상대적인 크기를 보여주는 데 사용하면 효과적입니다. 복잡한 계층구조를 시각적으로 표현하기 때문에 쉽게 이해할 수 있으며 비교가 편합니다. 데이터가 어떤 특징을 갖는 지 확인하고 계층적구조를 갖는 다면 Treemap을 이용해서 표현하는 것을 고민하면 좋을 것 같습니다.\n\n\n\n\nhttps://plotly.com/python/treemaps/"
  },
  {
    "objectID": "blog/posts/2023/20230916.html#treemap-색으로-값-비교하기",
    "href": "blog/posts/2023/20230916.html#treemap-색으로-값-비교하기",
    "title": "Plotly Treemap 만들기",
    "section": "",
    "text": "코드에 color 정보를 추가해서 값을 비교하겠습니다. 사각형의 색을 결정할 컬럼을 sales로 선택했습니다. 이제 각 사각형이 색을 갖습니다. 큰 값은 노란색 작은 값은 파란색으로 표시됩니다. South와 North의 sales값을 색으로 확인할 수 있습니다. 사각형의 위치가 멀어서 크기 확인이 어렵다면 색을 추가하여 값의 비교를 쉽게 할 수 있습니다.\n\nfig = px.treemap(df,\n    path=['location', 'regions', 'sectors',  'vendors'],\n    values='sales',\n    color='sales')\nfig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230916.html#treemap-색상-변경하기",
    "href": "blog/posts/2023/20230916.html#treemap-색상-변경하기",
    "title": "Plotly Treemap 만들기",
    "section": "",
    "text": "색상은 다양한 옵션을 지원합니다. color_continuous_scale 정보를 전달해서 다른 색상을 사용합니다. 단색의 경우 색의 채도로 값의 크기를 표현합니다. greens로 정보를 전달해서 초록색의 채도를 이용하여 값을 표현합니다.\n\nfig = px.treemap(df,\n    path=['location', 'regions', 'sectors',  'vendors'],\n    values='sales',\n    color='sales',\n    color_continuous_scale='greens')\nfig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\nfig.show()\n\n\n                                                \n\n\nTreemap은 데이터의 계층 구조와 상대적인 크기를 보여주는 데 사용하면 효과적입니다. 복잡한 계층구조를 시각적으로 표현하기 때문에 쉽게 이해할 수 있으며 비교가 편합니다. 데이터가 어떤 특징을 갖는 지 확인하고 계층적구조를 갖는 다면 Treemap을 이용해서 표현하는 것을 고민하면 좋을 것 같습니다."
  },
  {
    "objectID": "blog/posts/2023/20230916.html#참조",
    "href": "blog/posts/2023/20230916.html#참조",
    "title": "Plotly Treemap 만들기",
    "section": "",
    "text": "https://plotly.com/python/treemaps/"
  },
  {
    "objectID": "blog/posts/2023/20230930.html",
    "href": "blog/posts/2023/20230930.html",
    "title": "Plotly Axis 포멧 변경하기",
    "section": "",
    "text": "Plotly 차트의 포멧을 변경하는 방법을 정리합니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scatter(\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n    y = [0.28, 0.285, 0.37, 0.56, 0.69, 0.79, 0.78, 0.77, 0.74, 0.62, 0.45, 0.39]\n))\n\nfig.update_layout(yaxis_tickformat = '%')\nfig.show()\n\n\n                                                \n\n\ny축으로 표시하는 정보가 %단위인 경우 yaxis_tickformat으로 정보를 전달할 수 있습니다.\n\n\n소숫점 표현 방식을 지정하여 표현하는 방법을 정리합니다. yaxis_tickformat에 소수점 이하 한자리만 표현하기 위해서 .1%로 표현을 변경했습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scatter(\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n    y = [0.28, 0.285, 0.37, 0.56, 0.69, 0.79, 0.78, 0.77, 0.74, 0.62, 0.45, 0.39]\n))\n\nfig.update_layout(\n  yaxis_tickformat = '.1%')\nfig.show()\n\n\n                                                \n\n\n\n\n\n두 개의 Y축을 이용해서 그래프를 표현하는 방법을 정리합니다.\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=[1, 2, 3], y=[40, 50, 60], name=\"yaxis data (left)\"),\n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Scatter(x=[2, 3, 4], y=[4, 5, 6], name=\"yaxis2 data (right)\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Double Y Axis Example\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"xaxis title\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"&lt;b&gt;primary&lt;/b&gt; yaxis title\", secondary_y=False)\nfig.update_yaxes(title_text=\"&lt;b&gt;secondary&lt;/b&gt; yaxis title\", secondary_y=True)\n\nfig.show()\n\n\n                                                \n\n\n두 분째 Y축을 사용하기 위해서 make_subplots의 spec에 secondary_y값을 True로 설정합니다.\n그래프를 add_trace로 추가 시 secondary_y정보를 이용해서 오른쪽 Y축을 사용할 데이터를 결정합니다.\n각 그래프의 name을 yaxis data (left)와 yaxis2 data (right)와 같이 작성해서 어떤 Y축을 참고해야 하는 지 전달합니다."
  },
  {
    "objectID": "blog/posts/2023/20230930.html#자릿수-표현하기",
    "href": "blog/posts/2023/20230930.html#자릿수-표현하기",
    "title": "Plotly Axis 포멧 변경하기",
    "section": "",
    "text": "소숫점 표현 방식을 지정하여 표현하는 방법을 정리합니다. yaxis_tickformat에 소수점 이하 한자리만 표현하기 위해서 .1%로 표현을 변경했습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scatter(\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n    y = [0.28, 0.285, 0.37, 0.56, 0.69, 0.79, 0.78, 0.77, 0.74, 0.62, 0.45, 0.39]\n))\n\nfig.update_layout(\n  yaxis_tickformat = '.1%')\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230930.html#두개의-y축-표현하기",
    "href": "blog/posts/2023/20230930.html#두개의-y축-표현하기",
    "title": "Plotly Axis 포멧 변경하기",
    "section": "",
    "text": "두 개의 Y축을 이용해서 그래프를 표현하는 방법을 정리합니다.\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=[1, 2, 3], y=[40, 50, 60], name=\"yaxis data (left)\"),\n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Scatter(x=[2, 3, 4], y=[4, 5, 6], name=\"yaxis2 data (right)\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Double Y Axis Example\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"xaxis title\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"&lt;b&gt;primary&lt;/b&gt; yaxis title\", secondary_y=False)\nfig.update_yaxes(title_text=\"&lt;b&gt;secondary&lt;/b&gt; yaxis title\", secondary_y=True)\n\nfig.show()\n\n\n                                                \n\n\n두 분째 Y축을 사용하기 위해서 make_subplots의 spec에 secondary_y값을 True로 설정합니다.\n그래프를 add_trace로 추가 시 secondary_y정보를 이용해서 오른쪽 Y축을 사용할 데이터를 결정합니다.\n각 그래프의 name을 yaxis data (left)와 yaxis2 data (right)와 같이 작성해서 어떤 Y축을 참고해야 하는 지 전달합니다."
  },
  {
    "objectID": "blog/posts/2023/20230911.html",
    "href": "blog/posts/2023/20230911.html",
    "title": "Pandas 데이터프레임 머지",
    "section": "",
    "text": "병합은 서로다른 데이터프레임 객체에 동일하게 존재하는 값을 통해 양쪽 데이터를 연관 지어 하나의 데이터프레임으로 모델링할 수 있는 유용한 방법입니다. 연습을 위해서 데이터를 준비합니다.\nYahoo Finance에서는 미국뿐 아니라 한국 주식에 대한 정보를 제공합니다. KOSPI주식 정보를 csv형태로 저장해서 데이터프레임 머지 연습에 사용할께요. Yahoo Finance로 이동해서 historica l data 탭을 선택합니다.\n\nHistorical Data 를 선택하면 위와 같이 KOSPI 에 대한 시계열 데이터를 얻을 수 있습니다. download를 눌러 다운로드하여 저장합니다. 혹은 [KS11.csv]에서 다운로드 하세요.\n\n\ncsv파일을 불러와서 데이터프레임 형태를 확인합니다. 시계열데이터의 경우 날짜정보를 데이터프레임의 index로 사용하면 편리합니다. data컬럼을 index로 설정합니다.\n\nimport pandas as pd\nkospi = pd.read_csv(\"./^KS11.csv\", index_col ='Date')\nkospi.head()\n\n날짜정보가 index로 설정된 데이터프레임을 생성했습니다. 이제 연결을 위한 새로운 데이터프레임을 생성합니다. 데이트 프레임을 연결할 정보를 Ticker라는 컬럼으로 설정하고 기존 데이터프레임의 Volume컬럼을 추가합니다.\n\nkospi_volume = pd.DataFrame ({'Ticker': 'kospi', 'Volume' : kospi['Volume']})\nkospi_volume.head()\n\n2개의 데이터프레임이 함께 갖는 컬럼인 ’Ticker’를 통해서 병합을 진행하고 이를 통해서 Volume정보를 추가하려고 합니다. 올바르게 동작하는 지 확인하기 위해서 기존 데이터프레임의 Volume 컬럼을 삭제합니다.\n\nkospi['Ticker'] = 'kospi'\nkospi.pop('Volume')\nkospi.head()\n\nVolume컬럼이 삭제되었으니 병합을 진행합니다. pd.merge()함수를 사용하고 공통 컬럼인 Ticker컬럼을 전달합니다.\n\nmerged_df = pd.merge(kospi, kospi_volume, on='Ticker')\nmerged_df.head()\n\n이제 새로운 merged_df 데이터프레임은 2개의 데이터프레임을 연결하여 Volume정보를 추가 하였습니다."
  },
  {
    "objectID": "blog/posts/2023/20230911.html#데이터-로드하기",
    "href": "blog/posts/2023/20230911.html#데이터-로드하기",
    "title": "Pandas 데이터프레임 머지",
    "section": "",
    "text": "csv파일을 불러와서 데이터프레임 형태를 확인합니다. 시계열데이터의 경우 날짜정보를 데이터프레임의 index로 사용하면 편리합니다. data컬럼을 index로 설정합니다.\n\nimport pandas as pd\nkospi = pd.read_csv(\"./^KS11.csv\", index_col ='Date')\nkospi.head()\n\n날짜정보가 index로 설정된 데이터프레임을 생성했습니다. 이제 연결을 위한 새로운 데이터프레임을 생성합니다. 데이트 프레임을 연결할 정보를 Ticker라는 컬럼으로 설정하고 기존 데이터프레임의 Volume컬럼을 추가합니다.\n\nkospi_volume = pd.DataFrame ({'Ticker': 'kospi', 'Volume' : kospi['Volume']})\nkospi_volume.head()\n\n2개의 데이터프레임이 함께 갖는 컬럼인 ’Ticker’를 통해서 병합을 진행하고 이를 통해서 Volume정보를 추가하려고 합니다. 올바르게 동작하는 지 확인하기 위해서 기존 데이터프레임의 Volume 컬럼을 삭제합니다.\n\nkospi['Ticker'] = 'kospi'\nkospi.pop('Volume')\nkospi.head()\n\nVolume컬럼이 삭제되었으니 병합을 진행합니다. pd.merge()함수를 사용하고 공통 컬럼인 Ticker컬럼을 전달합니다.\n\nmerged_df = pd.merge(kospi, kospi_volume, on='Ticker')\nmerged_df.head()\n\n이제 새로운 merged_df 데이터프레임은 2개의 데이터프레임을 연결하여 Volume정보를 추가 하였습니다."
  },
  {
    "objectID": "blog/posts/2023/20231231.html",
    "href": "blog/posts/2023/20231231.html",
    "title": "코루틴(coroutine)과 이벤트 루프",
    "section": "",
    "text": "파이썬의 코루틴(coroutine)은 비동기 프로그래밍 및 동시성 작업을 구현하는데 사용되는 중요한 개념입니다.\n\n\n동시성 패턴은 프로그램이 여러 작업을 동시에 처리하거나 병령로 실행할 수 있도록 하는 디자인 패턴을 말합니다. 멀티스레딩, 멀티프로세싱, 이벤트루프, 코루틴 등이 동시성 패턴 중 하나입니다.\n코루틴은 루틴의 실행을 일시 중지하고 다른 작업을 처리한 다음 나중에 돌아오는 비동기적 함수 입니다. 코루틴은 이벤트 루프와 함께 사용하여 비동기 작업을 관리합니다.\n\n\n\n코루틴과 이벤트 루프는 비동기 프로그래밍과 동시성 작업을 관리하는 데 중요한 개념입니다.\n\n이벤트 루프 : 이벤트 루프틑 비동기적으로 실행되는 작업을 관리하고, 이벤트가 발생할 때 해당작업을 실행하고 작업들 사이의 실행을 조절합니다.\n코루틴 : 코루틴은 비동기적인 작업을 처리하기 위한 함수로 중단되고 재개될 수 있는 함수입니다. 이런 특성을 활용해서 이벤트 루프에 의해서 제어됩니다.\n\n파이썬에서는 이벤트 루프와 코루틴을 사용하기 위한 표준 라이브러리로 asyncio를 제공합니다. async키워드와 await키워드를 사용해서 비동기 함수를 정의하고 실행합니다.\n\n\n\n\n\n\nNote\n\n\n\n비동기 작업은 어떤 경우에 주로 사용될까요? 주로 파일 I/O, 네트워크 요청 등을 처리하는 데 사용됩니다. 블로킹되지 않고 비동기적으로 처리되기 때문에 여러작업을 동시에 처리할 수 있어 반응이 빨라집니다.\n\n\n비동기 함수가 동작하는 방식을 예제 코드로 정리합니다.\nimport asyncio\nimport time\n\nasync def say_hello(name):\n    print(f\"say_hello_{name} -&gt; asyncio.sleep : sleep\")\n    start_time = time.time()\n    await asyncio.sleep(1)\n    end_time = time.time()\n    print(f\"asyncio.sleep -&gt; say_hello_{name} : total({end_time - start_time})\")\n\nasync def main():\n    print(\"@startuml\")\n    print(\"main -&gt; say_hello_AAA\")\n    start_time = time.time()\n    await asyncio.gather(\n    say_hello(\"AAA\"),\n    say_hello(\"BBB\"),\n    say_hello(\"CCC\"),\n    )\n    end_time = time.time()\n    print(f\"say_hello_CCC -&gt; main : total({end_time - start_time})\")\n    print(\"@enduml\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n위의 코드에서 코드틴 함수인 say_hello는 함수에서 비동기적인 대기를 진행합니다. 비동기코드에서 특정 시간동안 대기하고 다른 적읍을 실행할 수 있도록 합니다.\n시퀀스 다이어그램으로 동작을 확인합니다. asyncio.gather()는 say_hello함수 3개가 동시에 실행될 수 있도록 합니다.\n\ngather함수가 3개의 say_hello 함수 실행을 완료한 시간은 총 1초입니다. 동기함수로 구현되어 sleep을 사용했다면 1초의 대기 시간동안 다른 함수의 실행이 불가능하지만 비동기 함수로 구현하여 대기 시간동안 다른 함수가 실행됩니다.\n\n\n\n이벤트 루프는 async로 정의된 비동기 함수(코루틴)을 실행합니다. 각 함수들은 await키워드를 사용하여 비동기적으로 실행되며 이벤트 루프는 이러한 작업을 관리합니다. 이벤트 루프를 사용하면 다른 루프의 작업과 상호 간섭없이 동작합니다. 여러 비동기 작업을 분리하거나 병렬로 처리하기 위해 사용합니다.\nasyncio 라이브러리에서는 쓰레드는 하나의 이벤트 루프를 생성하며 asyncio.run()함수는 현재 쓰레드의 기본 이벤트 루프를 자동으로 사용합니다. 따라서 새로운 이벤트 루프를 생성하는 경우 쓰레드에 사용할 이벤트 루프를 연결하는 과정이 필요합니다.\n아래의 코드는 새로운 이벤트 루프를 생성해서 실행되는 쓰레드의 이벤트 루프를 변경하는 예제 코드입니다.\nimport asyncio\nimport threading\n\nasync def simple_task(name, delay):\n    print(f\"Task {name} 시작\")\n    await asyncio.sleep(delay)\n    print(f\"Task {name} 완료\")\n\ndef create_and_run_event_loop():\n    print(\"[STEP] 새로운 이벤트 루프 생성\")\n    new_loop = asyncio.new_event_loop()\n\n    print(\"[STEP] 생성된 루프를 현재 스레드의 이벤트 루프로 설정\")\n    asyncio.set_event_loop(new_loop)\n\n    try:\n        print(\"[STEP] 비동기 함수 실행\")\n        new_loop.run(simple_task(\"새 루프 태스크\", 2))\n    finally:\n        print(\"[STEP] 이벤트 루프 닫기\")\n        new_loop.close()\n\nif __name__ == \"__main__\":\n    print(\"[STEP] 메인 함수에서 새 이벤트 루프 생성 및 실행\")\n    create_and_run_event_loop()\n[STEP] 메인 함수에서 새 이벤트 루프 생성 및 실행\n[STEP] 새로운 이벤트 루프 생성\n[STEP] 생성된 루프를 현재 스레드의 이벤트 루프로 설정\n[STEP] 비동기 함수 실행\nTask 새 루프 태스크 시작\nTask 새 루프 태스크 완료\n[STEP] 이벤트 루프 닫기\n출력 결과로 실행 순서를 확인합니다. new_event_loop함수로 이벤트 루프를 생성합니다. 생된된 이벤트 루프는 set_event_loop함수로 현제 쓰레드에 이벤트 루프로 설정합니다. run_until_complete 함수는 인자로 받은 코루틴을 실행합니다.\n이벤트 루프에 전달된 코루틴 함수 simple_task는 이벤트 루프에 의해서 실행되어 Task 새 루프 태스크 시작과 Task 새 루프 태스크 완료 로그를 출력합니다."
  },
  {
    "objectID": "blog/posts/2023/20231231.html#동시성-패턴",
    "href": "blog/posts/2023/20231231.html#동시성-패턴",
    "title": "코루틴(coroutine)과 이벤트 루프",
    "section": "",
    "text": "동시성 패턴은 프로그램이 여러 작업을 동시에 처리하거나 병령로 실행할 수 있도록 하는 디자인 패턴을 말합니다. 멀티스레딩, 멀티프로세싱, 이벤트루프, 코루틴 등이 동시성 패턴 중 하나입니다.\n코루틴은 루틴의 실행을 일시 중지하고 다른 작업을 처리한 다음 나중에 돌아오는 비동기적 함수 입니다. 코루틴은 이벤트 루프와 함께 사용하여 비동기 작업을 관리합니다."
  },
  {
    "objectID": "blog/posts/2023/20231231.html#코루틴과-이벤트루프",
    "href": "blog/posts/2023/20231231.html#코루틴과-이벤트루프",
    "title": "코루틴(coroutine)과 이벤트 루프",
    "section": "",
    "text": "코루틴과 이벤트 루프는 비동기 프로그래밍과 동시성 작업을 관리하는 데 중요한 개념입니다.\n\n이벤트 루프 : 이벤트 루프틑 비동기적으로 실행되는 작업을 관리하고, 이벤트가 발생할 때 해당작업을 실행하고 작업들 사이의 실행을 조절합니다.\n코루틴 : 코루틴은 비동기적인 작업을 처리하기 위한 함수로 중단되고 재개될 수 있는 함수입니다. 이런 특성을 활용해서 이벤트 루프에 의해서 제어됩니다.\n\n파이썬에서는 이벤트 루프와 코루틴을 사용하기 위한 표준 라이브러리로 asyncio를 제공합니다. async키워드와 await키워드를 사용해서 비동기 함수를 정의하고 실행합니다.\n\n\n\n\n\n\nNote\n\n\n\n비동기 작업은 어떤 경우에 주로 사용될까요? 주로 파일 I/O, 네트워크 요청 등을 처리하는 데 사용됩니다. 블로킹되지 않고 비동기적으로 처리되기 때문에 여러작업을 동시에 처리할 수 있어 반응이 빨라집니다.\n\n\n비동기 함수가 동작하는 방식을 예제 코드로 정리합니다.\nimport asyncio\nimport time\n\nasync def say_hello(name):\n    print(f\"say_hello_{name} -&gt; asyncio.sleep : sleep\")\n    start_time = time.time()\n    await asyncio.sleep(1)\n    end_time = time.time()\n    print(f\"asyncio.sleep -&gt; say_hello_{name} : total({end_time - start_time})\")\n\nasync def main():\n    print(\"@startuml\")\n    print(\"main -&gt; say_hello_AAA\")\n    start_time = time.time()\n    await asyncio.gather(\n    say_hello(\"AAA\"),\n    say_hello(\"BBB\"),\n    say_hello(\"CCC\"),\n    )\n    end_time = time.time()\n    print(f\"say_hello_CCC -&gt; main : total({end_time - start_time})\")\n    print(\"@enduml\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n위의 코드에서 코드틴 함수인 say_hello는 함수에서 비동기적인 대기를 진행합니다. 비동기코드에서 특정 시간동안 대기하고 다른 적읍을 실행할 수 있도록 합니다.\n시퀀스 다이어그램으로 동작을 확인합니다. asyncio.gather()는 say_hello함수 3개가 동시에 실행될 수 있도록 합니다.\n\ngather함수가 3개의 say_hello 함수 실행을 완료한 시간은 총 1초입니다. 동기함수로 구현되어 sleep을 사용했다면 1초의 대기 시간동안 다른 함수의 실행이 불가능하지만 비동기 함수로 구현하여 대기 시간동안 다른 함수가 실행됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231231.html#이벤트-루프",
    "href": "blog/posts/2023/20231231.html#이벤트-루프",
    "title": "코루틴(coroutine)과 이벤트 루프",
    "section": "",
    "text": "이벤트 루프는 async로 정의된 비동기 함수(코루틴)을 실행합니다. 각 함수들은 await키워드를 사용하여 비동기적으로 실행되며 이벤트 루프는 이러한 작업을 관리합니다. 이벤트 루프를 사용하면 다른 루프의 작업과 상호 간섭없이 동작합니다. 여러 비동기 작업을 분리하거나 병렬로 처리하기 위해 사용합니다.\nasyncio 라이브러리에서는 쓰레드는 하나의 이벤트 루프를 생성하며 asyncio.run()함수는 현재 쓰레드의 기본 이벤트 루프를 자동으로 사용합니다. 따라서 새로운 이벤트 루프를 생성하는 경우 쓰레드에 사용할 이벤트 루프를 연결하는 과정이 필요합니다.\n아래의 코드는 새로운 이벤트 루프를 생성해서 실행되는 쓰레드의 이벤트 루프를 변경하는 예제 코드입니다.\nimport asyncio\nimport threading\n\nasync def simple_task(name, delay):\n    print(f\"Task {name} 시작\")\n    await asyncio.sleep(delay)\n    print(f\"Task {name} 완료\")\n\ndef create_and_run_event_loop():\n    print(\"[STEP] 새로운 이벤트 루프 생성\")\n    new_loop = asyncio.new_event_loop()\n\n    print(\"[STEP] 생성된 루프를 현재 스레드의 이벤트 루프로 설정\")\n    asyncio.set_event_loop(new_loop)\n\n    try:\n        print(\"[STEP] 비동기 함수 실행\")\n        new_loop.run(simple_task(\"새 루프 태스크\", 2))\n    finally:\n        print(\"[STEP] 이벤트 루프 닫기\")\n        new_loop.close()\n\nif __name__ == \"__main__\":\n    print(\"[STEP] 메인 함수에서 새 이벤트 루프 생성 및 실행\")\n    create_and_run_event_loop()\n[STEP] 메인 함수에서 새 이벤트 루프 생성 및 실행\n[STEP] 새로운 이벤트 루프 생성\n[STEP] 생성된 루프를 현재 스레드의 이벤트 루프로 설정\n[STEP] 비동기 함수 실행\nTask 새 루프 태스크 시작\nTask 새 루프 태스크 완료\n[STEP] 이벤트 루프 닫기\n출력 결과로 실행 순서를 확인합니다. new_event_loop함수로 이벤트 루프를 생성합니다. 생된된 이벤트 루프는 set_event_loop함수로 현제 쓰레드에 이벤트 루프로 설정합니다. run_until_complete 함수는 인자로 받은 코루틴을 실행합니다.\n이벤트 루프에 전달된 코루틴 함수 simple_task는 이벤트 루프에 의해서 실행되어 Task 새 루프 태스크 시작과 Task 새 루프 태스크 완료 로그를 출력합니다."
  },
  {
    "objectID": "blog/posts/2023/20230921.html",
    "href": "blog/posts/2023/20230921.html",
    "title": "Plotly Histogram Plot만들기",
    "section": "",
    "text": "tips데이터는 고객 정보와 고객이 지불한 금액과 팁을 표시한 데이터입니다.\n\nimport plotly.express as px\ndf = px.data.tips()\ndf.head(3)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n\n\n\n\n\n\n\n’total_bill’에 대한 histogram을 표시합니다. 시간별 차이를 비교하기 위해서 facet_row에 time정보를 전달합니다.\n\nfig = px.histogram(df, x=\"total_bill\", facet_row=\"time\")\nfig.show()\n\n\n                                                \n\n\n히스토그램의 막대 갯수는 nbins로 수정합니다.\n\nfig = px.histogram(df, x=\"total_bill\", nbins=100)\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230921.html#서브플롯에-그래프-표시하기",
    "href": "blog/posts/2023/20230921.html#서브플롯에-그래프-표시하기",
    "title": "Plotly Histogram Plot만들기",
    "section": "",
    "text": "’total_bill’에 대한 histogram을 표시합니다. 시간별 차이를 비교하기 위해서 facet_row에 time정보를 전달합니다.\n\nfig = px.histogram(df, x=\"total_bill\", facet_row=\"time\")\nfig.show()\n\n\n                                                \n\n\n히스토그램의 막대 갯수는 nbins로 수정합니다.\n\nfig = px.histogram(df, x=\"total_bill\", nbins=100)\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230914.html",
    "href": "blog/posts/2023/20230914.html",
    "title": "Pandas 중복 데이터 제거하기",
    "section": "",
    "text": "데이터프레임에는 중복 데이터가 존재할 수 있습니다. 중복 데이터가 계산 결과에 영향을 주는 의도된 데이터가 아니라면 중복 데이터를 적절하게 처리하는 것이 필요할 수 있습니다. 현업에서 진행하게 된다면 이 과정은 데이터에 대해서 이해한 업무 담당자와 확인이 필요합니다. 중복데이터 연습을 위해서 데이터프레임을 생성합니다.\n\nimport pandas as pd\n\ndf_duplicated = pd.DataFrame({'city': ['seoul']*3 + ['busan']*2,\n                              'num' : ['02'] *3 + ['051']*2})\ndf_duplicated\n\n\n\n\n\n\n\n\ncity\nnum\n\n\n\n\n0\nseoul\n02\n\n\n1\nseoul\n02\n\n\n2\nseoul\n02\n\n\n3\nbusan\n051\n\n\n4\nbusan\n051\n\n\n\n\n\n\n\n도시 이름에 맞는 지역번호를 정보로 저장하는 데이터프레임으로 생성합니다. city 컬럼 정보를 이용하여 지역번호를 확인하기 위해 데이터프레임을 사용한다면 city정보가 중복될 필요가 없습니다. 중복되는 데이터를 정리할 수 있습니다. 중복된 열정보는 duplicated()함수를 이용하여 확인합니다.\n\ndf_duplicated.duplicated()\n\n0    False\n1     True\n2     True\n3    False\n4     True\ndtype: bool\n\n\n중복된 열정보를 갖는 boolean Series가 리턴되었습니다. 이 정보를 이용해서 중복된 열을 제거합니다. 중복된 열은 drop_duplicates()함수를 사용합니다. 함수의 [API정보]를 확인하면 keep 파라메터를 이용해서 어떤 위치의 중복열을 True로 표시할지 결정합니다.\n\n마지막 중복열을 제외한 모든 열을 True로 정의하기 위해서 keep 파라메터를 last로 전달합니다. 기본은 first값을 갖는군요.\n\ndf_duplicated.drop_duplicates(keep='last')\n\n\n\n\n\n\n\n\ncity\nnum\n\n\n\n\n2\nseoul\n02\n\n\n4\nbusan\n051\n\n\n\n\n\n\n\n중복된 열의 마지막 열만 남고 중복된 열이 삭제되었습니다. 아직 df_duplicated 데이터프레임의 정보는 변경되지 않았다는 것을 주의해야합니다.\n\ndf_duplicated\n\n\n\n\n\n\n\n\ncity\nnum\n\n\n\n\n0\nseoul\n02\n\n\n1\nseoul\n02\n\n\n2\nseoul\n02\n\n\n3\nbusan\n051\n\n\n4\nbusan\n051\n\n\n\n\n\n\n\n데이터프레임을 변경하는 경우 변수에 결과값을 다시 전달하거나 함수가 inplace파라메터를 지원해서 데이터프레임을 바로 수정할 수 있는 지 확인해야 합니다.\n\ndf = df_duplicated.drop_duplicates(keep='last')\ndf\n\n\n\n\n\n\n\n\ncity\nnum\n\n\n\n\n2\nseoul\n02\n\n\n4\nbusan\n051\n\n\n\n\n\n\n\n이제 중복을 제거한 데이터프레임의 city컬럼의 정보가 busan인 열을 선택합니다. 선택을 위해서 df에 boolean indexing결과를 전달합니다.\n\ndf[df['city'] == 'busan']\n\n\n\n\n\n\n\n\ncity\nnum\n\n\n\n\n4\nbusan\n051\n\n\n\n\n\n\n\n\n\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html"
  },
  {
    "objectID": "blog/posts/2023/20230914.html#참조",
    "href": "blog/posts/2023/20230914.html#참조",
    "title": "Pandas 중복 데이터 제거하기",
    "section": "",
    "text": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html"
  },
  {
    "objectID": "blog/posts/2023/20230919.html",
    "href": "blog/posts/2023/20230919.html",
    "title": "Plotly Box Plot만들기",
    "section": "",
    "text": "Plotly Box Plot 만드는 방법을 정리합니다. 데이터는 레스토랑의 tip정보를 저장한 tips를 사용합니다.\n\nimport plotly.express as px\ndf = px.data.tips()\ndf.sample(3)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n41\n17.46\n2.54\nMale\nNo\nSun\nDinner\n2\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n106\n20.49\n4.06\nMale\nYes\nSat\nDinner\n2\n\n\n\n\n\n\n\ntotal_bill 컬럼은 지출한 금액이고 tip은 지출한 팁을 표시하는 것 같습니다. 다음으로 고객의 다양한 특징을 표현하는 컬럼정보와 함께 지출했던 시간 정보가 있습니다. 우선 total_bill의 데이터 분포를 확인하기 위해서 Boxplot을 그려봅니다. 혹시 데이터프레임에 정보가 없는 영역이 있는 지 확인합니다. NaN인 경우 true로 표시하는 isnull()함수의 합계가 모두 0이기 때문에 데이터에 문제가 없습니다.\n\ndf.isnull().sum()\n\ntotal_bill    0\ntip           0\nsex           0\nsmoker        0\nday           0\ntime          0\nsize          0\ndtype: int64\n\n\nBox plot으로 의미있는 데이터를 얻기위해서 위해서 숫자형 데이터가 필요합니다. total_bill, tip, size는 숫자형 데이터임을 알 수 있습니다.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   total_bill  244 non-null    float64\n 1   tip         244 non-null    float64\n 2   sex         244 non-null    object \n 3   smoker      244 non-null    object \n 4   day         244 non-null    object \n 5   time        244 non-null    object \n 6   size        244 non-null    int64  \ndtypes: float64(2), int64(1), object(4)\nmemory usage: 13.5+ KB\n\n\ntotal_bill에 대한 Box plot정보를 표시합니다.\n\nfig = px.box(df, y=\"total_bill\")\nfig.show()\n\n\n                                                \n\n\n\n\n가로로 그래프로 표시할 경우 데이터를 전달하는 축을 x로 변경하여 전달합니다.\n\nfig = px.box(df, x=\"total_bill\")\nfig.show()\n\n\n                                                \n\n\n\n\n\nx축에 요일 정보를 추가해서 Box Plot 결과를 확인합니다. Q1, Q3, 중앙값이 표시됩니다. upper fance와 lower fance를 벗어나는 데이터는 이상치로 생각될 수 있습니다. 40달러 이상의 경우 이상치로 표시되고 있습니다. 저녁식사에 비용이 더 많이 발생했음을 쉽게 알 수 있습니다.\n\nfig = px.box(df, x=\"time\", y=\"total_bill\")\nfig.show()\n\n\n                                                \n\n\n\n\n\nsmoker에 따른 tip차이를 확인하기 위해서 color에 smoker를 전달합니다. x축의 각 요일에 표시되는 tip정보에 smoker정보가 추가되었습니다.\n\nfig = px.box(df, x=\"day\", y=\"tip\", color=\"smoker\")\nfig.show()\n\n\n                                                \n\n\n\n\n\n이번엔 facet_col을 이용해서 sex정보에 따라서 서로다른 그래프 영역으로 표시합니다. x축을 day로 변경하고 y축을 tip으로 변경해서 요일별 tip비용을 time에 따라 그래프를 독립적으로 생성합니다.\n\nfig = px.box(df, x=\"day\", y=\"tip\", color=\"smoker\", facet_col='time')\nfig.show()\n\n\n                                                \n\n\n주말에는 팁이 저녁 식사에 발생했고 토요일에는 이상치가 많이 발생했습니다. 점심식사는 목요일과 금요일에 주로 발생했고 금요일은 점심과 저녁 모두 팁이 발생하는 특징이 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20230919.html#가로로-그래프-표시하기",
    "href": "blog/posts/2023/20230919.html#가로로-그래프-표시하기",
    "title": "Plotly Box Plot만들기",
    "section": "",
    "text": "가로로 그래프로 표시할 경우 데이터를 전달하는 축을 x로 변경하여 전달합니다.\n\nfig = px.box(df, x=\"total_bill\")\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230919.html#축-정보-추가하기",
    "href": "blog/posts/2023/20230919.html#축-정보-추가하기",
    "title": "Plotly Box Plot만들기",
    "section": "",
    "text": "x축에 요일 정보를 추가해서 Box Plot 결과를 확인합니다. Q1, Q3, 중앙값이 표시됩니다. upper fance와 lower fance를 벗어나는 데이터는 이상치로 생각될 수 있습니다. 40달러 이상의 경우 이상치로 표시되고 있습니다. 저녁식사에 비용이 더 많이 발생했음을 쉽게 알 수 있습니다.\n\nfig = px.box(df, x=\"time\", y=\"total_bill\")\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230919.html#color를-이용해서-비교-정보-추가하기",
    "href": "blog/posts/2023/20230919.html#color를-이용해서-비교-정보-추가하기",
    "title": "Plotly Box Plot만들기",
    "section": "",
    "text": "smoker에 따른 tip차이를 확인하기 위해서 color에 smoker를 전달합니다. x축의 각 요일에 표시되는 tip정보에 smoker정보가 추가되었습니다.\n\nfig = px.box(df, x=\"day\", y=\"tip\", color=\"smoker\")\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230919.html#새로운-plot으로-비교하기",
    "href": "blog/posts/2023/20230919.html#새로운-plot으로-비교하기",
    "title": "Plotly Box Plot만들기",
    "section": "",
    "text": "이번엔 facet_col을 이용해서 sex정보에 따라서 서로다른 그래프 영역으로 표시합니다. x축을 day로 변경하고 y축을 tip으로 변경해서 요일별 tip비용을 time에 따라 그래프를 독립적으로 생성합니다.\n\nfig = px.box(df, x=\"day\", y=\"tip\", color=\"smoker\", facet_col='time')\nfig.show()\n\n\n                                                \n\n\n주말에는 팁이 저녁 식사에 발생했고 토요일에는 이상치가 많이 발생했습니다. 점심식사는 목요일과 금요일에 주로 발생했고 금요일은 점심과 저녁 모두 팁이 발생하는 특징이 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231221.html",
    "href": "blog/posts/2023/20231221.html",
    "title": "RAG(Retrieval Argumented Generation) 정리하기",
    "section": "",
    "text": "“Retrieval-Augmented Generation” (RAG)는 자연어 처리 분야에서 사용되는 기술로, 특히 질문에 대한 답변이나 문장 생성과 같은 작업을 수행할 때 기존의 텍스트 생성 모델과 정보 검색을 결합하는 방법입니다. RAG는 크게 두 가지 주요 구성 요소로 나눌 수 있습니다: 정보 검색(retrieval)과 생성(generation).\n정보 검색 (Retrieval): 이 단계에서는 주어진 질문이나 입력에 가장 관련이 높은 문서나 데이터를 검색합니다. 이 과정은 대규모의 데이터베이스나 문서 집합에서 특정 키워드나 문맥에 기반하여 가장 적절한 정보를 찾는 것을 포함합니다.\n생성 (Generation): 검색된 정보를 바탕으로, 언어 모델이 자연스러운, 일관된 답변이나 문장을 생성합니다. 이 단계에서는 전통적인 언어 모델링 기법이 사용되며, 검색된 결과를 참조하여 보다 정확하고 상세한 정보를 제공하는 데 도움이 됩니다.\nRAG의 핵심은 정보 검색과 생성 두 부분을 통합하여, 단순한 텍스트 생성을 넘어서 사용자의 질문이나 요구에 맞는 구체적이고 상세한 답변을 제공하는 것입니다. 이 기술은 질문-답변 시스템, 챗봇, 기사 생성, 요약 생성 등 다양한 분야에서 활용됩니다.\nRAG 시스템의 성능은 검색하는 데이터베이스의 질과 크기, 그리고 언어 모델의 능력에 크게 의존합니다. 이러한 시스템은 대량의 정보에 접근하고, 그 정보를 바탕으로 사용자에게 보다 정확하고 유용한 답변을 제공할 수 있는 잠재력을 가지고 있습니다\n\n\n\nLangChain은 언어 모델과 에이전트의 개발 및 분석을 용이하게 하는 다기능 파이썬 라이브러리입니다. 이 라이브러리는 특히 응용 프로그램에서 Retrieval-Augmented Generation (RAG) 패턴을 구현하는 데 유용합니다. LangChain을 사용하면 “문서” 객체를 통해 여러 다른 소스에서 온 데이터를 정규화할 수 있으며, 이는 다양한 체인에서 데이터를 구조화된 방식으로 처리하고 전달하는 데 필수적입니다.\nLangChain의 핵심 아이디어는 AI 행동을 특정 순서대로 배열하여 처리 파이프라인을 만드는 것입니다. RAG 패턴의 맥락에서는 사용자가 질문을 제출하는 것으로 시작하여, 임베딩 생성, 추가 맥락을 위한 벡터 데이터베이스 조회, 그리고 마지막으로 언어 모델을 위한 프롬프트 생성의 순서를 따릅니다. LangChain의 “체인” 구성은 이러한 단계들을 특정 구성으로 연결하여 처리 파이프라인의 원활한 흐름과 오류 처리를 보장합니다."
  },
  {
    "objectID": "blog/posts/2023/20231221.html#rag가-무엇인가요",
    "href": "blog/posts/2023/20231221.html#rag가-무엇인가요",
    "title": "RAG(Retrieval Argumented Generation) 정리하기",
    "section": "",
    "text": "“Retrieval-Augmented Generation” (RAG)는 자연어 처리 분야에서 사용되는 기술로, 특히 질문에 대한 답변이나 문장 생성과 같은 작업을 수행할 때 기존의 텍스트 생성 모델과 정보 검색을 결합하는 방법입니다. RAG는 크게 두 가지 주요 구성 요소로 나눌 수 있습니다: 정보 검색(retrieval)과 생성(generation).\n정보 검색 (Retrieval): 이 단계에서는 주어진 질문이나 입력에 가장 관련이 높은 문서나 데이터를 검색합니다. 이 과정은 대규모의 데이터베이스나 문서 집합에서 특정 키워드나 문맥에 기반하여 가장 적절한 정보를 찾는 것을 포함합니다.\n생성 (Generation): 검색된 정보를 바탕으로, 언어 모델이 자연스러운, 일관된 답변이나 문장을 생성합니다. 이 단계에서는 전통적인 언어 모델링 기법이 사용되며, 검색된 결과를 참조하여 보다 정확하고 상세한 정보를 제공하는 데 도움이 됩니다.\nRAG의 핵심은 정보 검색과 생성 두 부분을 통합하여, 단순한 텍스트 생성을 넘어서 사용자의 질문이나 요구에 맞는 구체적이고 상세한 답변을 제공하는 것입니다. 이 기술은 질문-답변 시스템, 챗봇, 기사 생성, 요약 생성 등 다양한 분야에서 활용됩니다.\nRAG 시스템의 성능은 검색하는 데이터베이스의 질과 크기, 그리고 언어 모델의 능력에 크게 의존합니다. 이러한 시스템은 대량의 정보에 접근하고, 그 정보를 바탕으로 사용자에게 보다 정확하고 유용한 답변을 제공할 수 있는 잠재력을 가지고 있습니다"
  },
  {
    "objectID": "blog/posts/2023/20231221.html#langchain은-무엇인가요",
    "href": "blog/posts/2023/20231221.html#langchain은-무엇인가요",
    "title": "RAG(Retrieval Argumented Generation) 정리하기",
    "section": "",
    "text": "LangChain은 언어 모델과 에이전트의 개발 및 분석을 용이하게 하는 다기능 파이썬 라이브러리입니다. 이 라이브러리는 특히 응용 프로그램에서 Retrieval-Augmented Generation (RAG) 패턴을 구현하는 데 유용합니다. LangChain을 사용하면 “문서” 객체를 통해 여러 다른 소스에서 온 데이터를 정규화할 수 있으며, 이는 다양한 체인에서 데이터를 구조화된 방식으로 처리하고 전달하는 데 필수적입니다.\nLangChain의 핵심 아이디어는 AI 행동을 특정 순서대로 배열하여 처리 파이프라인을 만드는 것입니다. RAG 패턴의 맥락에서는 사용자가 질문을 제출하는 것으로 시작하여, 임베딩 생성, 추가 맥락을 위한 벡터 데이터베이스 조회, 그리고 마지막으로 언어 모델을 위한 프롬프트 생성의 순서를 따릅니다. LangChain의 “체인” 구성은 이러한 단계들을 특정 구성으로 연결하여 처리 파이프라인의 원활한 흐름과 오류 처리를 보장합니다."
  },
  {
    "objectID": "blog/posts/2023/20231115-1.html",
    "href": "blog/posts/2023/20231115-1.html",
    "title": "wsl2에 docker 설치하기",
    "section": "",
    "text": "WSL에 Docker를 설치하는 방법을 정리합니다.\n\n\n기존의 설치된 Docker가 있다면 제거한다.\nsudo apt-get remove docker docker-engine docker.io containerd runc\nDocker 저장소를 사용할 수 있도록 패키지 인덱스를 업데이트 한다.\nsudo apt-get update\nsudo apt-get install \\\n  ca-certificates \\\n  curl \\\n  gnupg \\\n  lsb-release\nDocker의 공식 GPG키를 추가합니다. GPG(GNU Privacy Guard)는 개인 정보를 안전하게 보호하기 위한 오픈 소스의 암호화 소프트웨어입니다. Git에서 GPG는 주로 커밋에 서명을 추가하여 코드의 무결성을 보호하는 데 사용됩니다.\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n위의 명령을 이용해서 Docker APT저장소를 시스템에 추가합니다. 명령의 각 부분을 정리합니다.\n\ndeb는 APT(Advanced Package Tool)패키지 관리자가 사용하는 저장소를 정의합니다.\narch=$(dpkg --print-architecture)는 현재 설치를 수행하는 시스템의 아키택처를 가져옵니다.\nsigned-by=/etc/apt/keyrings/docker.gpg는 저장소가 서명된 GPG 키를 사용하고 있음을 나타냅니다.\n$(lsb_release -cs)는 현재 Ubuntu 배포판의 코드명(예: focal, bionic 등)을 가져옵니다.\ntee 명령은 표준 입력에서 데이터를 읽어 파일에 쓰는 동시에 표준 출력에도 쓰는 명령입니다.\n&gt; /dev/null은 tee의 출력을 표준 출력으로 보내지 않도록 하는데, 여기서는 필요하지 않은 출력을 방지하기 위해 사용됩니다.\n\n\n\n\n저장소를 추가했으니 도커에 관련된 설치를 위해서 apt 패키지 인덱스를 업데이트 및 설치합니다.\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n도커 설치가 완료되면 hello-world이미지를 실행해서 Docker Engine이 정상적으로 설치되었는지 확인합니다. 명령 실행 시 docker가 실행되지 않아 아래와 같은 에러가 발생할 수 있습니다.\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n이 경우 docker엔진을 실행합니다. 도커가 정상적으로 시행하되면 Docker is running메세지를 확인할 수 있습니다.\nsudo service docker start\nsudo service docker status\n * Docker is running\nhello-world 테스트 이미지를 실행해서 docker가 정상적으로 설치되었는지 확인합니다.\nsudo docker run hello-world\nhello-world이미지를 실행하면 아래와 같이 Hello from Docker!메세지를 확인할 수 있습니다.\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n719385e32844: Pull complete\nDigest: sha256:88ec0acaa3ec199d3b7eaf73588f4518c25f9d34f58ce9a0df68429c5af48e8d\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly."
  },
  {
    "objectID": "blog/posts/2023/20231115-1.html#기존-설치제거-저장소-추가",
    "href": "blog/posts/2023/20231115-1.html#기존-설치제거-저장소-추가",
    "title": "wsl2에 docker 설치하기",
    "section": "",
    "text": "기존의 설치된 Docker가 있다면 제거한다.\nsudo apt-get remove docker docker-engine docker.io containerd runc\nDocker 저장소를 사용할 수 있도록 패키지 인덱스를 업데이트 한다.\nsudo apt-get update\nsudo apt-get install \\\n  ca-certificates \\\n  curl \\\n  gnupg \\\n  lsb-release\nDocker의 공식 GPG키를 추가합니다. GPG(GNU Privacy Guard)는 개인 정보를 안전하게 보호하기 위한 오픈 소스의 암호화 소프트웨어입니다. Git에서 GPG는 주로 커밋에 서명을 추가하여 코드의 무결성을 보호하는 데 사용됩니다.\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n위의 명령을 이용해서 Docker APT저장소를 시스템에 추가합니다. 명령의 각 부분을 정리합니다.\n\ndeb는 APT(Advanced Package Tool)패키지 관리자가 사용하는 저장소를 정의합니다.\narch=$(dpkg --print-architecture)는 현재 설치를 수행하는 시스템의 아키택처를 가져옵니다.\nsigned-by=/etc/apt/keyrings/docker.gpg는 저장소가 서명된 GPG 키를 사용하고 있음을 나타냅니다.\n$(lsb_release -cs)는 현재 Ubuntu 배포판의 코드명(예: focal, bionic 등)을 가져옵니다.\ntee 명령은 표준 입력에서 데이터를 읽어 파일에 쓰는 동시에 표준 출력에도 쓰는 명령입니다.\n&gt; /dev/null은 tee의 출력을 표준 출력으로 보내지 않도록 하는데, 여기서는 필요하지 않은 출력을 방지하기 위해 사용됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231115-1.html#docker-engine-설치",
    "href": "blog/posts/2023/20231115-1.html#docker-engine-설치",
    "title": "wsl2에 docker 설치하기",
    "section": "",
    "text": "저장소를 추가했으니 도커에 관련된 설치를 위해서 apt 패키지 인덱스를 업데이트 및 설치합니다.\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n도커 설치가 완료되면 hello-world이미지를 실행해서 Docker Engine이 정상적으로 설치되었는지 확인합니다. 명령 실행 시 docker가 실행되지 않아 아래와 같은 에러가 발생할 수 있습니다.\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n이 경우 docker엔진을 실행합니다. 도커가 정상적으로 시행하되면 Docker is running메세지를 확인할 수 있습니다.\nsudo service docker start\nsudo service docker status\n * Docker is running\nhello-world 테스트 이미지를 실행해서 docker가 정상적으로 설치되었는지 확인합니다.\nsudo docker run hello-world\nhello-world이미지를 실행하면 아래와 같이 Hello from Docker!메세지를 확인할 수 있습니다.\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n719385e32844: Pull complete\nDigest: sha256:88ec0acaa3ec199d3b7eaf73588f4518c25f9d34f58ce9a0df68429c5af48e8d\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly."
  },
  {
    "objectID": "blog/posts/2023/20231003.html",
    "href": "blog/posts/2023/20231003.html",
    "title": "Plotly 불릿차트",
    "section": "",
    "text": "불릿(bullet)차트는 데이터 시각화에서 주로 성과를 추적하고 비교하는 데 주로 사용되는 차트입니다. Plotly로 불릿차트를 그리는 방법을 정리합니다.\n블릿 차트는 대시보드나 리포트에서 성과 지표를 시각적으로 표시하는 데 자주 사용됩니다. 이러한 차트는 정보를 빠르게 파악할 수 있도록 도와줍니다.\n\n\nIndictor는 number, delta, gauge의 세 가지 시각적 요소를 갖습니다. 이들의 조합을 mode로 전달합니다. 하나씩 설정하며 차이점을 확인합니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Indicator(\n    mode = \"gauge\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':0, 'column':0}\n))\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+number\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':0, 'column':1}))\n\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    delta = {'reference': 500},\n    title = {'text': \"Speed\"},\n    domain = {'row':1, 'column':0}\n))\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta+number\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    delta = {'reference': 500},\n    title = {'text': \"Speed\"},\n    domain = {'row':1, 'column':1}))\n\nfig.update_layout(\n    grid = {'rows': 2, 'columns': 2, 'pattern': \"independent\"})\n\n\n                                                \n\n\n기본적인 조합을 알아보기 위해서 차트의 첫번째 컬럼을 확인합니다. 첫번째 줄은 gauge와 number를 사용한 결과를 나타냅니다. 첫번째 줄의 우측에 숫자가 추가된 것을 확인할 수 있습니다.\n최대값을 500으로 정하기 위해서 gauge = {'axis': {'range': [None, 500]}}을 사용했습니다. 범위를 지정하지 않는 경우 현재 값에 맞춰 최댓값을 자동으로 설정합니다.\n두번째 줄은 delta를 mode에 추가하고 delta의 값을 설정하기 위해서 {'reference': 500}을 사용했습니다. 500과의 차이를 화살표와 함께 표시하는 것을 알 수 있습니다.\n\n\n\n불릿차트는 angular와 bullet의 모양을 갖습니다. 동일한 설정에서 shape만 변경하여 표현하면 모양의 차이를 알 수 있습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta+number\",\n    gauge = {'axis': {'range':[None, 500]},\n             'shape': 'angular'},\n    delta = {'reference': 500},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':0, 'column':0}\n))\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta+number\",\n    gauge = {'axis': {'range':[None, 500]},\n             'shape': 'bullet'},\n    delta = {'reference': 500, 'position' : \"top\"},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':1, 'column':0}\n))\n\nfig.update_layout(\n    grid = {'rows': 2, 'columns': 1, 'pattern': \"independent\"})\n\n\n                                                \n\n\n위의 예제와 차이점은 delta에 position정보를 추가하여 두 번째 불릿차트에서는 delta정보가 위에 위치했습니다. position정보를 사용하면 delta의 표시 위치를 설정할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231003.html#guage-기본사용법",
    "href": "blog/posts/2023/20231003.html#guage-기본사용법",
    "title": "Plotly 불릿차트",
    "section": "",
    "text": "Indictor는 number, delta, gauge의 세 가지 시각적 요소를 갖습니다. 이들의 조합을 mode로 전달합니다. 하나씩 설정하며 차이점을 확인합니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Indicator(\n    mode = \"gauge\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':0, 'column':0}\n))\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+number\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':0, 'column':1}))\n\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    delta = {'reference': 500},\n    title = {'text': \"Speed\"},\n    domain = {'row':1, 'column':0}\n))\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta+number\",\n    gauge = {'axis': {'range':[None, 500]}},\n    value = 450,\n    delta = {'reference': 500},\n    title = {'text': \"Speed\"},\n    domain = {'row':1, 'column':1}))\n\nfig.update_layout(\n    grid = {'rows': 2, 'columns': 2, 'pattern': \"independent\"})\n\n\n                                                \n\n\n기본적인 조합을 알아보기 위해서 차트의 첫번째 컬럼을 확인합니다. 첫번째 줄은 gauge와 number를 사용한 결과를 나타냅니다. 첫번째 줄의 우측에 숫자가 추가된 것을 확인할 수 있습니다.\n최대값을 500으로 정하기 위해서 gauge = {'axis': {'range': [None, 500]}}을 사용했습니다. 범위를 지정하지 않는 경우 현재 값에 맞춰 최댓값을 자동으로 설정합니다.\n두번째 줄은 delta를 mode에 추가하고 delta의 값을 설정하기 위해서 {'reference': 500}을 사용했습니다. 500과의 차이를 화살표와 함께 표시하는 것을 알 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231003.html#불릿-차트-모양-변경하기",
    "href": "blog/posts/2023/20231003.html#불릿-차트-모양-변경하기",
    "title": "Plotly 불릿차트",
    "section": "",
    "text": "불릿차트는 angular와 bullet의 모양을 갖습니다. 동일한 설정에서 shape만 변경하여 표현하면 모양의 차이를 알 수 있습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta+number\",\n    gauge = {'axis': {'range':[None, 500]},\n             'shape': 'angular'},\n    delta = {'reference': 500},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':0, 'column':0}\n))\n\nfig.add_trace(go.Indicator(\n    mode = \"gauge+delta+number\",\n    gauge = {'axis': {'range':[None, 500]},\n             'shape': 'bullet'},\n    delta = {'reference': 500, 'position' : \"top\"},\n    value = 450,\n    title = {'text': \"Speed\"},\n    domain = {'row':1, 'column':0}\n))\n\nfig.update_layout(\n    grid = {'rows': 2, 'columns': 1, 'pattern': \"independent\"})\n\n\n                                                \n\n\n위의 예제와 차이점은 delta에 position정보를 추가하여 두 번째 불릿차트에서는 delta정보가 위에 위치했습니다. position정보를 사용하면 delta의 표시 위치를 설정할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20230925.html",
    "href": "blog/posts/2023/20230925.html",
    "title": "Plotly Time Series 날짜 범위 UI 사용하기",
    "section": "",
    "text": "시계열 데이터의 날짜 범위를 잘 사용하면 데이터의 의미를 다양한 관점으로 이해할 수 있습니다. 시계열 데이터를 시각화 시 날짜 범위를 설정하는 방법을 정리합니다.\n\nimport plotly.express as px\n\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv')\ndisplay(df.head(3))\ndisplay(df.tail(3))\n\n\n\n\n\n\n\n\nDate\nAAPL.Open\nAAPL.High\nAAPL.Low\nAAPL.Close\nAAPL.Volume\nAAPL.Adjusted\ndn\nmavg\nup\ndirection\n\n\n\n\n0\n2015-02-17\n127.489998\n128.880005\n126.919998\n127.830002\n63152400\n122.905254\n106.741052\n117.927667\n129.114281\nIncreasing\n\n\n1\n2015-02-18\n127.629997\n128.779999\n127.449997\n128.720001\n44891700\n123.760965\n107.842423\n118.940333\n130.038244\nIncreasing\n\n\n2\n2015-02-19\n128.479996\n129.029999\n128.330002\n128.449997\n37362400\n123.501363\n108.894245\n119.889167\n130.884089\nDecreasing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nAAPL.Open\nAAPL.High\nAAPL.Low\nAAPL.Close\nAAPL.Volume\nAAPL.Adjusted\ndn\nmavg\nup\ndirection\n\n\n\n\n503\n2017-02-14\n133.470001\n135.089996\n133.250000\n135.020004\n32815500\n135.020004\n115.175718\n125.953499\n136.731280\nIncreasing\n\n\n504\n2017-02-15\n135.520004\n136.270004\n134.619995\n135.509995\n35501600\n135.509995\n115.545035\n126.723499\n137.901963\nDecreasing\n\n\n505\n2017-02-16\n135.669998\n135.899994\n134.839996\n135.350006\n22118000\n135.350006\n116.203299\n127.504333\n138.805366\nDecreasing\n\n\n\n\n\n\n\n시계열 데이터를 시각화하기 위해서 불러온 데이터를 확인합니다. 데이터프레임의 Date컬럼에 날짜 정보가 있습니다. 처음과 마지막 3개의 데이터를 확인하면 데이터에 2015년 2월부터 2017년 2월까지의 데이터가 있는 것을 알 수 있습니다.\n나머지 컬럼은 Apple 주가의 상한가, 하한가, 종가등의 정보를 갖습니다. Apple의 상한가를 Line plot으로 확인합니다.\n\nfig = px.line(df, x='Date', y='AAPL.High')\nfig.show()\n\n\n                                                \n\n\n2015년 부터 2017년까지의 주가 정보를 Line plot으로 시각화 했습니다.\n\n\n시계열 데이터를 좀 더 자세히 확인하기 위해서 x축으로 표시할 날짜 범위를 지정합니다. 2016년 3월부터 2016년 7월까지의 정보를 확인하기 위해서 날짜범위를 지정합니다.\n\nfig = px.line(df, x='Date', y='AAPL.High', range_x=['2016-03-01','2016-7-31'])\nfig.show()\n\n\n                                                \n\n\n전체 데이터에서 range_x로 지정한 날짜 사이의 데이터만 Line plot에 표시됩니다.\n\n\n\n슬라이더 UI를 사용하면 사용자가 원하는 날짜 범위를 설정하고 날짜를 변경할 수 있습니다.\n\nfig = px.line(df, x='Date', y='AAPL.High', title='Time Series with Rangeslider')\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()\n\n\n                                                \n\n\nupdate_xaxes()에 rangeslider_visible 옵션을 True로 선택해서 x축에 슬라이더 UI를 사용합니다.\n사용자는 그래프 하단의 날짜 범위 슬라이더의 양쪽 끝의 흰색 바를 이동하여 날짜 범위를 변경합니다. 슬라이더 내부를 선택한 상태로 이동시켜 날짜 범위의 위치를 변경할 수 있습니다.\n\n\n\n특정한 날짜 범위를 버튼으로 제공해서 사용자가 일정 날짜 범위로 데이터를 확인할 수 있습니다. update_xaxes()함수로 x축에 대한 설정을 변경합니다. rangeselector옵션에 버튼에 대한 정보를 딕셔너리 형태로 전달해서 버튼을 생성합니다.\nbuttons을 생성하기 위한 정보는 buttons API문서에서 확인할 수 있습니다. step을 통해서 날짜범위위의 단위를 결정하고 count를 통해서 범위횟수, stepmode는 현재 시점에서 어떤 방향로 날짜범위를 결정합니다.\n\nfig = px.line(df, x='Date', y='AAPL.High', title='Time Series with Range Slider and Selectors')\n\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()\n\n\n                                                \n\n\n그래프 위쪽의 날짜 버튼을 선택해서 슬라이더 UI가 어떻게 변경되는 지 확인해보세요."
  },
  {
    "objectID": "blog/posts/2023/20230925.html#날짜-범위-지정",
    "href": "blog/posts/2023/20230925.html#날짜-범위-지정",
    "title": "Plotly Time Series 날짜 범위 UI 사용하기",
    "section": "",
    "text": "시계열 데이터를 좀 더 자세히 확인하기 위해서 x축으로 표시할 날짜 범위를 지정합니다. 2016년 3월부터 2016년 7월까지의 정보를 확인하기 위해서 날짜범위를 지정합니다.\n\nfig = px.line(df, x='Date', y='AAPL.High', range_x=['2016-03-01','2016-7-31'])\nfig.show()\n\n\n                                                \n\n\n전체 데이터에서 range_x로 지정한 날짜 사이의 데이터만 Line plot에 표시됩니다."
  },
  {
    "objectID": "blog/posts/2023/20230925.html#슬라이더-ui-사용하기",
    "href": "blog/posts/2023/20230925.html#슬라이더-ui-사용하기",
    "title": "Plotly Time Series 날짜 범위 UI 사용하기",
    "section": "",
    "text": "슬라이더 UI를 사용하면 사용자가 원하는 날짜 범위를 설정하고 날짜를 변경할 수 있습니다.\n\nfig = px.line(df, x='Date', y='AAPL.High', title='Time Series with Rangeslider')\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()\n\n\n                                                \n\n\nupdate_xaxes()에 rangeslider_visible 옵션을 True로 선택해서 x축에 슬라이더 UI를 사용합니다.\n사용자는 그래프 하단의 날짜 범위 슬라이더의 양쪽 끝의 흰색 바를 이동하여 날짜 범위를 변경합니다. 슬라이더 내부를 선택한 상태로 이동시켜 날짜 범위의 위치를 변경할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20230925.html#버튼-ui-사용하기",
    "href": "blog/posts/2023/20230925.html#버튼-ui-사용하기",
    "title": "Plotly Time Series 날짜 범위 UI 사용하기",
    "section": "",
    "text": "특정한 날짜 범위를 버튼으로 제공해서 사용자가 일정 날짜 범위로 데이터를 확인할 수 있습니다. update_xaxes()함수로 x축에 대한 설정을 변경합니다. rangeselector옵션에 버튼에 대한 정보를 딕셔너리 형태로 전달해서 버튼을 생성합니다.\nbuttons을 생성하기 위한 정보는 buttons API문서에서 확인할 수 있습니다. step을 통해서 날짜범위위의 단위를 결정하고 count를 통해서 범위횟수, stepmode는 현재 시점에서 어떤 방향로 날짜범위를 결정합니다.\n\nfig = px.line(df, x='Date', y='AAPL.High', title='Time Series with Range Slider and Selectors')\n\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()\n\n\n                                                \n\n\n그래프 위쪽의 날짜 버튼을 선택해서 슬라이더 UI가 어떻게 변경되는 지 확인해보세요."
  },
  {
    "objectID": "blog/posts/2023/20231122.html",
    "href": "blog/posts/2023/20231122.html",
    "title": "airflow postgresoperator 사용하기",
    "section": "",
    "text": "WSL을 사용할 때 필요한 정보를 정리합니다. WS:로 작업한 내용을 복구하기 위해서 WSL 이미지를 원하는 위치로 변경합니다.\n\n\n[move-wsl] 깃 저장소에서 제공하는 파워쉘 스크립트를 이용하면 쉽게 wsl 이미지 위치를 변경할 수 있습니다. 스크립트로 이동 시 주의해야할 점은 Docker WSL이 정지된 상태인지 확인하는 것이라고 합니다. 정지되지 않은 상태에서 스크립트가 실행되는 경우 crash로 fatory default로 리셋될 수 있다고 합니다. (너무 무섭네요….)\n\n\n\n우선 설치된 모든 배포판을 확인합니다. 각 이미지의 상태도 확인할 수 있습니다.\nwsl -l -v\n  NAME                   STATE           VERSION\n* Ubuntu-20.04           Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n배포판에 특정 유저이름으로 접속하는 경우 유저이름을 추가할 수 있습니다.\nwsl -u &lt;유저이름&gt;\n\n\nwsl --export &lt;배포판 이름&gt; &lt;파일명&gt;\n\n\n\n실행하면 설치위치에 ext4.vhdx 파일이 생성됩니다.\nwsl --import &lt;패포판 이름&gt; &lt;설치할 위치&gt; &lt;가져올 배포판 파일명&gt;"
  },
  {
    "objectID": "blog/posts/2023/20231122.html#wsl-이미지-저장-위치-변경하기",
    "href": "blog/posts/2023/20231122.html#wsl-이미지-저장-위치-변경하기",
    "title": "airflow postgresoperator 사용하기",
    "section": "",
    "text": "[move-wsl] 깃 저장소에서 제공하는 파워쉘 스크립트를 이용하면 쉽게 wsl 이미지 위치를 변경할 수 있습니다. 스크립트로 이동 시 주의해야할 점은 Docker WSL이 정지된 상태인지 확인하는 것이라고 합니다. 정지되지 않은 상태에서 스크립트가 실행되는 경우 crash로 fatory default로 리셋될 수 있다고 합니다. (너무 무섭네요….)"
  },
  {
    "objectID": "blog/posts/2023/20231122.html#wsl-이미지-백업하기",
    "href": "blog/posts/2023/20231122.html#wsl-이미지-백업하기",
    "title": "airflow postgresoperator 사용하기",
    "section": "",
    "text": "우선 설치된 모든 배포판을 확인합니다. 각 이미지의 상태도 확인할 수 있습니다.\nwsl -l -v\n  NAME                   STATE           VERSION\n* Ubuntu-20.04           Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n배포판에 특정 유저이름으로 접속하는 경우 유저이름을 추가할 수 있습니다.\nwsl -u &lt;유저이름&gt;\n\n\nwsl --export &lt;배포판 이름&gt; &lt;파일명&gt;\n\n\n\n실행하면 설치위치에 ext4.vhdx 파일이 생성됩니다.\nwsl --import &lt;패포판 이름&gt; &lt;설치할 위치&gt; &lt;가져올 배포판 파일명&gt;"
  },
  {
    "objectID": "blog/posts/2023/20231005.html",
    "href": "blog/posts/2023/20231005.html",
    "title": "Plotly Funnel(깔대기) 차트 만들기",
    "section": "",
    "text": "Funnel Chart(깔대기 차트)는 데이터의 흐름이나 과정을 시각화하기 위한 그래프 유형 중 하나입니다. 여러 세그먼트 또는 카테고리 간의 비교를 강조하는 데 사용됩니다. 각 단계 또는 세그먼트의 크기를 표시하여 이들 간의 상대적인 크기를 시각화로 표현할 수 있습니다.\n특히 비즈니스 프로세스, 온라인 판매 흐름, 고객 경로 등과 같은 순차적인 단계로 이루어진 프로세스를 분석하는 데 유용합니다. 각 단계에서 어떤 퍼센트의 항목이 소멸하거나 성공적으로 이동하는지를 보여줍니다.\n웹사이트에 방문한 고객의 흐름을 보여주는 Funnel Chart로 동작을 확인합니다.\n\nimport plotly.express as px\ndata = dict(\n    number=[39, 27.4, 20.6, 11, 2],\n    stage=[\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\", \"invoice sent\"])\nfig = px.funnel(data, x='number', y='stage')\nfig.show()\n\n\n                                                \n\n\nFunnel 차트는 전달하는 데이터 프레임에 각 흐름의 단계에 대한 값 정보와 단계의 이름을 저장합니다. 총 5단계가 전달되었고 단계의 너비는 값에 따라 결정됩니다.\n\n\n비교를 웨해서 여러 개의 데이터를 Funnel Chart로 표시하는 방법을 정리합니다. 비교를 위해 생성한 각 데이터는 단계가 서로 다르게 설정되었습니다. 차트에 어떻게 표시되는 지 확인해보세요.\n\nfrom plotly import graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Funnel(\n    name = 'Montreal',\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\"],\n    x = [100, 90, 81, 72.9],\n    textinfo = \"value+percent initial\"))\n\nfig.add_trace(go.Funnel(\n    name = 'Toronto',\n    orientation = \"h\",\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\", \"invoice sent\"],\n    x = [100, 90, 81, 72.9, 65.61],\n    textposition = \"inside\",\n    textinfo = \"value+percent previous\"))\n\nfig.add_trace(go.Funnel(\n    name = 'Vancouver',\n    orientation = \"h\",\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\", \"invoice sent\", \"Finalized\"],\n    x = [100, 90, 81, 72.9, 65.61, 59],\n    textposition = \"inside\",\n    textinfo = \"value+percent total\"))\n\nfig.show()\n\n\n                                                \n\n\nFunnel Chart내부에 표시되는 비율은 textinfo로 전달되는 정보로 설정됩니다. value+percent initial, value+percent previous, value+percent total의 차이를 알아봅니다. 모든 데이터는 초기값 100에서 90%만 다음 단계로 넘어가도록 구성되어 있습니다.\n\nvalue+percent initial : 현재 단계의 값을 초기값에 대한 비율로 표시합니다.\nvalue+percent previous : 현재 단계의 값을 이전 단계에 대한 비율로 표시합니다. 값이 90%로 유지되는 것을 확인할 수 있습니다.\nvalue+percent total : 현재 단계의 값을 전체 단계의 총합에 대한 비율로 표시합니다. 첫번째 단계는 전체 단계의 총합으로 나눈 비율이며 와 같이 아래와 같이 계산됩니다. \\[21\\% = \\frac{100 (첫번째 단계 값)}{468.51 (전체 단계 총합)}\\]"
  },
  {
    "objectID": "blog/posts/2023/20231005.html#여러-개의-데이터를-funnel-chart로-표시하기",
    "href": "blog/posts/2023/20231005.html#여러-개의-데이터를-funnel-chart로-표시하기",
    "title": "Plotly Funnel(깔대기) 차트 만들기",
    "section": "",
    "text": "비교를 웨해서 여러 개의 데이터를 Funnel Chart로 표시하는 방법을 정리합니다. 비교를 위해 생성한 각 데이터는 단계가 서로 다르게 설정되었습니다. 차트에 어떻게 표시되는 지 확인해보세요.\n\nfrom plotly import graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Funnel(\n    name = 'Montreal',\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\"],\n    x = [100, 90, 81, 72.9],\n    textinfo = \"value+percent initial\"))\n\nfig.add_trace(go.Funnel(\n    name = 'Toronto',\n    orientation = \"h\",\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\", \"invoice sent\"],\n    x = [100, 90, 81, 72.9, 65.61],\n    textposition = \"inside\",\n    textinfo = \"value+percent previous\"))\n\nfig.add_trace(go.Funnel(\n    name = 'Vancouver',\n    orientation = \"h\",\n    y = [\"Website visit\", \"Downloads\", \"Potential customers\", \"Requested price\", \"invoice sent\", \"Finalized\"],\n    x = [100, 90, 81, 72.9, 65.61, 59],\n    textposition = \"inside\",\n    textinfo = \"value+percent total\"))\n\nfig.show()\n\n\n                                                \n\n\nFunnel Chart내부에 표시되는 비율은 textinfo로 전달되는 정보로 설정됩니다. value+percent initial, value+percent previous, value+percent total의 차이를 알아봅니다. 모든 데이터는 초기값 100에서 90%만 다음 단계로 넘어가도록 구성되어 있습니다.\n\nvalue+percent initial : 현재 단계의 값을 초기값에 대한 비율로 표시합니다.\nvalue+percent previous : 현재 단계의 값을 이전 단계에 대한 비율로 표시합니다. 값이 90%로 유지되는 것을 확인할 수 있습니다.\nvalue+percent total : 현재 단계의 값을 전체 단계의 총합에 대한 비율로 표시합니다. 첫번째 단계는 전체 단계의 총합으로 나눈 비율이며 와 같이 아래와 같이 계산됩니다. \\[21\\% = \\frac{100 (첫번째 단계 값)}{468.51 (전체 단계 총합)}\\]"
  },
  {
    "objectID": "blog/posts/2023/20230913.html",
    "href": "blog/posts/2023/20230913.html",
    "title": "Plotly Subpolt 만들기",
    "section": "",
    "text": "Python으로 여러개의 그래프를 비교하기 좋은 방법은 subplot을 이용한 방법인 것 같습니다. subplot을 만드는 방법과 subplot의 title작성하는 방법 그리고 subplot들에 대한 전체 title을 넣는 방법도 함께 정리합니다.\nPlotly의 make_subplots함수로 subplot을 구성하고 ploty 그래프를 생성했습니다. add_trace()함수로 생성한 subplot에 그래프를 추가합니다.\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(rows=1, cols = 2)\n\nfig.add_trace(go.Scatter(x=[1, 2, 3], y=[4, 5, 6], name=\"subplot 1\"),\n              row=1, col=1)\nfig.add_trace(go.Scatter(x=[10, 20, 30], y=[100, 200, 300], name=\"subplot 2\"),\n              row=1, col=2)\n\nfig.show()\n\n\n                                                \n\n\n\n\nmake_subplot의 세부 설정을 알아보고 어떻게 변경할 수 있는지 알아봅니다. 하나의 Y축을 2개의 subplot이 공유하도록 shared_yaxes를 사용합니다. 각각의 subplot의 크기는 column_widths로 변경할 수 있습니다. 2개의 subplot사이의 거리는 horizontal_spacing으로 정합니다.\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(\n    rows=1, cols=2,\n    shared_yaxes=True,\n    horizontal_spacing=0.05,\n    column_widths=[0.3, 0.7]\n)\n\n\nfig.add_trace(go.Scatter(x=[1, 2, 3], y=[4, 5, 6], name=\"subplot 1\"),\n              row=1, col=1)\nfig.add_trace(go.Scatter(x=[10, 20, 30], y=[10, 20, 30], name=\"subplot 2\"),\n              row=1, col=2)\n\nfig.show()\n\n\n                                                \n\n\n\n\n\n\nhttps://chancoding.tistory.com/229"
  },
  {
    "objectID": "blog/posts/2023/20230913.html#subplot-세부설정",
    "href": "blog/posts/2023/20230913.html#subplot-세부설정",
    "title": "Plotly Subpolt 만들기",
    "section": "",
    "text": "make_subplot의 세부 설정을 알아보고 어떻게 변경할 수 있는지 알아봅니다. 하나의 Y축을 2개의 subplot이 공유하도록 shared_yaxes를 사용합니다. 각각의 subplot의 크기는 column_widths로 변경할 수 있습니다. 2개의 subplot사이의 거리는 horizontal_spacing으로 정합니다.\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(\n    rows=1, cols=2,\n    shared_yaxes=True,\n    horizontal_spacing=0.05,\n    column_widths=[0.3, 0.7]\n)\n\n\nfig.add_trace(go.Scatter(x=[1, 2, 3], y=[4, 5, 6], name=\"subplot 1\"),\n              row=1, col=1)\nfig.add_trace(go.Scatter(x=[10, 20, 30], y=[10, 20, 30], name=\"subplot 2\"),\n              row=1, col=2)\n\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230913.html#참고",
    "href": "blog/posts/2023/20230913.html#참고",
    "title": "Plotly Subpolt 만들기",
    "section": "",
    "text": "https://chancoding.tistory.com/229"
  },
  {
    "objectID": "blog/posts/2023/20231008.html",
    "href": "blog/posts/2023/20231008.html",
    "title": "Plotly line, shape 그리기",
    "section": "",
    "text": "Ploty로 line과 shape를 그리는 방법을 정리합니다.\n\n\nadd_shape함수로 line을 그리는 코드입니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\n# Create scatter trace of text labels\nfig.add_trace(go.Scatter(\n    x=[6, 6, 6],\n    y=[1, 3, 5],\n    text=[\"Line\",\n          \"Dashed Line\",\n          \"Dotted Line\"],\n    mode=\"text\",\n))\n\n# Add shapes\nfig.add_shape(type=\"line\",\n    x0=1, y0=1, x1=5, y1=1,\n    line=dict(color=\"RoyalBlue\",width=3)\n)\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=3, x1=5, y1=3,\n    line=dict(\n        color=\"LightSeaGreen\",\n        width=4,\n        dash=\"dashdot\",\n    )\n)\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=5, x1=5, y1=5,\n    line=dict(\n        color=\"MediumPurple\",\n        width=4,\n        dash=\"dot\",\n    )\n)\n\n# Set axes ranges\nfig.update_xaxes(range=[0, 8])\nfig.update_yaxes(range=[0, 6])\n\nfig.show()\n\n\n                                                \n\n\nline은 add_shape함수를 사용합니다. 라인의 스타일은 line변수에 딕셔너리 형식으로 정보를 전달합니다. 딕셔너리의 dash는 라인의 형태를 결정하고 dashdot, dot, line으로 설정할 수 있습니다.\n\n\n\nadd_shape함수로 직사각형을 그리는 코드입니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=[1.5, 4.5],\n    y=[0.75, 0.75],\n    text=[\"Unfilled Rectangle\", \"Filled Rectangle\"],\n    mode=\"text\",\n))\n\n# Set axes properties\nfig.update_xaxes(range=[0, 7], showgrid=False)\nfig.update_yaxes(range=[0, 3.5])\n\n# Add shapes\nfig.add_shape(type=\"rect\",\n    x0=1, y0=1, x1=2, y1=3,\n    line=dict(color=\"RoyalBlue\"),\n)\nfig.add_shape(type=\"rect\",\n    x0=3, y0=1, x1=6, y1=2,\n    line=dict(\n        color=\"RoyalBlue\",\n        width=2,\n    ),\n    fillcolor=\"LightSkyBlue\",\n)\nfig.update_shapes(dict(xref='x', yref='y'))\nfig.show()\n\n\n                                                \n\n\n이번엔 add_shape함수에 type으로 전달하는 정보를 rect로 전달해서 직사각형을 만들었습니다. 내부를 색으로 채울때는 fillcolor를 사용했습니다.\n\n\n\n차트에 라인을 이용하여 원하는 위치를 지정하는 경우 투명도를 조정해서 차트의 정보를 유지하면 라인을 그릴 수 있습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=1, x1=5, y1=1,\n    opacity=0.5,\n    line=dict(\n        color=\"MediumPurple\",\n        width=4,\n        dash=\"dot\",\n    )\n)\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=2, x1=5, y1=2,\n    opacity=0.7,\n    line=dict(\n        color=\"MediumPurple\",\n        width=4,\n        dash=\"dot\",\n    )\n)\n\n# Set axes ranges\nfig.update_xaxes(range=[0, 6])\nfig.update_yaxes(range=[0, 3])\n\nfig.show()\n\n\n                                                \n\n\nadd_shape함수에 opacity를 추가로 전달합니다. opacity가 1인 경우 투명도가 없이 표시되며 opacity가 0인 경우 완전히 투명합니다."
  },
  {
    "objectID": "blog/posts/2023/20231008.html#line-그리는-방법",
    "href": "blog/posts/2023/20231008.html#line-그리는-방법",
    "title": "Plotly line, shape 그리기",
    "section": "",
    "text": "add_shape함수로 line을 그리는 코드입니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\n# Create scatter trace of text labels\nfig.add_trace(go.Scatter(\n    x=[6, 6, 6],\n    y=[1, 3, 5],\n    text=[\"Line\",\n          \"Dashed Line\",\n          \"Dotted Line\"],\n    mode=\"text\",\n))\n\n# Add shapes\nfig.add_shape(type=\"line\",\n    x0=1, y0=1, x1=5, y1=1,\n    line=dict(color=\"RoyalBlue\",width=3)\n)\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=3, x1=5, y1=3,\n    line=dict(\n        color=\"LightSeaGreen\",\n        width=4,\n        dash=\"dashdot\",\n    )\n)\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=5, x1=5, y1=5,\n    line=dict(\n        color=\"MediumPurple\",\n        width=4,\n        dash=\"dot\",\n    )\n)\n\n# Set axes ranges\nfig.update_xaxes(range=[0, 8])\nfig.update_yaxes(range=[0, 6])\n\nfig.show()\n\n\n                                                \n\n\nline은 add_shape함수를 사용합니다. 라인의 스타일은 line변수에 딕셔너리 형식으로 정보를 전달합니다. 딕셔너리의 dash는 라인의 형태를 결정하고 dashdot, dot, line으로 설정할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231008.html#직사각형을-그리는-방법",
    "href": "blog/posts/2023/20231008.html#직사각형을-그리는-방법",
    "title": "Plotly line, shape 그리기",
    "section": "",
    "text": "add_shape함수로 직사각형을 그리는 코드입니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=[1.5, 4.5],\n    y=[0.75, 0.75],\n    text=[\"Unfilled Rectangle\", \"Filled Rectangle\"],\n    mode=\"text\",\n))\n\n# Set axes properties\nfig.update_xaxes(range=[0, 7], showgrid=False)\nfig.update_yaxes(range=[0, 3.5])\n\n# Add shapes\nfig.add_shape(type=\"rect\",\n    x0=1, y0=1, x1=2, y1=3,\n    line=dict(color=\"RoyalBlue\"),\n)\nfig.add_shape(type=\"rect\",\n    x0=3, y0=1, x1=6, y1=2,\n    line=dict(\n        color=\"RoyalBlue\",\n        width=2,\n    ),\n    fillcolor=\"LightSkyBlue\",\n)\nfig.update_shapes(dict(xref='x', yref='y'))\nfig.show()\n\n\n                                                \n\n\n이번엔 add_shape함수에 type으로 전달하는 정보를 rect로 전달해서 직사각형을 만들었습니다. 내부를 색으로 채울때는 fillcolor를 사용했습니다."
  },
  {
    "objectID": "blog/posts/2023/20231008.html#투명도-조절하기",
    "href": "blog/posts/2023/20231008.html#투명도-조절하기",
    "title": "Plotly line, shape 그리기",
    "section": "",
    "text": "차트에 라인을 이용하여 원하는 위치를 지정하는 경우 투명도를 조정해서 차트의 정보를 유지하면 라인을 그릴 수 있습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=1, x1=5, y1=1,\n    opacity=0.5,\n    line=dict(\n        color=\"MediumPurple\",\n        width=4,\n        dash=\"dot\",\n    )\n)\n\nfig.add_shape(type=\"line\",\n    x0=1, y0=2, x1=5, y1=2,\n    opacity=0.7,\n    line=dict(\n        color=\"MediumPurple\",\n        width=4,\n        dash=\"dot\",\n    )\n)\n\n# Set axes ranges\nfig.update_xaxes(range=[0, 6])\nfig.update_yaxes(range=[0, 3])\n\nfig.show()\n\n\n                                                \n\n\nadd_shape함수에 opacity를 추가로 전달합니다. opacity가 1인 경우 투명도가 없이 표시되며 opacity가 0인 경우 완전히 투명합니다."
  },
  {
    "objectID": "blog/posts/2023/20231129.html",
    "href": "blog/posts/2023/20231129.html",
    "title": "Dataframe을 Dict로 생성 및 변환",
    "section": "",
    "text": "파이썬 딕셔너리 데이터로 Dataframe을 생성하는 방법을 정리합니다.\n\ndata = {\n  \"A\" : [1,2,3],\n  \"B\" : [4,5,6],\n  \"C\" : [7,8,9]\n}\ndata\n\n{'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n\n\n딕셔너리 데이터를 데이터프레임으로 변경하기 위해서 from_dict를 사용합니다.\n\nimport pandas as pd\ndf = pd.DataFrame.from_dict(data)\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n4\n7\n\n\n1\n2\n5\n8\n\n\n2\n3\n6\n9"
  },
  {
    "objectID": "blog/posts/2023/20231129.html#dict-형식",
    "href": "blog/posts/2023/20231129.html#dict-형식",
    "title": "Dataframe을 Dict로 생성 및 변환",
    "section": "dict 형식",
    "text": "dict 형식\n변환 형식은 orient에 전달되고 기본값은 dict 형식입니다. index가 추가되는 {column -&gt; {index-&gt;value}}와 같은 형식을 갖습니다.\n\ndict_from_dataframe = df.to_dict(orient='dict')\ndict_from_dataframe\n\n{'A': {0: 1, 1: 2, 2: 3}, 'B': {0: 4, 1: 5, 2: 6}, 'C': {0: 7, 1: 8, 2: 9}}"
  },
  {
    "objectID": "blog/posts/2023/20231129.html#list-형식",
    "href": "blog/posts/2023/20231129.html#list-형식",
    "title": "Dataframe을 Dict로 생성 및 변환",
    "section": "list 형식",
    "text": "list 형식\nlist 형식은 {column -&gt; [value]}와 같은 형식을 갖습니다. 일반적으로 딕셔너리에 index를 사용하지 않기 때문에 list형식으로 표현하는 것이 익숙합니다.\n\ndict_from_dataframe = df.to_dict(orient='list')\ndict_from_dataframe\n\n{'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}"
  },
  {
    "objectID": "blog/posts/2023/20231129.html#records-형식",
    "href": "blog/posts/2023/20231129.html#records-형식",
    "title": "Dataframe을 Dict로 생성 및 변환",
    "section": "records 형식",
    "text": "records 형식\nrecords 형식은 [{column-&gt;value}, ... , {column-&gt;value}]와 같은 형식을 갖습니다. 각각의 열을 리스트로 표현하기 때문에 데이터베이스의 레코드와 비슷합니다.\n\ndict_from_dataframe = df.to_dict(orient='records')\ndict_from_dataframe\n\n[{'A': 1, 'B': 4, 'C': 7}, {'A': 2, 'B': 5, 'C': 8}, {'A': 3, 'B': 6, 'C': 9}]"
  },
  {
    "objectID": "blog/posts/2023/20231120.html",
    "href": "blog/posts/2023/20231120.html",
    "title": "wsl 이미지 저장 위치 변경 및 백업",
    "section": "",
    "text": "WSL을 사용할 때 필요한 정보를 정리합니다.\n\n\n[move-wsl] 깃 저장소에서 제공하는 파워쉘 스크립트를 이용하면 쉽게 wsl 이미지 위치를 변경할 수 있습니다. 스크립트로 이동 시 주의해야할 점은 Docker WSL이 정지된 상태인지 확인하는 것이라고 합니다. 정지되지 않은 상태에서 스크립트가 실행되는 경우 crash로 fatory default로 리셋될 수 있다고 합니다. (너무 무섭네요….)\n\n\n\n우선 설치된 모든 배포판을 확인합니다. 각 이미지의 상태도 확인할 수 있습니다.\nwsl -l -v\n  NAME                   STATE           VERSION\n* Ubuntu-20.04           Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n배포판에 특정 유저이름으로 접속하는 경우 유저이름을 추가할 수 있습니다.\nwsl -u &lt;유저이름&gt;\n\n\nwsl --export &lt;배포판 이름&gt; &lt;파일명&gt;\n\n\n\n실행하면 설치위치에 ext4.vhdx 파일이 생성됩니다.\nwsl --import &lt;패포판 이름&gt; &lt;설치할 위치&gt; &lt;가져올 배포판 파일명&gt;"
  },
  {
    "objectID": "blog/posts/2023/20231120.html#wsl-이미지-저장-위치-변경하기",
    "href": "blog/posts/2023/20231120.html#wsl-이미지-저장-위치-변경하기",
    "title": "wsl 이미지 저장 위치 변경 및 백업",
    "section": "",
    "text": "[move-wsl] 깃 저장소에서 제공하는 파워쉘 스크립트를 이용하면 쉽게 wsl 이미지 위치를 변경할 수 있습니다. 스크립트로 이동 시 주의해야할 점은 Docker WSL이 정지된 상태인지 확인하는 것이라고 합니다. 정지되지 않은 상태에서 스크립트가 실행되는 경우 crash로 fatory default로 리셋될 수 있다고 합니다. (너무 무섭네요….)"
  },
  {
    "objectID": "blog/posts/2023/20231120.html#wsl-이미지-백업하기",
    "href": "blog/posts/2023/20231120.html#wsl-이미지-백업하기",
    "title": "wsl 이미지 저장 위치 변경 및 백업",
    "section": "",
    "text": "우선 설치된 모든 배포판을 확인합니다. 각 이미지의 상태도 확인할 수 있습니다.\nwsl -l -v\n  NAME                   STATE           VERSION\n* Ubuntu-20.04           Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n배포판에 특정 유저이름으로 접속하는 경우 유저이름을 추가할 수 있습니다.\nwsl -u &lt;유저이름&gt;\n\n\nwsl --export &lt;배포판 이름&gt; &lt;파일명&gt;\n\n\n\n실행하면 설치위치에 ext4.vhdx 파일이 생성됩니다.\nwsl --import &lt;패포판 이름&gt; &lt;설치할 위치&gt; &lt;가져올 배포판 파일명&gt;"
  },
  {
    "objectID": "blog/posts/2023/20230918.html",
    "href": "blog/posts/2023/20230918.html",
    "title": "Plotly Animation 만들기",
    "section": "",
    "text": "Plotly Bubble chart animation 만들기\nBubble차트를 animation으로 표현하는 방법을 정리합니다. 데이터는 gapminder를 사용합니다.\n\nimport plotly.express as px\ndf = px.data.gapminder()\ndf.sample(5)\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n379\nCroatia\nEurope\n1987\n71.520\n4484310\n13822.583940\nHRV\n191\n\n\n1222\nPhilippines\nAsia\n2002\n70.303\n82995088\n2650.921068\nPHL\n608\n\n\n1119\nNiger\nAfrica\n1967\n40.118\n4534062\n1054.384891\nNER\n562\n\n\n1662\nWest Bank and Gaza\nAsia\n1982\n64.406\n1425876\n4336.032082\nPSE\n275\n\n\n49\nArgentina\nAmericas\n1957\n64.399\n19610538\n6856.856212\nARG\n32\n\n\n\n\n\n\n\n데이터를 Animation으로 보여주기 위해서 데이터프레임의 정보를 확인합니다.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 8 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   country    1704 non-null   object \n 1   continent  1704 non-null   object \n 2   year       1704 non-null   int64  \n 3   lifeExp    1704 non-null   float64\n 4   pop        1704 non-null   int64  \n 5   gdpPercap  1704 non-null   float64\n 6   iso_alpha  1704 non-null   object \n 7   iso_num    1704 non-null   int64  \ndtypes: float64(2), int64(3), object(3)\nmemory usage: 106.6+ KB\n\n\n데이터프레임의 year 컬럼을 이용해서 연도별 흐름을 animation으로 표현할 수 있을 것 같습니다. 좀 더 자세히 year컬럼을 확인합니다.\n\ndisplay(len(df['year'].unique()))\nfig = px.histogram(df, x='year', nbins = 60)\nfig.show()\n\n12\n\n\n\n                                                \n\n\n데이터프레임의 year컬럼은 총 12개의 unique value를 갖고 있습니다. 히스토그램으로 표시하면 5년 단위로 값을 갖는 것을 알 수 있습니다. 이제 year 정보를 이용해서 animation을 구성합니다.\n\nfig = px.scatter(df, x='gdpPercap', y='lifeExp', color='continent', size='pop',\n                hover_name='country', log_x=True, animation_frame='year',\n                 animation_group='country', range_x=[100, 70000], range_y=[25,90])\nfig.show()\n\n\n                                                \n\n\n시간의 흐름에 따라서 x축과 y축에 표시되는 데이터의 위치가 변경됩니다. 데이터가 최초와 최종 animation단계에서 모두 그래프에 표시될 수 있도록 range_x와 range_y를 이용하여 축의 범위를 수정합니다.\n\nfig = px.bar(df, x=\"continent\", y=\"pop\", color=\"continent\", hover_name='country',\n  animation_frame=\"year\", animation_group=\"country\", range_y=[0,4000000000])\nfig.show()\n\n\n                                                \n\n\n위와 같이 Bar차트도 동일하게 animation_frame과 animation_group을 설정하여 시간의 흐름에 따른 인구 변화를 나타낼 수 있습니다. hover_name을 country로 설정해서 animation_group의 country 정보를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231203.html",
    "href": "blog/posts/2023/20231203.html",
    "title": "vite를 이용한 react 개발환경 세팅",
    "section": "",
    "text": "npm은 Node Package Manager의 약자로, JavaScript 및 Node.js 프로젝트에서 패키지를 관리하는 도구입니다. npm은 JavaScript 패키지의 설치, 관리, 업데이트 및 삭제를 쉽게 수행할 수 있도록 도와주며, 프로젝트의 의존성 관리에 중요한 역할을 합니다.\n그럼 Node는 뭔가요?\nNode.js(노드 제이에스)는 JavaScript 런타임 환경으로, 서버 측 프로그래밍을 위해 설계되었습니다. 기존에는 브라우저에서만 실행되던 JavaScript를 서버 사이드에서도 실행할 수 있게끔 하는 환경을 제공합니다.\n\n\napt-get명령으로 nodejs와 npm을 설치하고 버전을 확인합니다.\nsudo apt-get update\nsudo apt-get install nodejs npm\nnode의 버전은 12.22.09입니다.\nnodejs -v\nv12.22.9\nnpm 버전은 10.2.3입니다.\nnpm -v\n10.2.3\nnpm이 설치되었으면 node 버전을 최신으로 업데이트 합니다. n이라는 모듈은 node의 버전을 관리해줍니다. -g 옵션을 사용해서 gloal하게 설치합니다.\nsudo npm install -g n\nn -v\nv9.2.0\n이제 n을 사용해서 node를 lts(Long Term Support) version으로 업데이트합니다\nsudo n lts\ncopying : node/20.10.0\ninstalled : v20.10.0 (with npm 10.2.3)\nv20.10.0이 설치 되었습니다.\n\n\n\n이제 react환경을 구성할 프로젝트 폴더를 생성합니다. react 환경을 구성할 프로젝트 폴더에서 아래의 명령을 수행합니다.\n자신이 생성할 프로젝트 명과 사용할 개발환경을 선택하면 프로젝트 폴더가 생성되고 프로젝트 구성을 위해 실행할 명령을 가이드 해줍니다.\nnpm create vite\nNeed to install the following packages:\ncreate-vite@5.0.0\nOk to proceed? (y) y\n✔ Project name: … nwitter-reloaded\n✔ Select a framework: › React\n? Select a variant: › - Use arrow-keys. Return to submit.\n    TypeScript\n❯   TypeScript + SWC\n    JavaScript\n    JavaScript + SWC\n\nDone. Now run:\n\n  cd nwitter-reloaded\n  npm install\n  npm run dev\n이제 명령을 하나씩 수행합니다. cd 명령으로 프로젝트로 이동 후 npm install명령을 실행하고 프로젝트에 필요한 파일이 설치 완료되면 npm run dev를 실행합니다. 실행결과로 표시된 링크로 연결하면 react개발환경이 구축된 것을 확인할 수 있습니다.\n  VITE v5.0.4  ready in 447 ms\n\n  ➜  Local:   http://localhost:5173/\n  ➜  Network: use --host to expose\n  ➜  press h + enter to show help"
  },
  {
    "objectID": "blog/posts/2023/20231203.html#node.js와-npm-설치하기",
    "href": "blog/posts/2023/20231203.html#node.js와-npm-설치하기",
    "title": "vite를 이용한 react 개발환경 세팅",
    "section": "",
    "text": "apt-get명령으로 nodejs와 npm을 설치하고 버전을 확인합니다.\nsudo apt-get update\nsudo apt-get install nodejs npm\nnode의 버전은 12.22.09입니다.\nnodejs -v\nv12.22.9\nnpm 버전은 10.2.3입니다.\nnpm -v\n10.2.3\nnpm이 설치되었으면 node 버전을 최신으로 업데이트 합니다. n이라는 모듈은 node의 버전을 관리해줍니다. -g 옵션을 사용해서 gloal하게 설치합니다.\nsudo npm install -g n\nn -v\nv9.2.0\n이제 n을 사용해서 node를 lts(Long Term Support) version으로 업데이트합니다\nsudo n lts\ncopying : node/20.10.0\ninstalled : v20.10.0 (with npm 10.2.3)\nv20.10.0이 설치 되었습니다."
  },
  {
    "objectID": "blog/posts/2023/20231203.html#vite를-이용한-react-환경-install",
    "href": "blog/posts/2023/20231203.html#vite를-이용한-react-환경-install",
    "title": "vite를 이용한 react 개발환경 세팅",
    "section": "",
    "text": "이제 react환경을 구성할 프로젝트 폴더를 생성합니다. react 환경을 구성할 프로젝트 폴더에서 아래의 명령을 수행합니다.\n자신이 생성할 프로젝트 명과 사용할 개발환경을 선택하면 프로젝트 폴더가 생성되고 프로젝트 구성을 위해 실행할 명령을 가이드 해줍니다.\nnpm create vite\nNeed to install the following packages:\ncreate-vite@5.0.0\nOk to proceed? (y) y\n✔ Project name: … nwitter-reloaded\n✔ Select a framework: › React\n? Select a variant: › - Use arrow-keys. Return to submit.\n    TypeScript\n❯   TypeScript + SWC\n    JavaScript\n    JavaScript + SWC\n\nDone. Now run:\n\n  cd nwitter-reloaded\n  npm install\n  npm run dev\n이제 명령을 하나씩 수행합니다. cd 명령으로 프로젝트로 이동 후 npm install명령을 실행하고 프로젝트에 필요한 파일이 설치 완료되면 npm run dev를 실행합니다. 실행결과로 표시된 링크로 연결하면 react개발환경이 구축된 것을 확인할 수 있습니다.\n  VITE v5.0.4  ready in 447 ms\n\n  ➜  Local:   http://localhost:5173/\n  ➜  Network: use --host to expose\n  ➜  press h + enter to show help"
  },
  {
    "objectID": "blog/posts/2023/20231206.html",
    "href": "blog/posts/2023/20231206.html",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "MySQL DB를 연습하기 위해서 도커로 MySQL 이미지를 다운로드 및 실행합니다. 우선 MySQL이미지를 도커 허브에서 찾습니다.\n\nmysql 이미지 이름을 다운로드 할 수 있습니다. DB 볼륨을 로컬컴퓨터에서 확인하고 파일을 관리하기 위한 볼륨을 마운트하기 위해서 docker-compose.yml파일을 만들어서 관리합니다.\n\n\ndocker-compose.yml\n\nversion: '3'\nservices:\n    mysqldb:\n      container_name: mysqldb\n      image: mysql\n      ports:\n        - \"3306:3306\"\n      volumes:\n        - ./mysqldb:/var/lib/mysql\n      env_file: .env\n      environment:\n        - MYSQL_ROOT_PASSWORD=1234\n        - TZ=Asia/Seoul\n      restart: always\n\ndocker-compose를 아래의 명령으로 실행합니다.\ndocker-compose up -d\nDB를 편리하게 사용하기 위해서 DBeaver를 설치합니다. 설치방법은 mysql설치를 확인합니다.\nDBeaver를 이용해서 설치한 DB에 연결합니다. 데이터베이스 &gt; 새 데이터베이스 연결을 선택해서 DB에 연결합니다. 연결이 완료되었으니 이제 docker의 데이터베이스에 접속합니다.\nsudo docker exec -it &lt;docker서비스명&gt;  bash\nMySQL을 container생성을 위해 사용한 root 계정의 암호를 입력하여 mysql에 접속합니다.\nmysql -u root -p\n\n\n데이터베이스는 내부에 테이블을 갖습니다. 테이블은 MySQL의 가장 작은 데이터베이스 단위 입니다. 테이블은 엑설처럼 데이터를 나타내는 특정 유형의 테이터를 나타내는 열과 각 데이터 레코드를 나타내는 행으로 구성됩니다. 각 열은 데이터의 유형과 속성정보를 갖습니다.\n\n\n\n기본으로 생성된 database를 확인합니다.\nSHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n+--------------------+\n4 rows in set (0.00 sec)\n\n\n\nDB연습을 위한 데이터베이스를 생성합니다.\nCREATE DATABASE test_db;\nQuery OK, 1 row affected (0.24 sec)\n\n\n\n유저이름은 test_id, 암호는 test1234를 갖는 유저를 생성합니다. %를 사용해서 유저는 모든 클라이언트에서 접속 가능하도록 설정합니다.\nCREATE USER 'test_id'@'%' IDENTIFIED BY 'test1234';\n유저가 사용할 수 있는 데이터베이스와 권한을 설정합니다.\nGRANT ALL PREVILEGES ON test_db.* TO 'test_id'@'%';\ntest_db의 모든 테이블에 권한을 부여하기 위해 test_db.*을 사용했습니다. 이제 새로 생성한 유저로 접속해서 test_db를 사용할 수 있는 지 확인합니다.\n\n\n\nmysql -u test_id -p\nmysql&gt; SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| performance_schema |\n| test_db            |\n+--------------------+\n3 rows in set (0.01 sec)\n새로 생성한 사용자로 접속 시 새로 생성된 database를 확인할 수 있습니다.\n\n\n\n현재 선택된 데이터베이스가 있는 지 확인합니다.\nSELECT DATABASE();\n+------------+\n| database() |\n+------------+\n| NULL       |\n+------------+\n1 row in set (0.00 sec)\n아직 선택된 데이터베이스가 없습니다.\nUSE test_db;\nSELECT DATABASE();\n+------------+\n| DATABASE() |\n+------------+\n| test_db    |\n+------------+\n이제 데이터베이스가 변경되었으며 현재 사용중인 데이터베이스는 test_db로 표시됩니다.\n\n\n\n데이터 베이스의 TABLE을 확인합니다. 생성된 테이블이 없는 상태입니다.\nSHOW TABLES;\nEmpty set (0.00 sec)\n\n\n\n테이블을 생성하고 생성된 테이블 정보를 확인합니다.\nCREATE TABLE test_table (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  name VARCHAR(100) NOT NULL,\n  phone VARCHAR(50)\n);\n생성된 테이블 정보는 describe으로 확인할 수 있습니다.\ndescribe test_table;\n+-------+--------------+------+-----+---------+----------------+\n| Field | Type         | Null | Key | Default | Extra          |\n+-------+--------------+------+-----+---------+----------------+\n| id    | int          | NO   | PRI | NULL    | auto_increment |\n| name  | varchar(100) | NO   |     | NULL    |                |\n| phone | varchar(50)  | YES  |     | NULL    |                |\n+-------+--------------+------+-----+---------+----------------+\n3 rows in set (0.00 sec)\n3개의 열이 있는 테이블에 대한 정보를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스-구조",
    "href": "blog/posts/2023/20231206.html#데이터베이스-구조",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "데이터베이스는 내부에 테이블을 갖습니다. 테이블은 MySQL의 가장 작은 데이터베이스 단위 입니다. 테이블은 엑설처럼 데이터를 나타내는 특정 유형의 테이터를 나타내는 열과 각 데이터 레코드를 나타내는 행으로 구성됩니다. 각 열은 데이터의 유형과 속성정보를 갖습니다."
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스-확인하기",
    "href": "blog/posts/2023/20231206.html#데이터베이스-확인하기",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "기본으로 생성된 database를 확인합니다.\nSHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n+--------------------+\n4 rows in set (0.00 sec)"
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스-생성",
    "href": "blog/posts/2023/20231206.html#데이터베이스-생성",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "DB연습을 위한 데이터베이스를 생성합니다.\nCREATE DATABASE test_db;\nQuery OK, 1 row affected (0.24 sec)"
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스-사용자-생성",
    "href": "blog/posts/2023/20231206.html#데이터베이스-사용자-생성",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "유저이름은 test_id, 암호는 test1234를 갖는 유저를 생성합니다. %를 사용해서 유저는 모든 클라이언트에서 접속 가능하도록 설정합니다.\nCREATE USER 'test_id'@'%' IDENTIFIED BY 'test1234';\n유저가 사용할 수 있는 데이터베이스와 권한을 설정합니다.\nGRANT ALL PREVILEGES ON test_db.* TO 'test_id'@'%';\ntest_db의 모든 테이블에 권한을 부여하기 위해 test_db.*을 사용했습니다. 이제 새로 생성한 유저로 접속해서 test_db를 사용할 수 있는 지 확인합니다."
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스-접속",
    "href": "blog/posts/2023/20231206.html#데이터베이스-접속",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "mysql -u test_id -p\nmysql&gt; SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| performance_schema |\n| test_db            |\n+--------------------+\n3 rows in set (0.01 sec)\n새로 생성한 사용자로 접속 시 새로 생성된 database를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스-선택-및-확인",
    "href": "blog/posts/2023/20231206.html#데이터베이스-선택-및-확인",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "현재 선택된 데이터베이스가 있는 지 확인합니다.\nSELECT DATABASE();\n+------------+\n| database() |\n+------------+\n| NULL       |\n+------------+\n1 row in set (0.00 sec)\n아직 선택된 데이터베이스가 없습니다.\nUSE test_db;\nSELECT DATABASE();\n+------------+\n| DATABASE() |\n+------------+\n| test_db    |\n+------------+\n이제 데이터베이스가 변경되었으며 현재 사용중인 데이터베이스는 test_db로 표시됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231206.html#데이터베이스의-테이블-확인하기",
    "href": "blog/posts/2023/20231206.html#데이터베이스의-테이블-확인하기",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "데이터 베이스의 TABLE을 확인합니다. 생성된 테이블이 없는 상태입니다.\nSHOW TABLES;\nEmpty set (0.00 sec)"
  },
  {
    "objectID": "blog/posts/2023/20231206.html#테이블-생성-및-확인",
    "href": "blog/posts/2023/20231206.html#테이블-생성-및-확인",
    "title": "MySQL 도커로 설치하고 테스트 DB 사용하기",
    "section": "",
    "text": "테이블을 생성하고 생성된 테이블 정보를 확인합니다.\nCREATE TABLE test_table (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  name VARCHAR(100) NOT NULL,\n  phone VARCHAR(50)\n);\n생성된 테이블 정보는 describe으로 확인할 수 있습니다.\ndescribe test_table;\n+-------+--------------+------+-----+---------+----------------+\n| Field | Type         | Null | Key | Default | Extra          |\n+-------+--------------+------+-----+---------+----------------+\n| id    | int          | NO   | PRI | NULL    | auto_increment |\n| name  | varchar(100) | NO   |     | NULL    |                |\n| phone | varchar(50)  | YES  |     | NULL    |                |\n+-------+--------------+------+-----+---------+----------------+\n3 rows in set (0.00 sec)\n3개의 열이 있는 테이블에 대한 정보를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231002.html",
    "href": "blog/posts/2023/20231002.html",
    "title": "Plotly Hover 설정하기",
    "section": "",
    "text": "Plotly에서는 데이터의 정보를 쉽게 확인할 수 있는 Hover 레이블을 제공합니다. Hover 레이블은 정보를 확인할 데이터의 위치로 마우스를 이동하면 정보를 표시하는 기능입니다.\n\nimport plotly.express as px\n\ndf = px.data.gapminder().query(\"continent=='Oceania'\")\n\nfig = px.line(df, x=\"year\", y=\"lifeExp\", color=\"country\", title=\"layout.hovermode='closest' (the default)\")\nfig.update_traces(mode=\"markers+lines\")\n\nfig.show()\n\n\n                                                \n\n\n테스트를위해서 line 차트를 생성합니다. Hover 레이블에 대한 설정이 없을 경우 layout.hovermode='closest으로 설정되고 가장 가까운 데이터를 Hover 레이블로 표시합니다.\n\n\n선택된 X축 또는 Y축에 해당하는 데이터를 함게 표시하는 Hover 레이블 모드를 정리합니다.\n\nimport plotly.express as px\n\ndf = px.data.gapminder().query(\"continent=='Oceania'\")\n\nfig = px.line(df, x=\"year\", y=\"lifeExp\", color=\"country\", title=\"layout.hovermode='x'\")\nfig.update_traces(mode=\"markers+lines\", hovertemplate=None)\nfig.update_layout(hovermode=\"x\")\n\nfig.show()\n\n\n                                                \n\n\nupdate_layout에 hovermode를 x로 정의하면 선택된 X축에 위치한 데이터 벙보를 호버 레이블로 표시합니다.\nx unified형식은 X, Y정보를 Hover 레이블에 추가합니다. 그리고 각 축의 값을 표시하기위한 점선도 함께 추가됩니다.\n\nimport plotly.express as px\n\ndf = px.data.gapminder().query(\"continent=='Oceania'\")\n\nfig = px.line(df, x=\"year\", y=\"lifeExp\", color=\"country\", title=\"layout.hovermode='x unified'\")\nfig.update_traces(mode=\"markers+lines\", hovertemplate=None)\nfig.update_layout(hovermode=\"x unified\")\n\nfig.show()\n\n\n                                                \n\n\n위의 실행결과를 확인하면 점선이 생성되는 것을 확인할 수 있습니다.\n\n\n\nHover 레이블에 표시할 데이터를 설정하는 방법을 정리합니다.\n\nimport plotly.express as px\n\ndf_2007 = px.data.gapminder().query(\"year==2007\")\ndf.head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n60\nAustralia\nOceania\n1952\n69.12\n8691212\n10039.59564\nAUS\n36\n\n\n61\nAustralia\nOceania\n1957\n70.33\n9712569\n10949.64959\nAUS\n36\n\n\n62\nAustralia\nOceania\n1962\n70.93\n10794968\n12217.22686\nAUS\n36\n\n\n63\nAustralia\nOceania\n1967\n71.10\n11872264\n14526.12465\nAUS\n36\n\n\n64\nAustralia\nOceania\n1972\n71.93\n13177000\n16788.62948\nAUS\n36\n\n\n\n\n\n\n\ngapminder데이터를 gdpPercap을 x축, lifeExp를 y축으로 설정하여 데이터를 표시합니다.\n\nfig = px.scatter(df_2007, x=\"gdpPercap\", y=\"lifeExp\", log_x=True,\n                 hover_name=\"country\",)\nfig.show()\n\n\n                                                \n\n\n위의 그래프에서 임의의 데이터의 위치로 마우스를 이동하면 기본적으로 그래프에 사용한 x축과 y축의 데이터인 gdpPercap과 lifeExp정보만 Hover 레이블에 표시됨을 알 수 있습니다.\n\nfig = px.scatter(df_2007, x=\"gdpPercap\", y=\"lifeExp\", log_x=True,\n                 hover_name=\"country\", hover_data=[\"continent\", \"pop\"])\n\nfig.show()\n\n\n                                                \n\n\n위의 차트에는 hover_data를 통해서 추가 정보를 확인할 컬럼명을 전달하였습니다. 이제 추가정보가 Hover 레이블에 표시됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231002.html#x축-y축-기준으로-hover-레이블-표시하기",
    "href": "blog/posts/2023/20231002.html#x축-y축-기준으로-hover-레이블-표시하기",
    "title": "Plotly Hover 설정하기",
    "section": "",
    "text": "선택된 X축 또는 Y축에 해당하는 데이터를 함게 표시하는 Hover 레이블 모드를 정리합니다.\n\nimport plotly.express as px\n\ndf = px.data.gapminder().query(\"continent=='Oceania'\")\n\nfig = px.line(df, x=\"year\", y=\"lifeExp\", color=\"country\", title=\"layout.hovermode='x'\")\nfig.update_traces(mode=\"markers+lines\", hovertemplate=None)\nfig.update_layout(hovermode=\"x\")\n\nfig.show()\n\n\n                                                \n\n\nupdate_layout에 hovermode를 x로 정의하면 선택된 X축에 위치한 데이터 벙보를 호버 레이블로 표시합니다.\nx unified형식은 X, Y정보를 Hover 레이블에 추가합니다. 그리고 각 축의 값을 표시하기위한 점선도 함께 추가됩니다.\n\nimport plotly.express as px\n\ndf = px.data.gapminder().query(\"continent=='Oceania'\")\n\nfig = px.line(df, x=\"year\", y=\"lifeExp\", color=\"country\", title=\"layout.hovermode='x unified'\")\nfig.update_traces(mode=\"markers+lines\", hovertemplate=None)\nfig.update_layout(hovermode=\"x unified\")\n\nfig.show()\n\n\n                                                \n\n\n위의 실행결과를 확인하면 점선이 생성되는 것을 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231002.html#hover-레이블에-표시할-데이터-설정하기",
    "href": "blog/posts/2023/20231002.html#hover-레이블에-표시할-데이터-설정하기",
    "title": "Plotly Hover 설정하기",
    "section": "",
    "text": "Hover 레이블에 표시할 데이터를 설정하는 방법을 정리합니다.\n\nimport plotly.express as px\n\ndf_2007 = px.data.gapminder().query(\"year==2007\")\ndf.head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n60\nAustralia\nOceania\n1952\n69.12\n8691212\n10039.59564\nAUS\n36\n\n\n61\nAustralia\nOceania\n1957\n70.33\n9712569\n10949.64959\nAUS\n36\n\n\n62\nAustralia\nOceania\n1962\n70.93\n10794968\n12217.22686\nAUS\n36\n\n\n63\nAustralia\nOceania\n1967\n71.10\n11872264\n14526.12465\nAUS\n36\n\n\n64\nAustralia\nOceania\n1972\n71.93\n13177000\n16788.62948\nAUS\n36\n\n\n\n\n\n\n\ngapminder데이터를 gdpPercap을 x축, lifeExp를 y축으로 설정하여 데이터를 표시합니다.\n\nfig = px.scatter(df_2007, x=\"gdpPercap\", y=\"lifeExp\", log_x=True,\n                 hover_name=\"country\",)\nfig.show()\n\n\n                                                \n\n\n위의 그래프에서 임의의 데이터의 위치로 마우스를 이동하면 기본적으로 그래프에 사용한 x축과 y축의 데이터인 gdpPercap과 lifeExp정보만 Hover 레이블에 표시됨을 알 수 있습니다.\n\nfig = px.scatter(df_2007, x=\"gdpPercap\", y=\"lifeExp\", log_x=True,\n                 hover_name=\"country\", hover_data=[\"continent\", \"pop\"])\n\nfig.show()\n\n\n                                                \n\n\n위의 차트에는 hover_data를 통해서 추가 정보를 확인할 컬럼명을 전달하였습니다. 이제 추가정보가 Hover 레이블에 표시됩니다."
  },
  {
    "objectID": "blog/posts/2024/20240103.html",
    "href": "blog/posts/2024/20240103.html",
    "title": "Javascript의 defer 속성은 왜 사용하는가?",
    "section": "",
    "text": "JavaScript를 활용할 때 웹 페이지의 로딩 속도와 상호작용을 최적화하는 것은 필수적입니다. 이와 관련하여 ‘defer’ 속성은 중요한 역할을 합니다. 본문에서는 JavaScript에서 ‘defer’ 속성을 사용하는 이유와 간단한 예제 코드를 소개하겠습니다.\n\n\ndefer는 &lt;script&gt; 태그에 사용되는 속성입니다. 이 속성은 HTML 파싱 동안 외부 스크립트를 비동기적으로 로드한 후, HTML 파싱이 완료된 후에 스크립트를 실행하도록 합니다. 이 속성은 사용하면 페이지 로딩 시간을 최적화할 수 있고 스크립트의 순차적 실행을 보장합니다 HTML 파싱이 완료된 후 script가 동작하기 때문에 DOM()이 완전히 구성된 상태에서 script가 실행되는 장점이 있습니다.\n\n\n\n웹 페이지 로딩 순서를 사용자가 웹 페이지에 접근하면 아래의 과정이 수행됩니다.\n\n웹 페이지 로딩 시작 사용자가 웹 페이지에 접근하면 로딩 과정이 시작됩니다.\nHTML 파싱 브라우저는 HTML 문서의 파싱을 시작합니다. 이 단계에서 문서의 구조가 분석되며, 이는 페이지의 렌더링 기초를 형성합니다.\nDefer 속성을 가진 Script 태그 : HTML 파싱 중 defer 속성을 갖는 script 태그를 만나면 비동기적으로 다운로드됩니다.\n해당 스크립트는 HTML 파싱을 방해하지 않고 비동기적으로 다운로드됩니다. 이는 웹 페이지의 성능을 향상시키는 중요한 단계입니다.\n스크립트 다운로드와 동시에 HTML 문서의 파싱이 계속됩니다. 이 과정은 페이지 로딩의 효율성을 높입니다.\nHTML 문서의 파싱이 완료되며 이제 스크립트 실행이 가능합니다.\n스크립트 실행 : 모든 HTML 파싱이 완료된 후, defer로 표시된 스크립트들이 순서대로 실행됩니다. 이 단계는 스크립트의 올바른 작동을 보장합니다.\n웹 페이지 로딩 완료 : 모든 스크립트가 실행되고, 페이지 로딩이 완료됩니다.\n\n플로우 차트로 간단히 정리하면 아래와 같습니다.\n\n\n\n\n\n\n\n\nHTML과 Javascript 코드를 통해서 defer 속성의 동작을 확인합니다. HTML코드는 defer속성을 사용하여 example.js 스크립트를 사용합니다.\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Defer Example&lt;/title&gt;\n    &lt;script src=\"example.js\" defer&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, world!&lt;/h1&gt;\n    &lt;p id=\"demo\"&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nHTML 코드에서 사용하는 example.js는 아래와 같이 HTML문서의 demo ID 정보를 얻어야 정상적으로 동작합니다. head에서 실행될 때는 HTML문서 정보가 없기 때문에 문제가 발생하지만 defer속성으로 스크립트가 실행되는 시간은 HTML 코드가 모두 로드된 후에 사용됩니다.\n// example.js\n\n// 이 스크립트는 페이지 로드 후에 실행됩니다.\n// HTML 문서의 내용을 조작하거나 업데이트할 수 있습니다.\n\n// DOM 요소를 가져와서 내용을 변경하는 함수\nfunction updateContent() {\n    var demoElement = document.getElementById(\"demo\");\n    demoElement.innerHTML = \"This content was added using JavaScript!\";\n}\n\n// 위에서 정의한 함수를 호출\nupdateContent();\nHTML 코드에서는 id demo의 정보가 없기 때문에 defer속성없이 스크립트를 실행하는 경우 스크립트 오류가 발생합니다.\n하지만 defer속성을 사용했기 때문에 DOM이 구성된 후에 id 가 demo 문서 요소에 접근해 아래과 같이 정보가 추가합니다."
  },
  {
    "objectID": "blog/posts/2024/20240103.html#defer-속성이란",
    "href": "blog/posts/2024/20240103.html#defer-속성이란",
    "title": "Javascript의 defer 속성은 왜 사용하는가?",
    "section": "",
    "text": "defer는 &lt;script&gt; 태그에 사용되는 속성입니다. 이 속성은 HTML 파싱 동안 외부 스크립트를 비동기적으로 로드한 후, HTML 파싱이 완료된 후에 스크립트를 실행하도록 합니다. 이 속성은 사용하면 페이지 로딩 시간을 최적화할 수 있고 스크립트의 순차적 실행을 보장합니다 HTML 파싱이 완료된 후 script가 동작하기 때문에 DOM()이 완전히 구성된 상태에서 script가 실행되는 장점이 있습니다."
  },
  {
    "objectID": "blog/posts/2024/20240103.html#웹페이지-로딩-순서",
    "href": "blog/posts/2024/20240103.html#웹페이지-로딩-순서",
    "title": "Javascript의 defer 속성은 왜 사용하는가?",
    "section": "",
    "text": "웹 페이지 로딩 순서를 사용자가 웹 페이지에 접근하면 아래의 과정이 수행됩니다.\n\n웹 페이지 로딩 시작 사용자가 웹 페이지에 접근하면 로딩 과정이 시작됩니다.\nHTML 파싱 브라우저는 HTML 문서의 파싱을 시작합니다. 이 단계에서 문서의 구조가 분석되며, 이는 페이지의 렌더링 기초를 형성합니다.\nDefer 속성을 가진 Script 태그 : HTML 파싱 중 defer 속성을 갖는 script 태그를 만나면 비동기적으로 다운로드됩니다.\n해당 스크립트는 HTML 파싱을 방해하지 않고 비동기적으로 다운로드됩니다. 이는 웹 페이지의 성능을 향상시키는 중요한 단계입니다.\n스크립트 다운로드와 동시에 HTML 문서의 파싱이 계속됩니다. 이 과정은 페이지 로딩의 효율성을 높입니다.\nHTML 문서의 파싱이 완료되며 이제 스크립트 실행이 가능합니다.\n스크립트 실행 : 모든 HTML 파싱이 완료된 후, defer로 표시된 스크립트들이 순서대로 실행됩니다. 이 단계는 스크립트의 올바른 작동을 보장합니다.\n웹 페이지 로딩 완료 : 모든 스크립트가 실행되고, 페이지 로딩이 완료됩니다.\n\n플로우 차트로 간단히 정리하면 아래와 같습니다."
  },
  {
    "objectID": "blog/posts/2024/20240103.html#예제-코드로-이해하기",
    "href": "blog/posts/2024/20240103.html#예제-코드로-이해하기",
    "title": "Javascript의 defer 속성은 왜 사용하는가?",
    "section": "",
    "text": "HTML과 Javascript 코드를 통해서 defer 속성의 동작을 확인합니다. HTML코드는 defer속성을 사용하여 example.js 스크립트를 사용합니다.\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Defer Example&lt;/title&gt;\n    &lt;script src=\"example.js\" defer&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, world!&lt;/h1&gt;\n    &lt;p id=\"demo\"&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nHTML 코드에서 사용하는 example.js는 아래와 같이 HTML문서의 demo ID 정보를 얻어야 정상적으로 동작합니다. head에서 실행될 때는 HTML문서 정보가 없기 때문에 문제가 발생하지만 defer속성으로 스크립트가 실행되는 시간은 HTML 코드가 모두 로드된 후에 사용됩니다.\n// example.js\n\n// 이 스크립트는 페이지 로드 후에 실행됩니다.\n// HTML 문서의 내용을 조작하거나 업데이트할 수 있습니다.\n\n// DOM 요소를 가져와서 내용을 변경하는 함수\nfunction updateContent() {\n    var demoElement = document.getElementById(\"demo\");\n    demoElement.innerHTML = \"This content was added using JavaScript!\";\n}\n\n// 위에서 정의한 함수를 호출\nupdateContent();\nHTML 코드에서는 id demo의 정보가 없기 때문에 defer속성없이 스크립트를 실행하는 경우 스크립트 오류가 발생합니다.\n하지만 defer속성을 사용했기 때문에 DOM이 구성된 후에 id 가 demo 문서 요소에 접근해 아래과 같이 정보가 추가합니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html",
    "href": "blog/posts/2024/20240623.html",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "웹사이트의 트래픽을 늘리기 위해 검색 엔진 최적화(SEO)가 중요한 역할을 합니다. 검색 엔진은 웹 크롤러를 통해 웹사이트의 콘텐츠를 수집하고 색인합니다. 하지만 모든 페이지가 크롤링되는 것은 바람직하지 않을 수 있습니다. 이때 필요한 것이 바로 robots.txt 파일입니다. 이 파일은 웹사이트 소유자가 웹 크롤러에 대해 특정 페이지나 섹션의 접근을 제한할 수 있도록 도와줍니다.\n\n\n\nrobots.txt는 웹사이트의 루트 디렉토리에 위치한 텍스트 파일로, 검색 엔진의 웹 크롤러에게 어떤 페이지를 크롤링할 수 있는지, 또는 크롤링할 수 없는지를 지시하는 역할을 합니다. 예를 들어, 민감한 정보를 포함한 페이지나, 중복된 콘텐츠 페이지 등이 검색 엔진에 의해 인덱싱되는 것을 막기 위해 사용됩니다.\n\n\n\nrobots.txt 파일은 기본적으로 다음과 같은 지시어들로 구성됩니다:\n\nUser-agent: 크롤러의 이름을 지정합니다. 모든 크롤러에게 적용하고자 할 때는 *를 사용합니다.\nDisallow: 특정 페이지나 디렉토리를 크롤링하지 않도록 지시합니다.\nAllow: 특정 파일이나 디렉토리를 크롤링하도록 허용합니다(일부 크롤러에만 해당).\nSitemap: 사이트맵 파일의 위치를 지정하여 크롤러가 웹사이트 구조를 쉽게 이해할 수 있도록 합니다.\n\n\n\n\n다음은 robots.txt 파일의 간단한 예제입니다:\nUser-agent: *\nDisallow: /private/\nDisallow: /tmp/\nAllow: /public/\nSitemap: http://example.com/sitemap.xml\n이 예제에서는 모든 크롤러(User-agent: *)에게 /private/와 /tmp/ 디렉토리를 크롤링하지 말 것을 지시하고, /public/ 디렉토리는 크롤링하도록 허용합니다. 또한, 사이트맵 파일의 위치를 지정하고 있습니다.\n\n\n\nrobots.txt 파일을 작성할 때는 몇 가지 주의사항을 염두에 두어야 합니다:\n\n위치: robots.txt 파일은 반드시 웹사이트의 루트 디렉토리에 있어야 합니다. 예를 들어, http://example.com/robots.txt와 같은 위치에 있어야 합니다.\n대소문자 구분: robots.txt 파일 내의 지시어는 대소문자를 구분합니다. 잘못된 대소문자 사용은 의도한 대로 작동하지 않을 수 있습니다.\n기본 허용: 명시적으로 Disallow 지시어를 사용하지 않으면, 기본적으로 모든 페이지가 크롤링될 수 있습니다.\n안전성: 민감한 정보가 포함된 페이지는 robots.txt에만 의존하여 보호하지 마세요. URL이 노출될 수 있습니다. 대신 서버 측 인증을 통해 보호하는 것이 좋습니다.\n\n\n\n\nrobots.txt 파일은 웹사이트의 SEO 전략에 중요한 역할을 합니다. 잘 설계된 robots.txt 파일은 검색 엔진이 중요한 페이지를 효과적으로 크롤링하고, 불필요한 페이지는 무시하도록 함으로써 웹사이트의 검색 엔진 순위를 개선할 수 있습니다.\n\n\n\nrobots.txt 파일은 웹사이트 관리자가 검색 엔진 크롤러의 접근을 제어할 수 있는 강력한 도구입니다. 올바르게 설정된 robots.txt 파일은 웹사이트의 보안과 효율성을 높이는 데 기여할 수 있으며, SEO 최적화에도 중요한 역할을 합니다. 웹사이트의 구조와 콘텐츠에 따라 적절한 설정을 통해 최상의 결과를 얻으시길 바랍니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#개요",
    "href": "blog/posts/2024/20240623.html#개요",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "웹사이트의 트래픽을 늘리기 위해 검색 엔진 최적화(SEO)가 중요한 역할을 합니다. 검색 엔진은 웹 크롤러를 통해 웹사이트의 콘텐츠를 수집하고 색인합니다. 하지만 모든 페이지가 크롤링되는 것은 바람직하지 않을 수 있습니다. 이때 필요한 것이 바로 robots.txt 파일입니다. 이 파일은 웹사이트 소유자가 웹 크롤러에 대해 특정 페이지나 섹션의 접근을 제한할 수 있도록 도와줍니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#robots.txt란",
    "href": "blog/posts/2024/20240623.html#robots.txt란",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "robots.txt는 웹사이트의 루트 디렉토리에 위치한 텍스트 파일로, 검색 엔진의 웹 크롤러에게 어떤 페이지를 크롤링할 수 있는지, 또는 크롤링할 수 없는지를 지시하는 역할을 합니다. 예를 들어, 민감한 정보를 포함한 페이지나, 중복된 콘텐츠 페이지 등이 검색 엔진에 의해 인덱싱되는 것을 막기 위해 사용됩니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#robots.txt의-구성-요소",
    "href": "blog/posts/2024/20240623.html#robots.txt의-구성-요소",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "robots.txt 파일은 기본적으로 다음과 같은 지시어들로 구성됩니다:\n\nUser-agent: 크롤러의 이름을 지정합니다. 모든 크롤러에게 적용하고자 할 때는 *를 사용합니다.\nDisallow: 특정 페이지나 디렉토리를 크롤링하지 않도록 지시합니다.\nAllow: 특정 파일이나 디렉토리를 크롤링하도록 허용합니다(일부 크롤러에만 해당).\nSitemap: 사이트맵 파일의 위치를 지정하여 크롤러가 웹사이트 구조를 쉽게 이해할 수 있도록 합니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#robots.txt-예제",
    "href": "blog/posts/2024/20240623.html#robots.txt-예제",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "다음은 robots.txt 파일의 간단한 예제입니다:\nUser-agent: *\nDisallow: /private/\nDisallow: /tmp/\nAllow: /public/\nSitemap: http://example.com/sitemap.xml\n이 예제에서는 모든 크롤러(User-agent: *)에게 /private/와 /tmp/ 디렉토리를 크롤링하지 말 것을 지시하고, /public/ 디렉토리는 크롤링하도록 허용합니다. 또한, 사이트맵 파일의 위치를 지정하고 있습니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#robots.txt-작성-시-주의사항",
    "href": "blog/posts/2024/20240623.html#robots.txt-작성-시-주의사항",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "robots.txt 파일을 작성할 때는 몇 가지 주의사항을 염두에 두어야 합니다:\n\n위치: robots.txt 파일은 반드시 웹사이트의 루트 디렉토리에 있어야 합니다. 예를 들어, http://example.com/robots.txt와 같은 위치에 있어야 합니다.\n대소문자 구분: robots.txt 파일 내의 지시어는 대소문자를 구분합니다. 잘못된 대소문자 사용은 의도한 대로 작동하지 않을 수 있습니다.\n기본 허용: 명시적으로 Disallow 지시어를 사용하지 않으면, 기본적으로 모든 페이지가 크롤링될 수 있습니다.\n안전성: 민감한 정보가 포함된 페이지는 robots.txt에만 의존하여 보호하지 마세요. URL이 노출될 수 있습니다. 대신 서버 측 인증을 통해 보호하는 것이 좋습니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#robots.txt와-seo",
    "href": "blog/posts/2024/20240623.html#robots.txt와-seo",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "robots.txt 파일은 웹사이트의 SEO 전략에 중요한 역할을 합니다. 잘 설계된 robots.txt 파일은 검색 엔진이 중요한 페이지를 효과적으로 크롤링하고, 불필요한 페이지는 무시하도록 함으로써 웹사이트의 검색 엔진 순위를 개선할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2024/20240623.html#결론",
    "href": "blog/posts/2024/20240623.html#결론",
    "title": "Robots.txt 작성방법",
    "section": "",
    "text": "robots.txt 파일은 웹사이트 관리자가 검색 엔진 크롤러의 접근을 제어할 수 있는 강력한 도구입니다. 올바르게 설정된 robots.txt 파일은 웹사이트의 보안과 효율성을 높이는 데 기여할 수 있으며, SEO 최적화에도 중요한 역할을 합니다. 웹사이트의 구조와 콘텐츠에 따라 적절한 설정을 통해 최상의 결과를 얻으시길 바랍니다."
  },
  {
    "objectID": "dashboard_blog/posts/sp500_monthly_returns/sp500_monthly.html",
    "href": "dashboard_blog/posts/sp500_monthly_returns/sp500_monthly.html",
    "title": "SP500 Monthly Returns",
    "section": "",
    "text": "S&P500의 월별 수익률을 표시한 그래프 입니다. 주식시장에서 월별 수익률은 해당 월 동안의 주식 가격의 변동을 나타냅니다. 양의 수익률은 주식시장이 상승하고 있다는 것을 나타내며, 음의 수익률은 주식시장이 하락하고 있다는 것을 나타냅니다.\n파란색 막대 그래프는 최근 12개월의 월별 수익률을 나타냅니다. 붉은색 실선은 S&P500 지수를 나타내며 월별 수익률에 따른 지수의 변화를 이해할 수 있습니다. 그래프 상단의 붉은색 점선은 월별 국고채 수익률을 표시하고 있습니다.\n\n\n\n                                                \n\n\n\n\n주식과 채권의 비율을 12개월 중 국고채 수익률 보다 높은 월의 횟수로 결정하는 방법입니다. 예를들어 12개월 중 7개월이 국고채 수익률보다 높은 경우 주식과 채권의 비율을 7:3으로 적용할 수 있습니다.\n자신만에 포트폴리오 모멘텀 투자방식을 자신만의 포트폴리오 리벨런싱 규칙으로 사용할 수 있습니다."
  },
  {
    "objectID": "dashboard_blog/posts/sp500_monthly_returns/sp500_monthly.html#모멘텀-투자",
    "href": "dashboard_blog/posts/sp500_monthly_returns/sp500_monthly.html#모멘텀-투자",
    "title": "SP500 Monthly Returns",
    "section": "",
    "text": "주식과 채권의 비율을 12개월 중 국고채 수익률 보다 높은 월의 횟수로 결정하는 방법입니다. 예를들어 12개월 중 7개월이 국고채 수익률보다 높은 경우 주식과 채권의 비율을 7:3으로 적용할 수 있습니다.\n자신만에 포트폴리오 모멘텀 투자방식을 자신만의 포트폴리오 리벨런싱 규칙으로 사용할 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/summary.html",
    "href": "book_blog/posts/2023-09-03-data-visualization/summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_visualization.html",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_visualization.html",
    "title": "시계열 데이터 시각화",
    "section": "",
    "text": "시계열 데이터를 시각화를 연습합니다. 시계열 데이터 중 좋은 예로 사용할 수 있는 데이터는 주식데이터일 것 같습니다. FinanceDataReader라이브러리를 이용하여 Kospi 주가 정보를 읽어오고 이를 이용하여 월별 수익률을 계산합니다.\n시계열 데이터의 경우 일정 기간을 기준으로 통계정보를 추출하고 이를 지표로 사용하는 경우가 많습니다. KOSPI 주가지수를 분석하는 예제로 시계열 데이터를 시각화합니다.\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n2021-01-04\n2874.500000\n2946.540039\n2869.110107\n2944.449951\n2944.449951\n1026500\n\n\n2021-01-05\n2943.669922\n2990.570068\n2921.840088\n2990.570068\n2990.570068\n1519900\n\n\n2021-01-06\n2993.340088\n3027.159912\n2961.370117\n2968.209961\n2968.209961\n1793400\n\n\n2021-01-07\n2980.750000\n3055.280029\n2980.750000\n3031.679932\n3031.679932\n1524700\n\n\n2021-01-08\n3040.110107\n3161.110107\n3040.110107\n3152.179932\n3152.179932\n1297900\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2024-06-24\n2772.850098\n2782.899902\n2758.090088\n2764.729980\n2764.729980\n592800\n\n\n2024-06-25\n2765.760010\n2780.419922\n2765.760010\n2774.389893\n2774.389893\n714200\n\n\n2024-06-26\n2767.429932\n2792.070068\n2762.979980\n2792.050049\n2792.050049\n534300\n\n\n2024-06-27\n2767.620117\n2784.330078\n2761.550049\n2784.060059\n2784.060059\n396700\n\n\n2024-06-28\n2792.790039\n2797.820068\n2782.399902\n2797.820068\n2797.820068\n610600\n\n\n\n\n858 rows × 6 columns\n\n\n\n\n                                                \n\n\nPandas 데이터 프레임으로 KOSPI 주가지수 정보를 로드하고 각각의 정보를 3개의 sub plot으로 구성하여 같이 비교할 수 있도록 위와 같이 구성합니다. 예제를 통해서 subplot을 생성하는 방법에 대해서 이해할 수 있었고 특정 시간 단위로 시계열 데이터를 처리하는 방법도 배울 수 있었습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html",
    "title": "시계열 데이터",
    "section": "",
    "text": "시계열 데이터는 일정 시간간격을 측정된 정보한 데이터입니다. 시계열 데이터는 시간의 흐름에 따라서 테이터가 갖는 특징을 확인하기 위해서 생성되며 금융 정보나 생체 정보등의 특징을 저장하는 경우가 많습니다.\nPandas는 시계열 데이터를 관리하기 위한 많은 기능을 제공합니다. 데이터의 추세, 주기성 등을 파악할 수 있고 필요한 경우 예측 모델링을 할 수 있습니다. 그리고 원하는 형태의 시간을 표시할 수 있도록 DatetimeIndex, Timestamp, Teimdelta등 다양한 함수를 지원하고 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시간-데이터형",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시간-데이터형",
    "title": "시계열 데이터",
    "section": "시간 데이터형",
    "text": "시간 데이터형\n시계열 데이터를 이해하기 위해서 데이터를 구성하는 날짜를 어떻게 지정하는 지 이해해야 합니다. 파이썬은 날짜와 시간을 나타내는 datetime클래스를 제공합니다. 그리고 Pandas는 datetime객체를 Timestamp 객체로 변화시켜 사용합니다.\n\nfrom datetime import datetime\nnew_year = datetime(2023, 1, 1, 0, 0)\nnew_year\n\ndatetime.datetime(2023, 1, 1, 0, 0)\n\n\ndatetime객체를 이용하여 2023년 1월 1일 0시 0분을 나타내는 객체를 생성하였습니다. 이제 Timestamp를 이용하여 특정 시점을 표현합니다.\n\nimport pandas as pd\ntime_start = pd.Timestamp('2002-5-5 13:00')\ntime_start\n\nTimestamp('2002-05-05 13:00:00')\n\n\n이제 Pandas의 시계열 데이터의 특정시점을 지정하기 위해서 Timestamp 객체를 생성할 수 있습니다. 하지만 시간 정보를 전달 받는 대부분의 라이브러리는 내부적으로 Timestamp객체로 만들어 데이터를 처리하기 때문에 날짜 및 시간을 표시하는 문자열을 전달 받습니다.\n만약 이와 같이 구성하지 않고 생각해보면 매번 Timestamp나 datetime 클래스로 시간 정보를 변경해서 전달 해야 했다면 매우 불편했을 것 같습니다.\n시계열 데이터는 데이터의 인덱스로 시간 정보를 사용하는 경우가 대부분입니다. Pandas에서는 Timestamp 데이터로 정의된 인덱스인 DatetimeIndex객체를 사용합니다. 시계열 데이터로 데이터 프레임을 생성하고 이 데이터 프레임 index가 어떤 데이터 형인지 알아봅니다.\n\ndates = pd.Series([10, 20], [pd.Timestamp('2023-1-1'), pd.Timestamp('2023-1-2')])\nprint(type(dates.index))\ndisplay(dates)\n\n&lt;class 'pandas.core.indexes.datetimes.DatetimeIndex'&gt;\n\n\n2023-01-01    10\n2023-01-02    20\ndtype: int64\n\n\n위의 코드에서 dates라는 이름으로 pandas series데이터를 생성했습니다. 데이터와 함께 index로 Timestamp정보가 전달됩니다. dates series 데이터에 전달된 Timestamp는 인덱스로 사용되면서 데이터형은 DatetimeIndex로 설정되었습니다.\n\ndf = pd.DataFrame({'data': [10, 20]},\n                    index = pd.to_datetime(['2023-1-1', '2023-1-2']))\nprint(type(df.index))\ndisplay(df)\n\n&lt;class 'pandas.core.indexes.datetimes.DatetimeIndex'&gt;\n\n\n\n\n\n\n\n\n\ndata\n\n\n\n\n2023-01-01\n10\n\n\n2023-01-02\n20\n\n\n\n\n\n\n\n위의 코드는 df 데이터 프레임 생성 시 index정보를 to_datetime()함수를 이용하여 Timestamp로 변환하고 이를 index로 전달했습니다. 데이터 프레임의 index는 이전 예제와 같이 DatetimeIndex로 표시됩니다.\n\n\n\n\n\n\nTip\n\n\n\n하지만 매번 Timestamp객체를 만들어 전달하는 것을 코드의 가독성을 낮추는 문제가 있습니다. to_dateteime함수는 Pandas는 Timestamp로 전달될 수 있는 문자열을 Timestamp로 변환할 수 있기 때문에 좀 더 효율적으로 DatetimeIndex를 생성할 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시간-간격-표현방법",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시간-간격-표현방법",
    "title": "시계열 데이터",
    "section": "시간 간격 표현방법",
    "text": "시간 간격 표현방법\n\nTimedelta\nTimedelta 클래스는 시간간격을 표시하기 위해 사용됩니다. 두 날짜 사이의 차이를 계산하거나 간격을 계산하기 위해서 사용됩니다. Timedelta를 사용하기 위해서는 datatime 패키지에서 Timedelta를 import해야 합니다.\n\nimport pandas as pd\nfrom datetime import datetime, timedelta\nnow = datetime.now()\nbefore_7days = now - timedelta(days=7)\ndisplay(before_7days)\n\ndatetime.datetime(2024, 6, 22, 23, 7, 14, 174614)\n\n\n예를 들어 시계열 데이터의 현재시점에서 7일전 데이터와의 차이를 확인하기 위해서는 현재 시점에서 원하는 날짜 차이를 빼야 합니다. timedelta를 사용하여 현재 시간에서 7일전을 계산한 결과가 출력되었습니다.\n\n\nDateOffset\nDateOffset은 정기적인 증가 또는 감소를 표현하기 위한 시간적 크기를 표현합니다. 일정 시점에서 자신이 원하는 시간 간격만큼 더하거나 빼는 수학적 연산을 DateOffset을 이용하여 수행합니다.\n\ndate = pd.Timestamp('2023-01-01')\noffset_3days = pd.DateOffset(days = 3)\noffset_3hours = pd.DateOffset(hours = 3)\ndisplay(date + offset_3days)\ndisplay(date + offset_3hours)\n\nTimestamp('2023-01-04 00:00:00')\n\n\nTimestamp('2023-01-01 03:00:00')\n\n\n2023년 1월 1일을 나타내는 date에 3일과 3시간 간격의 DateOffset 객체를 더해 지정한 간격의 날짜 정보를 얻을 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시간-반복-시계열-생성방법",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시간-반복-시계열-생성방법",
    "title": "시계열 데이터",
    "section": "시간 반복 시계열 생성방법",
    "text": "시간 반복 시계열 생성방법\n\nRange\nRange class는 일정 시간 간격으로 시계열 데이터를 만들어야하는 경우 사용됩니다. 년도, 분기, 월 등 다양한 시간간격을 나타낼 수 있으며 이를 이용하여 일정한 간격의 시계열 데이터를 처리하는 경우에 사용할 수 있습니다.\n예를 들어 특정한 시작날짜와 종료날짜 사이의 기간을 주단위로 시간간격으로 정보를 확인해야하는 경우 사용될 수 있습니다.\n\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2023-1-1', '2023-5-1', freq = 'W')\ndf = pd.DataFrame({'date' : dates,\n                   'value' : range(len(dates))})\ndisplay(dates)\ndisplay(df.head())\n\nDatetimeIndex(['2023-01-01', '2023-01-08', '2023-01-15', '2023-01-22',\n               '2023-01-29', '2023-02-05', '2023-02-12', '2023-02-19',\n               '2023-02-26', '2023-03-05', '2023-03-12', '2023-03-19',\n               '2023-03-26', '2023-04-02', '2023-04-09', '2023-04-16',\n               '2023-04-23', '2023-04-30'],\n              dtype='datetime64[ns]', freq='W-SUN')\n\n\n\n\n\n\n\n\n\ndate\nvalue\n\n\n\n\n0\n2023-01-01\n0\n\n\n1\n2023-01-08\n1\n\n\n2\n2023-01-15\n2\n\n\n3\n2023-01-22\n3\n\n\n4\n2023-01-29\n4\n\n\n\n\n\n\n\ndates는 date_range()함수에 전달된 시작시점과 종료시점 사이를 freq로 전달된 간격만큼 떨어진 시간 정보를 생성했습니다. freq로 전달될 수 있는 주요 offset정보는 아래와 같습니다. 자세한 내용은 Pandas API 문서에서 확인 합니다.\n\n\n\nAlias\nDescription\n\n\n\n\nB\nbusiness day frequency\n\n\nBM\nbusiness month end frequency\n\n\nMS\nmonth start frequency\n\n\nQ\nquarter end frequency\n\n\nW-MON\nweekly frequency (Mondays)\n\n\n\nW-MON은 고정 오프셋으로 특정 날짜를 기준으로하는 빈도가 필요할 때 사용합니다. 위의 예제의 기간 중 매주 월요일을 간격으로 날짜를 생성하는 예제를 확인합니다.\n\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2023-1-1', '2023-5-1', freq = 'W-MON')\ndf = pd.DataFrame({'date' : dates,\n                   'value' : range(len(dates))})\ndisplay(df.head())\n\n\n\n\n\n\n\n\ndate\nvalue\n\n\n\n\n0\n2023-01-02\n0\n\n\n1\n2023-01-09\n1\n\n\n2\n2023-01-16\n2\n\n\n3\n2023-01-23\n3\n\n\n4\n2023-01-30\n4\n\n\n\n\n\n\n\n생성된 데이터 프레임의 처음 날짜는 2023년 1월 1일이 아니고 해당 기간 중 첫 번째 월요일인 2023년 1월 2일로 날짜가 생성되었습니다.\n\n\nPeriod\n일정 시점에서 한달 간격으로 수행하는 작업이 있는 경우 Period를 사용할 수 있습니다. Period는 Timestamp와 DateOffset으로 생성한는 시간 데이터를 더 효율적으로 관리할 수 있도록 합니다.\n\nperiods = pd.Period('2023-1-1', freq='M')\ndisplay(periods)\ndisplay(periods+1)\n\nPeriod('2023-01', 'M')\n\n\nPeriod('2023-02', 'M')"
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시계열-데이터-만들기",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_basic.html#시계열-데이터-만들기",
    "title": "시계열 데이터",
    "section": "시계열 데이터 만들기",
    "text": "시계열 데이터 만들기\n다양한 시계열 데이터를 만들면서 Pandas에서 제공하는 시계열 데이터 생성 기능을 배워봅니다.\n\n특정 빈도의 시계열 생성\nPandas에서 제공하는 to_datetime()'과date_range()` 함수를 이용해서 시계열 데이터를 만들어 봅니다.\n\nindex = pd.to_datetime(['2023-1-1', '2023-2-28', '2023-3-31', '2023-4-30'])\ndata = range(len(index))\ndf = pd.DataFrame({'data': data},\n                    index = index)\nprint(type(df.index))\ndisplay(df)\n\n&lt;class 'pandas.core.indexes.datetimes.DatetimeIndex'&gt;\n\n\n\n\n\n\n\n\n\n\ndata\n\n\n\n\n2023-01-01\n0\n\n\n2023-02-28\n1\n\n\n2023-03-31\n2\n\n\n2023-04-30\n3\n\n\n\n\n\nFigure 1: 데이터프레임 생성, to_datetime()\n\n\n\n위의 예제에서는 to_datetime()함수로 일정 시간 정보를 데이터 프레임의 index로 전달하여 데이터 프레임을 생성합니다. 데이터 프레임의 index는 DateTimeIndex로 표시되었습니다.\n\nindex = pd.date_range('2023-1-1', '2023-5-1', freq = 'M')\ndata = range(len(index))\ndf = pd.DataFrame({'data' : data},\n                   index = index)\ndisplay(df)\n\n\n\n\n\n\n\n\n\ndata\n\n\n\n\n2023-01-31\n0\n\n\n2023-02-28\n1\n\n\n2023-03-31\n2\n\n\n2023-04-30\n3\n\n\n\n\n\nFigure 2: 데이터프레임 생성, date_range()\n\n\n\nSection 3.2 에서 사용한 date_range()함수를 이용하면 Figure 1 와 같이 to_datatime()함수 이용한 시간 정보가 동일한 간격이라면 Figure 2 처럼 date_range()함수를 이용해 다시 간략하게 표현할 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/first_plotly.html",
    "href": "book_blog/posts/2024-06-29-plotly/first_plotly.html",
    "title": "첫 번째 Plotly 그래프 그리기",
    "section": "",
    "text": "Plotly를 위한 개발환경이 준비되었으니 간단한 Plotly 그래프를 만들어 보겠습니다. Plotly를 이용해서 그래프를 그리는 전체 과정을 알아보며 큰 그림을 그릴 수 있도록 진행하겠습니다.\n과정 중 이해가 되지 않는 부분이 있더라도 책에서 차근차근 소개할 예정이니 전체 흐름을 이해한다는 느낌으로 읽으면 좋겠습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/first_plotly.html#데이터-준비하기",
    "href": "book_blog/posts/2024-06-29-plotly/first_plotly.html#데이터-준비하기",
    "title": "첫 번째 Plotly 그래프 그리기",
    "section": "데이터 준비하기",
    "text": "데이터 준비하기\nPlotly로 그래프를 만들기 위해서는 시각화할 데이터를 준비해야 합니다. 이번 예제에서는 간단한 선 그래프를 만들기 위해 아래와 같은 데이터를 사용할 것입니다:\n\nimport pandas as pd\n\ndata = {\n    \"날짜\": [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", \"2024-01-04\", \"2024-01-05\"],\n    \"판매량\": [150, 200, 170, 220, 180],\n    \"판매왕\": [\"John\", \"Peter\", \"Peter\", \"Tony\", \"Bob\"]\n}\n\ndf = pd.DataFrame(data)\ndf[\"날짜\"] = pd.to_datetime(df[\"날짜\"])\ndf.head()\n\n\n\n\n\n\n\n\n날짜\n판매량\n판매왕\n\n\n\n\n0\n2024-01-01\n150\nJohn\n\n\n1\n2024-01-02\n200\nPeter\n\n\n2\n2024-01-03\n170\nPeter\n\n\n3\n2024-01-04\n220\nTony\n\n\n4\n2024-01-05\n180\nBob\n\n\n\n\n\n\n\n위의 코드는 Pandas 데이터프레임을 생성합니다. 컬럼은 날짜와 판매량은 각각 날짜 데이터와 판매량을 표현하는 숫자를 갖습니다.\n좋은 시각화는 적절한 그래프 선택으로 시작합니다. 어떤 그래프가 이 데이터를 잘 시각화 할 수 있을까요? 시간의 흐름에 따른 값의 변화를 표현해야 하기 때문에 이 데이터를 잘 표현할 수 있는 그래프는 line 차트 또는 bar 차트가 될 것 같습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/first_plotly.html#plotly-그래프-생성하기",
    "href": "book_blog/posts/2024-06-29-plotly/first_plotly.html#plotly-그래프-생성하기",
    "title": "첫 번째 Plotly 그래프 그리기",
    "section": "Plotly 그래프 생성하기",
    "text": "Plotly 그래프 생성하기\nPlotly를 사용하여 그래프를 생성하는 것은 매우 간단합니다. Plotly의 express 모듈을 사용하면 몇 줄의 코드로 아름다운 그래프를 만들 수 있습니다. 이번 예제에서는 px.line을 사용하여 선 그래프를 그리겠습니다.\n\nimport plotly.express as px\n\nfig = px.line(df, x=\"날짜\", y=\"판매량\", title=\"일별 판매량\")\nfig.show()\n\n\n                                                \n\n\nx축에는 날짜, y축에는 해당 날짜의 판매량이 표시됩니다. 시간에 흐름에 따른 판매량의 변화를 이해할 수 있습니다. 차트의 제목을 일별 판매량으로 표시되는군요.\n막대 그래프로 표현하는 경우는 어떨까요?\n\nimport plotly.express as px\n\nfig = px.bar(df, x=\"날짜\", y=\"판매량\", title=\"일별 판매량\")\nfig.show()\n\n\n                                                \n\n\n위의 코드는 동일한 데이터를 막대그래프로 표현하는 코드입니다. 사용하는 함수가 px.line()에서 px.bar()로 변경되었고 전달하는 데이터는 동일합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/first_plotly.html#그래프-커스터마이징",
    "href": "book_blog/posts/2024-06-29-plotly/first_plotly.html#그래프-커스터마이징",
    "title": "첫 번째 Plotly 그래프 그리기",
    "section": "그래프 커스터마이징",
    "text": "그래프 커스터마이징\n그래프는 데이터를 잘 표현하고 있지만 살짝 아시운 부분이 있습니다. 그래프로 표현하는 X축과 Y축의 값이 작고 보고서의 폰트와 달라 아쉽습니다.\n다행히 Plotly는 기본 그래프 생성 외에도 다양한 커스터마이징 옵션을 제공합니다. 이 기능을 이용하면 제목, 축 레이블, 레이아웃 등을 쉽게 변경할 수 있습니다. 몇 가지 예를 들어보겠습니다.\n\nfig.update_layout(\n    title=\"2024년 일별 판매량\",\n    xaxis_title=\"날짜\",\n    yaxis_title=\"판매량\",\n    font=dict(\n        family=\"Courier New\",\n        size=25,\n        color=\"darkgreen\"\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\n새로운 그래프는 X축, Y축의 글자 크기도 커지고 원하는 폰트로 변경되었습니다. 보고서에 사용하기 적합하게 그래프를 커스터마이징했습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/first_plotly.html#대화형-기능-추가하기",
    "href": "book_blog/posts/2024-06-29-plotly/first_plotly.html#대화형-기능-추가하기",
    "title": "첫 번째 Plotly 그래프 그리기",
    "section": "대화형 기능 추가하기",
    "text": "대화형 기능 추가하기\nPlotly의 강력한 기능 중 하나는 대화형 기능입니다. 사용자가 그래프의 특정 부분을 클릭하거나 마우스를 올렸을 때 추가 정보를 표시할 수 있습니다. 이를 위해 hover_data 옵션을 사용할 수 있습니다.\n\nfig = px.bar(df, x=\"날짜\", y=\"판매량\", title=\"일별 판매량\", hover_data={\"판매왕\": True})\nfig.show()\n\n\n                                                \n\n\n해당 날짜의 판매왕이 누구인지를 그래프 대화박스에 표시할 수 있다면 좋겠습니다. 위의 코드로 대화박스에 표현될 데이터인 판매왕 표시할 수 있습니다. 이제 그래프 대화박스에 판매왕정보가 추가되었습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/first_plotly.html#다양한-그래프-유형",
    "href": "book_blog/posts/2024-06-29-plotly/first_plotly.html#다양한-그래프-유형",
    "title": "첫 번째 Plotly 그래프 그리기",
    "section": "다양한 그래프 유형",
    "text": "다양한 그래프 유형\nPlotly는 선 그래프 외에도 막대 그래프, 원형 차트, 산점도 등 다양한 그래프 유형을 지원합니다. 데이터에 맞는 그래프를 선택해서 데이터를 시각화할 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/main_features.html",
    "href": "book_blog/posts/2024-06-29-plotly/main_features.html",
    "title": "Plotly의 기능소개",
    "section": "",
    "text": "Plotly를 이용해서 간단한 그래프를 그리고 그래프를 커스터마이징하는 과정을 진행했습니다. 이 장에서는 Plotly에서 지원하는 더룬 주요 기능에 대해서 설명합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/main_features.html#다양한-그래프-유형",
    "href": "book_blog/posts/2024-06-29-plotly/main_features.html#다양한-그래프-유형",
    "title": "Plotly의 기능소개",
    "section": "다양한 그래프 유형",
    "text": "다양한 그래프 유형\nPlotly는 다양한 그래프 유형을 지원하여 사용자가 다양한 형태의 데이터를 시각화할 수 있도록 합니다. 주요 그래프 유형으로는 선형 차트, 막대 차트, 원형 차트, 히스토그램, 산점도, 박스 플롯, 히트맵, 버블 차트, 트리맵, 지오스캐터 차트, 영역 차트, 극좌표 차트 등이 있습니다.\n\n\n\n\n\n\n\n차트종류\n목적\n\n\n\n\n선형 차트 (Line Chart)\n선형 차트는 시간의 경과에 따른 데이터 변화를 시각화하는 데 유용합니다.\n\n\n막대 차트 (Bar Chart)\n막대 차트는 범주형 데이터를 비교하는 데 유용합니다.\n\n\n원형 차트 (Pie Chart)\n원형 차트는 전체에 대한 각 부분의 비율을 시각화하는 데 유용합니다.\n\n\n히스토그램 (Histogram)\n히스토그램은 데이터의 분포를 시각화하는 데 유용합니다.\n\n\n산점도 (Scatter Plot)\n산점도는 두 변수 간의 관계를 시각화하는 데 유용합니다.\n\n\n박스 플롯 (Box Plot)\n박스 플롯은 데이터의 분포와 이상치를 시각화하는 데 유용합니다.\n\n\n히트맵 (Heatmap)\n히트맵은 두 변수의 값을 색상으로 시각화하는 데 유용합니다.\n\n\n버블 차트 (Bubble Chart)\n버블 차트는 산점도의 확장으로, 세 번째 변수를 점의 크기로 시각화합니다.\n\n\n트리맵 (Treemap)\n트리맵은 계층 구조를 색상과 면적으로 시각화하는 데 유용합니다.\n\n\n지오스캐터 차트 (Geoscatter Plot)\n지오스캐터 차트는 지도 위에 데이터 포인트를 시각화하는 데 유용합니다.\n\n\n영역 차트 (Area Chart)\n영역 차트는 선형 차트와 비슷하지만, 아래 영역을 색칠하여 데이터의 누적치를 강조합니다.\n\n\n극좌표 차트 (Polar Chart)\n극좌표 차트는 원형 축을 사용하여 데이터를 시각화합니다.\n\n\n\nPlotly는 이 외에도 다양한 특수 목적의 그래프를 지원합니다. 각 그래프 유형은 다양한 시각화 요구를 충족시키기 위해 커스터마이징이 가능합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/main_features.html#대화형-그래프",
    "href": "book_blog/posts/2024-06-29-plotly/main_features.html#대화형-그래프",
    "title": "Plotly의 기능소개",
    "section": "대화형 그래프",
    "text": "대화형 그래프\nPlotly의 가장 큰 장점 중 하나는 대화형 그래프를 쉽게 생성할 수 있다는 점입니다. 마우스 오버, 클릭, 확대/축소 등의 기능을 통해 사용자와 상호작용할 수 있는 그래프를 만들 수 있습니다. 이러한 대화형 기능은 데이터 분석을 더욱 직관적이고 이해하기 쉽게 만듭니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/main_features.html#대시보드와-통합",
    "href": "book_blog/posts/2024-06-29-plotly/main_features.html#대시보드와-통합",
    "title": "Plotly의 기능소개",
    "section": "대시보드와 통합",
    "text": "대시보드와 통합\nPlotly는 Dash와 함께 사용하여 대시보드를 쉽게 생성할 수 있습니다. Dash는 Plotly를 기반으로 한 대시보드 프레임워크로, 웹 애플리케이션을 만들기 위한 다양한 도구와 기능을 제공합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/main_features.html#출력-형식",
    "href": "book_blog/posts/2024-06-29-plotly/main_features.html#출력-형식",
    "title": "Plotly의 기능소개",
    "section": "출력 형식",
    "text": "출력 형식\nPlotly는 그래프를 다양한 형식으로 저장할 수 있습니다. HTML, PNG, JPEG, SVG 등 여러 형식으로 저장할 수 있어 웹에 쉽게 삽입하거나 문서에 포함시킬 수 있습니다.\nPlotly 그래프를 이미지 파일로 저장하려면 추가적으로 Kaleido 라이브러리를 설치해야 합니다. Kaleido는 Plotly 그래프를 PNG, JPEG, SVG와 같은 형식으로 저장하는 데 사용되는 도구입니다. 아래의 명령어를 샐행하여 Kaleido를 설치합니다.\n\npip install -U kaleido\n\nRequirement already up-to-date: kaleido in /usr/lib/python3.8/site-packages (0.2.1)\nNote: you may need to restart the kernel to use updated packages.\n\n\n데이터를 로드하고 그래프를 생성한 후 이미지로 저장하기 위해 아래 코드를 실행합니다.\n\nimport pandas as pd\nimport plotly.express as px\n\ndata = {\n    \"날짜\": [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", \"2024-01-04\", \"2024-01-05\"],\n    \"판매량\": [150, 200, 170, 220, 180],\n    \"판매왕\": [\"John\", \"Peter\", \"Peter\", \"Tony\", \"Bob\"]\n}\n\ndf = pd.DataFrame(data)\ndf[\"날짜\"] = pd.to_datetime(df[\"날짜\"])\n\nfig = px.line(df, x=\"날짜\", y=\"판매량\", title=\"일별 판매량\")\nfig.write_image(\"fig1.png\")\n\n\n위의 코드를 실행하면 위와 같이 그래프가 fig1.png 파일로 저장됩니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/plotly.html",
    "href": "book_blog/posts/2024-06-29-plotly/plotly.html",
    "title": "Plotly를 이용한 데이터시각화",
    "section": "",
    "text": "Plotly는 Python을 비롯한 여러 프로그래밍 언어에서 데이터 시각화를 쉽게 만들 수 있도록 도와주는 오픈 소스 그래프 라이브러리입니다.\nPlotly의 주요 장점은 대화형(interactive) 그래프를 생성할 수 있다는 점입니다. 이는 사용자가 그래프와 상호작용하며 데이터를 더 깊이 탐색할 수 있게 합니다.\n이 책을 통해서 Plotly로 데이터를 시각화하는 방법을 정리합니다."
  },
  {
    "objectID": "books.html",
    "href": "books.html",
    "title": "Books",
    "section": "",
    "text": "온라인 책들을 정리합니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Public BookShelf",
    "section": "",
    "text": "온라인 책장입니다. 공부한 내용을 정리하고 차근차근 모아 책으로 만듭니다.\n추가하고 싶은 책이 있다면 블로그에 하나씩 글을 모으는 것으로 시작합니다. 느리게 작지만 꾸준히 글쓰기를 연습합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/line_chart.html",
    "href": "book_blog/posts/2024-06-29-plotly/line_chart.html",
    "title": "Line Chart",
    "section": "",
    "text": "업데이트 예정"
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/installation.html",
    "href": "book_blog/posts/2024-06-29-plotly/installation.html",
    "title": "Plotly 설치 및 기본 설정 방법",
    "section": "",
    "text": "Plotly는 Python의 패키지 관리 도구인 pip를 사용하여 쉽게 설치할 수 있습니다. 먼저, 터미널(또는 커맨드 프롬프트)을 열고 다음 명령어를 입력하여 Plotly를 설치합니다.\n이 명령어를 실행하면 Plotly와 그 종속성들이 자동으로 설치됩니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/installation.html#jupyter-notebook-설정",
    "href": "book_blog/posts/2024-06-29-plotly/installation.html#jupyter-notebook-설정",
    "title": "Plotly 설치 및 기본 설정 방법",
    "section": "Jupyter Notebook 설정",
    "text": "Jupyter Notebook 설정\nPlotly는 Jupyter Notebook과 잘 통합되어 있어, Jupyter Notebook을 사용하는 경우 Plotly의 대화형 그래프를 쉽게 생성할 수 있습니다. Jupyter Notebook을 설치하려면 다음 명령어를 실행합니다.\npip install notebook\n설치가 완료되면, 터미널에서 jupyter notebook 명령어를 입력하여 Jupyter Notebook을 시작할 수 있습니다.\njupyter notebook"
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/installation.html#간단한-예제-작성",
    "href": "book_blog/posts/2024-06-29-plotly/installation.html#간단한-예제-작성",
    "title": "Plotly 설치 및 기본 설정 방법",
    "section": "간단한 예제 작성",
    "text": "간단한 예제 작성\n이제 Plotly를 사용하여 간단한 예제 그래프를 작성해보겠습니다. 다음 코드를 Jupyter Notebook의 셀에 입력하고 실행합니다.\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\n\n# 샘플 데이터 생성\nx_data = [1, 2, 3, 4, 5]\ny_data = [10, 11, 12, 13, 14]\n\n# 그래프 객체 생성\ntrace = go.Scatter(\n    x=x_data,\n    y=y_data,\n    mode='lines+markers',\n    name='Sample Data'\n)\n\ndata = [trace]\n\nlayout = go.Layout(\n    title='Plotly Example',\n    xaxis=dict(title='X-axis'),\n    yaxis=dict(title='Y-axis')\n)\n\nfig = go.Figure(data=data, layout=layout)\n\n# 그래프 출력\npyo.plot(fig, filename='plotly_example.html')\n이 코드는 간단한 라인 그래프를 생성하여 plotly_example.html 파일로 저장합니다. 저장된 HTML 파일을 브라우저에서 열면 대화형 그래프를 확인할 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/installation.html#jupyter-notebook에서-그래프-표시",
    "href": "book_blog/posts/2024-06-29-plotly/installation.html#jupyter-notebook에서-그래프-표시",
    "title": "Plotly 설치 및 기본 설정 방법",
    "section": "Jupyter Notebook에서 그래프 표시",
    "text": "Jupyter Notebook에서 그래프 표시\nJupyter Notebook 내부에서 직접 그래프를 표시하려면 fig.show()명령을 사용합니다.\n\nimport plotly.graph_objs as go\n\n# 샘플 데이터 생성\nx_data = [1, 2, 3, 4, 5]\ny_data = [10, 11, 12, 13, 14]\n\n# 그래프 객체 생성\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n        x=x_data,\n        y=y_data,\n        mode='lines+markers',\n        name='Sample Data',\n    ))\n\nfig.show()\n\n\n                                                \n\n\nfig.show()를 호출하여 그래프를 표시합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html",
    "href": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html",
    "title": "Plotly가 무엇인가요?",
    "section": "",
    "text": "Plotly는 Python을 비롯한 여러 프로그래밍 언어에서 데이터 시각화를 쉽게 만들 수 있도록 도와주는 오픈 소스 그래프 라이브러리입니다. Plotly의 주요 장점은 대화형(interactive) 그래프를 생성할 수 있다는 점입니다. 이는 사용자가 그래프와 상호작용하며 데이터를 더 깊이 탐색할 수 있게 합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#plotly의-역사와-배경",
    "href": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#plotly의-역사와-배경",
    "title": "Plotly가 무엇인가요?",
    "section": "Plotly의 역사와 배경",
    "text": "Plotly의 역사와 배경\nPlotly는 2013년에 설립된 Plotly Inc.에 의해 개발되었습니다. 초기에는 웹 기반 데이터 시각화 도구로 시작했으나, 이후 Python, R, MATLAB 등 여러 언어를 지원하는 라이브러리로 발전하였습니다. Plotly는 데이터 과학자, 분석가, 연구자 등이 데이터를 보다 효과적으로 시각화하고 공유할 수 있도록 돕기 위해 만들어졌습니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#plotly의-주요-특징",
    "href": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#plotly의-주요-특징",
    "title": "Plotly가 무엇인가요?",
    "section": "Plotly의 주요 특징",
    "text": "Plotly의 주요 특징\n\n대화형 그래프: Plotly로 생성된 그래프는 기본적으로 대화형입니다. 사용자는 그래프의 특정 부분에 마우스를 올리거나 클릭하여 추가 정보를 확인할 수 있습니다.\n다양한 차트 종류: Plotly는 선 그래프, 막대 그래프, 산점도, 히트맵, 3D 그래프 등 다양한 차트를 지원합니다.\n높은 커스터마이제이션: Plotly는 그래프의 세부 요소를 사용자 정의할 수 있는 강력한 커스터마이제이션 기능을 제공합니다. 색상, 폰트, 레이아웃 등 다양한 부분을 세밀하게 조정할 수 있습니다.\n웹 기반 시각화: Plotly로 생성된 그래프는 HTML, JSON 등의 웹 표준을 사용하여 웹 페이지에 쉽게 삽입할 수 있습니다.\nPlotly Express: Plotly Express는 간단한 문법으로 빠르게 고품질의 그래프를 생성할 수 있는 Plotly의 고급 API입니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#python-시각화-라이브러리",
    "href": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#python-시각화-라이브러리",
    "title": "Plotly가 무엇인가요?",
    "section": "Python 시각화 라이브러리",
    "text": "Python 시각화 라이브러리\nPython에는 다양한 데이터 시각화 라이브러리가 있으며, 각각 고유한 장점과 특징이 있습니다. 여기서는 Matplotlib, Seaborn, Bokeh, 그리고 Plotly를 비교하여 설명하겠습니다.\n\n1. Matplotlib\nMatplotlib은 Python에서 가장 널리 사용되는 데이터 시각화 라이브러리 중 하나로, 2D 그래프를 생성하는 데 강력한 기능을 제공합니다.\n\n특징\n\n기본적이고 광범위한 기능: 선 그래프, 막대 그래프, 히스토그램 등 다양한 기본 그래프를 그릴 수 있습니다.\n높은 커스터마이제이션: 그래프의 거의 모든 요소를 사용자 정의할 수 있습니다.\n정적 이미지: 주로 정적인 그래프를 생성하며, 대화형 기능은 제한적입니다.\n복잡한 문법: 간단한 그래프를 그리기 위해서는 비교적 많은 코드가 필요합니다.\n\n\n\n예제\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nx = [1, 2, 3, 4, 5]\ny = [10, 20, 30, 40, 50]\n\nplt.plot(x, y)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Matplotlib Graph')\nplt.show()\n\n\n\n\n\n\n\n2. Seaborn\n\n개요\nSeaborn은 Matplotlib 기반의 라이브러리로, 통계적 데이터 시각화를 더 쉽게 만들 수 있도록 설계되었습니다.\n\n\n특징\n\n통계적 시각화: 상관 관계, 분포 등 통계적 시각화에 강력한 기능을 제공합니다.\n간단한 문법: Matplotlib에 비해 더 간단하고 직관적인 문법을 제공합니다.\n고급 스타일링: 기본 스타일이 세련되고 시각적으로 매력적입니다.\nMatplotlib와 통합: Matplotlib 객체를 사용하여 세밀하게 조정할 수 있습니다.\n\n\n\n예제\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntips = sns.load_dataset(\"tips\")\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips)\nplt.title('Seaborn')\nplt.show()\n\n\n\n\n\n\n\n3. Plotly\n\n개요\nPlotly는 대화형 그래프를 쉽게 만들 수 있는 라이브러리로, 웹 브라우저에서의 시각화에 강력한 기능을 제공합니다.\n\n\n특징\n\n대화형 그래프: 기본적으로 대화형 그래프를 생성할 수 있습니다.\n다양한 차트 종류: 선 그래프, 막대 그래프, 산점도, 3D 그래프 등 다양한 차트를 지원합니다.\n웹 기반 시각화: 웹 표준을 사용하여 그래프를 쉽게 웹에 포함할 수 있습니다.\n간단한 문법: Plotly Express를 사용하여 간단한 문법으로 그래프를 생성할 수 있습니다.\n\n\n\n예제\n\nimport plotly.graph_objects as go\n\nx = [1, 2, 3, 4, 5]\ny = [10, 20, 30, 40, 50]\n\nfig = go.Figure(data=go.Scatter(x=x, y=y))\nfig.show()\n\n\n                                                \n\n\n\n\n\n비교 요약\n\n\n\n\n\n\n\n\n\n\n\n라이브러리\n대화형 그래프\n차트 종류\n커스터마이제이션\n웹 통합\n사용 난이도\n\n\n\n\nMatplotlib\n제한적\n다양\n높음\n낮음\n중간\n\n\nSeaborn\n제한적\n통계적 시각화\n중간\n낮음\n쉬움\n\n\nBokeh\n매우 높음\n다양\n중간\n매우 높음\n어려움\n\n\nPlotly\n매우 높음\n매우 다양\n높음\n매우 높음\n중간\n\n\n\n\n\n결론\n\nMatplotlib은 세밀한 커스터마이제이션이 필요하고 정적 그래프를 주로 그리는 경우에 적합합니다.\nSeaborn은 통계적 데이터 시각화와 간단한 문법을 선호하는 사용자에게 적합합니다.\nBokeh는 웹 기반 대화형 시각화를 원하며, 웹 애플리케이션에 통합하려는 경우에 유리합니다.\nPlotly는 대화형 그래프와 다양한 차트 종류를 필요로 하며, 웹과의 통합이 중요한 경우에 가장 적합합니다."
  },
  {
    "objectID": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#plotly의-응용-분야",
    "href": "book_blog/posts/2024-06-29-plotly/what_is_plotly.html#plotly의-응용-분야",
    "title": "Plotly가 무엇인가요?",
    "section": "Plotly의 응용 분야",
    "text": "Plotly의 응용 분야\nPlotly는 다양한 분야에서 활용될 수 있습니다. 예를 들어:\n\n데이터 분석: 데이터 과학자들이 데이터를 분석하고 시각화 및 분석을 위해 사용합니다.\n금융: 주식 시장 데이터, 금융 지표 등을 시각화하여 트렌드를 분석합니다.\n연구 및 학술: 연구자들이 실험 데이터를 시각화하여 논문에 사용하거나 프레젠테이션에 활용합니다.\n마케팅: 마케팅 데이터를 시각화하여 캠페인 성과를 분석하고 전략을 수립합니다.\n\n특히 데이터 시각화를 웹으로 표현해야하는 목적이 있다면 Plotly가 적합한 데이터 시각화 라이브러리가 될 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/data_visualization.html",
    "href": "book_blog/posts/2023-09-03-data-visualization/data_visualization.html",
    "title": "시계열 데이터 시각화",
    "section": "",
    "text": "데이터 시각화 과정을 정리하고 결과를 정리하기 위한 책입니다.\n배움을 잘 이해하고 기억하는 가장 좋은 방법은 정리하여 글로 남기는 것이라고 생각합니다. 다만 배운 내용을 정리하는 과정에 잘못된 정보가 있을 수 있습니다.\n읽으시며 중요한 내용이 있다면 틀린 부분이 있는 지 다시 확인해 주시길 부탁드립니다. 이 책을 만들면서 데이터 시각화에 대해서 좀 더 잘 이해하고 더불어 이 책을 보는 분들에게도 도움이 되면 좋겠습니다.\n감사합니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html",
    "title": "시계열 데이터 분석",
    "section": "",
    "text": "KOSPI주가 정보를 저장한 시계열 데이터를 이용해서 정보를 분석하는 연습을 합니다. 시계열데이터 분석을 위해서 시간에 따라 이동시키거나 일정 주기로 추출하는 작업을 수행을 합니다. 일정 기간동안의 통계적 특성을 분석하기 위해서 window을 만들고 이동할 수도 있습니다.\n우선 연습을 위해서 KOSPI주가 정보를 가져옵니다. KOSPI주가 정보를 가져오기 위해 FinanceDataReader 라이브러리를 사용합니다. DataReader함수에 시계열 정보를 가져올 주식 종목 기호 KS11과 시작 시점을 전달합니다.\nimport pandas as pd\nimport numpy as np\nimport FinanceDataReader as fdr\n\nstock_name = 'KS11'\ndf = fdr.DataReader(stock_name, start = '2022-1-1')\ndisplay(df.head(5))\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n2022-01-04\n2991.969971\n2995.250000\n2973.080078\n2989.239990\n2989.239990\n621200\n\n\n2022-01-05\n2984.050049\n2986.199951\n2936.729980\n2953.969971\n2953.969971\n786900\n\n\n2022-01-06\n2925.399902\n2952.540039\n2915.379883\n2920.530029\n2920.530029\n785500\n\n\n2022-01-07\n2933.780029\n2959.030029\n2933.100098\n2954.889893\n2954.889893\n545800\n\n\n2022-01-10\n2947.370117\n2951.120117\n2910.899902\n2926.719971\n2926.719971\n477000\n\n\n\n\n\nFigure 1: KOPI 시계열 데이터\n리턴된 데이터를 간단하게 살펴봅니다. 시간 정보로 Index가 표시되고 주가 정보는 각 컬럼에 표시됩니다. 해당 시점의 고점, 저점, 종가, 수정 종가, 시가 총액이 각각 컬럼으로 있습니다.\nFigure 1 의 index의 데이터 형식은 DatetimeIndex로 출력됩니다. 따라서 시계열 데이터 분석에 사용할 수 있는 Pandas 기능을 사용할 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#shift",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#shift",
    "title": "시계열 데이터 분석",
    "section": "shift()",
    "text": "shift()\n시간을 이동시키는 명령어인 shift()함수를 알아봅니다. shift()함수는 지정한 수만큼 인덱스를 이동 시키는 명령입니다. Figure 1 데이터 프레임은 한국 주식 시장이 운영기간을 하루 단위로 측정된 시계열 데이터 프레임입니다. shift()명령을 이용하여 Close컬럼 데이터를 1개 Index크기 만큼 앞으로 이동합니다.\n\ndf['Close+1'] = df['Close'].shift(1)\ndisplay(df[['Close', 'Close+1']].head(5))\n\n\n\n\n\n\n\n\nClose\nClose+1\n\n\nDate\n\n\n\n\n\n\n2022-01-04\n2989.239990\nNaN\n\n\n2022-01-05\n2953.969971\n2989.239990\n\n\n2022-01-06\n2920.530029\n2953.969971\n\n\n2022-01-07\n2954.889893\n2920.530029\n\n\n2022-01-10\n2926.719971\n2954.889893\n\n\n\n\n\n\n\n비교를 쉽게하기 위해서 Close와 Close+1 컬럼만 표시하여 결과를 확인합니다. 새롭게 생성한 Close+1 컬럼은 Close 컬럼이 이동되어 저장되었습니다. 정보를 가져올 수 없는 2023-01-02 인덱스 정보는 NaN으로 표시됩니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#asfreq",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#asfreq",
    "title": "시계열 데이터 분석",
    "section": "asfreq()",
    "text": "asfreq()\n시계열 데이터 프레임을 새로운 빈도로 변환하기 위해서 as_freq()함수를 사용합니다. KOSPI주가 데이터의 월별 종가 정보를 확인할 수 있도록 이 함수를 사용해 봅니다.\n\ndf_monthly = df.asfreq('M')\ndisplay(df_monthly.head(5))\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nClose+1\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2022-01-31\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2022-02-28\n2663.000000\n2699.179932\n2658.250000\n2699.179932\n2699.179932\n613300.0\n2676.760010\n\n\n2022-03-31\n2743.239990\n2765.199951\n2743.199951\n2757.649902\n2757.649902\n1029500.0\n2746.739990\n\n\n2022-04-30\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2022-05-31\n2666.879883\n2685.899902\n2654.320068\n2685.899902\n2685.899902\n670700.0\n2669.659912\n\n\n\n\n\n\n\n결과를 보면 NaN으로 데이터가 처리된 부분이 있습니다. 2020년 1월 31일과 2022년 4월 30일 데이터는 왜 없는 걸까요?\n\nstart_day = pd.Timestamp('2022-01-28 00:00:00')\nend_day = start_day + pd.DateOffset(days = 10)\ndf.loc[start_day : end_day, :]\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nClose+1\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2022-01-28\n2617.870117\n2668.590088\n2591.530029\n2663.340088\n2663.340088\n433700\n2614.489990\n\n\n2022-02-03\n2706.340088\n2735.340088\n2702.780029\n2707.820068\n2707.820068\n435300\n2663.340088\n\n\n2022-02-04\n2714.830078\n2751.800049\n2712.870117\n2750.260010\n2750.260010\n535900\n2707.820068\n\n\n2022-02-07\n2750.699951\n2750.699951\n2718.939941\n2745.060059\n2745.060059\n417600\n2750.260010\n\n\n\n\n\n\n\n시작일을 2022-01-28일로 설정하고 시작일로 부터 10일 간격 뒤의 시간을 종료일로 설정 후 해당 위치의 데이터 프레임 정보를 확인합니다. 1월의 마지막은 1월 31일이지만 주식시장은 1월 28일 거래로 폐장 후 2월에 개장하기 때문에 데이터가 없는 상태입니다.\nasfreq()로 간격을 설정한 기준은 월말을 기준으로 했기 때문에 해당 시점에 데이터가 없어 NaN으로 결과가 출력 되었습니다.\n\n\n\n\n\n\nTip\n\n\n\n새로운 시간 단위를 설정 시 새롭게 설정하는 시간간격에 맞는 원데이터가 없는 경우 NaN으로 데이터가 표시되기 때문에 결과에 유의 해야합니다.\n\n\n주식정보를 갖는 이 데이터 프레임의 특성 상 해당 날짜에 주가 정보가 없다면 직전 날짜의 주가 정보를 유지하면 될 것 같습니다. 1월 28일의 마지막 주가 정보를 1월말 주가 정보로 대체해도 문제가 없는 데이터이기 때문에 as_freq()함수의 method인자를 이용합니다.\nmethod인자에는 NaN으로 표시된 결측치를 어떤 정보로 채울지 결정할 정보를 전달합니다. API문서를 확인하면 bfill과 ffill을 지원한다고 합니다. 우리의 경우 이전 시점의 데이터로 결측치를 채울 예정이니 ffill로 설정합니다.\n\ndf_monthly = df.asfreq('M', method='ffill')\ndisplay(df_monthly.head(5))\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nClose+1\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2022-01-31\n2617.870117\n2668.590088\n2591.530029\n2663.340088\n2663.340088\n433700\n2614.489990\n\n\n2022-02-28\n2663.000000\n2699.179932\n2658.250000\n2699.179932\n2699.179932\n613300\n2676.760010\n\n\n2022-03-31\n2743.239990\n2765.199951\n2743.199951\n2757.649902\n2757.649902\n1029500\n2746.739990\n\n\n2022-04-30\n2669.179932\n2696.100098\n2664.060059\n2695.050049\n2695.050049\n975000\n2667.489990\n\n\n2022-05-31\n2666.879883\n2685.899902\n2654.320068\n2685.899902\n2685.899902\n670700\n2669.659912\n\n\n\n\n\n\n\n이번에는 월말인 2022년 1월 31일 데이터가 NaN이 아니고 이전 시점의 데이터로 업데이트 된 것을 알 수 있습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#resample",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#resample",
    "title": "시계열 데이터 분석",
    "section": "resample()",
    "text": "resample()\nresample()함수는 주어진 빈도로 리샘플링할 때 사용합니다. 데이터를 보간하여 빈 시간대에 대한 새로운 값을 생성합니다. 시간을 기반으로 한 데이터에 적용하는 groupby함수로 생각할 수 있습니다.\nasfreq()함수는 주기를 변경하기 위해 사용되어 해당 시점에 원데이터가 없다면 NaN으로 표시됩니다.\n\ndf_monthly = df.resample('M').last()\ndf_monthly.head(5)\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nClose+1\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2022-01-31\n2617.870117\n2668.590088\n2591.530029\n2663.340088\n2663.340088\n433700\n2614.489990\n\n\n2022-02-28\n2663.000000\n2699.179932\n2658.250000\n2699.179932\n2699.179932\n613300\n2676.760010\n\n\n2022-03-31\n2743.239990\n2765.199951\n2743.199951\n2757.649902\n2757.649902\n1029500\n2746.739990\n\n\n2022-04-30\n2669.179932\n2696.100098\n2664.060059\n2695.050049\n2695.050049\n975000\n2667.489990\n\n\n2022-05-31\n2666.879883\n2685.899902\n2654.320068\n2685.899902\n2685.899902\n670700\n2669.659912\n\n\n\n\n\n\n\n\n\nresample()함수에 시간 간격이 전달된 후 리턴되는 객체는 DatetimeIndexResampler입니다. 이 객체에 시간단위로 그룹된 데이터를 처리할 방식을 전달합니다. 월단위로 리샘플링된 그룹에 마지막 값을 취하기 위해서 last()를 수행하여 매월 마지막 주가정보로 저장되었습니다.\n\ndf_monthly = df.resample('M').mean()\ndf_monthly.head(5)\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nClose+1\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2022-01-31\n2872.972116\n2886.611598\n2842.880525\n2859.066830\n2859.066830\n5.516632e+05\n2869.940538\n\n\n2022-02-28\n2722.530002\n2740.107788\n2703.206665\n2724.015015\n2724.015015\n5.617500e+05\n2722.023912\n\n\n2022-03-31\n2699.054316\n2710.955694\n2684.923840\n2698.716192\n2698.716192\n6.851857e+05\n2695.931908\n\n\n2022-04-30\n2700.210007\n2711.937163\n2688.504790\n2703.242850\n2703.242850\n1.048310e+06\n2706.223796\n\n\n2022-05-31\n2628.057971\n2642.537500\n2613.529016\n2629.215002\n2629.215002\n7.979600e+05\n2629.672510\n\n\n\n\n\n\n\n\n\nKOSPI주가 지수의 월별 평균값을 구해봅니다. 시간간격은 동일하게 월 단위이고 해당 시간 단위 데이터를 평균하기 위해 mean함수를 사용했습니다."
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#rolling",
    "href": "book_blog/posts/2023-09-03-data-visualization/time_series_analysis.html#rolling",
    "title": "시계열 데이터 분석",
    "section": "rolling()",
    "text": "rolling()\n시계열 정보에서는 여러가지 이동 통계를 사용합니다. 일반적으로 이동 평균, 이동 표준 편차등이 주로 사용됩니다. 이동 통계를 이용하면 시계열 데이터의 추세를 확인할 수 있으며 이상치 검출에도 사용할 수 있습니다. 이동 윈도우에 크기에 따라서 데이터를 부드럽게 만들 수 있기 때문에 데이터가 가지는 불필요한 고주파 노이즈를 제거할 수 있습니다.\nPandas에서는 rolling()함수로 롤링 윈도우를 지원합니다. 이 함수를 이용해서 KOSPI 지수의 60일 이동평균값을 확인해봅니다.\n\ndf_monthly = df.rolling('60d').mean()\ndf_monthly.head(5)\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nClose+1\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2022-01-04\n2991.969971\n2995.250000\n2973.080078\n2989.239990\n2989.239990\n621200.0\nNaN\n\n\n2022-01-05\n2988.010010\n2990.724976\n2954.905029\n2971.604981\n2971.604981\n704050.0\n2989.239990\n\n\n2022-01-06\n2967.139974\n2977.996663\n2941.729980\n2954.579997\n2954.579997\n731200.0\n2971.604981\n\n\n2022-01-07\n2958.799988\n2973.255005\n2939.572510\n2954.657471\n2954.657471\n684850.0\n2954.579997\n\n\n2022-01-10\n2956.514014\n2968.828027\n2933.837988\n2949.069971\n2949.069971\n643280.0\n2954.657471"
  },
  {
    "objectID": "book_blog/posts/2023-09-03-data-visualization/intro.html",
    "href": "book_blog/posts/2023-09-03-data-visualization/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "데이터 시각화 과정을 정리하고 결과를 정리하기 위한 책입니다."
  },
  {
    "objectID": "dashboard_blog/posts/nsi/nsi.html",
    "href": "dashboard_blog/posts/nsi/nsi.html",
    "title": "NSI",
    "section": "",
    "text": "NSI\n뉴스 감성 지수(NSI)는 뉴스 기사를 분석하여 경제적 감성을 측정하는 지표입니다. 자연어 처리(NLP) 기술을 사용하여 뉴스 콘텐츠에 표현된 톤과 감정을 평가합니다. 다음은 NSI의 작동 방식과 그 중요성에 대한 간략한 설명입니다\n온라인 뉴스 플랫폼과 소셜 미디어를 포함한 다양한 소스에서 대규모 뉴스 기사 데이터를 수집합니다. 수집된 텍스트에서 광고 및 특수 문자를 제거하여 데이터를 분석에 적합한 형식으로 정리합니다.\n신경망 기반의 머신러닝 모델을 사용하여 텍스트에 표현된 감정을 식별하고 분류합니다. 이 모델은 긍정적, 부정적, 중립적 감정을 구분할 수 있습니다. 감성 점수를 집계하여 각 뉴스 소스의 전반적인 감성 점수를 계산합니다. 이 점수는 뉴스 기사에 표현된 일반적인 분위기나 감정을 반영합니다.\nNSI지수는 100을 기준으로 100을 초과하면 긍정을 의미하고 그 반대의 경우 부정적인 뉴스가 많다는 것을 의미합니다."
  },
  {
    "objectID": "dashboard_blog/posts/commercial/commercial.html",
    "href": "dashboard_blog/posts/commercial/commercial.html",
    "title": "상권분석",
    "section": "",
    "text": "서울 지역 상권 중 유동인구가 높은 주요 상권을 알아보고 각 상권의 연령별 특징을 알아봅니다. 20~30대 연령과 40~50대 유동인구가 높은 상권이 어떤 지역인지 살펴봅니다.\n연령별 특징을 확인하면 해당 상권의 소비 패턴을 예상할 수 있고 특정 연령층을 타겟으로 한 마케팅 전략을 세울 수 있습니다. 예를 들어, 특정 지역의 주요 유동인구가 20대에서 30대인 경우, 이들이 선호하는 상품이나 서비스를 개발하거나 마케팅 전략을 세울 수 있습니다.\n\n\n우리나라 상권 중 총 유동인구수가 높은 지역은 어디일까요? 상권 중 총 유동인구가 높은 지역을 확인하고 상위 10개 지역을 알아봅니다. 데이터는 2024년 1분기 총 유동인구를 표시합니다.\n\n\n\n                                                \n\n\n 총 유동인구수를 기준으로 정렬한 결과 종로/청계 관광특구가 1위를 차지 했습니다. 2위는 강남역입니다.\n상권과 함께 까치산역, 종로3가역, 수유역, 선릉역, 충정로역, 화곡역이 유동인구 상위 순위에 포함되었습니다. 해당 역의 유동인구과 상권을 분석하면 상권의 특징을 좀 더 자세히 알 수 있을 것 같습니다.\n\n\n\n\n\n\n\n\n\n상권에 대한 특징은 상권의 유동인구 정보로 이해할 수 있다.\n\n\n\n상권에 대한 특징을 알기 위해서 여러가지 정보를 확인할 수 있습니다. 그 중 연령별 유동인구를 사용하면 상권 정보를 잘 구분할 수 있을까요?\n\n\n\n유동인구 수가 높은 상위 지역별 상권의 특징을 확인하기 위해서 상위 7개 지역에 대한 연령별 유동인구 수를 확인 합니다. 데이터의 특징을 분석하며 가설을 검증해 봅니다.\n총 유동인구가 많은 7개 지역의 연령대별 유동인구를 조사합니다. 7개 지역은 각각 종로/청계 관광특구, 강남역, 명동/남대문/무교동 관광특구, 신촌역, 종로3가, 까치산역, 수유역입니다.\n각 지역에서 어떤 연령대 비율이 많은지 비교하기 위해서 각 지역의 연령별 유동인구수를 총 유동인구 수로 나누어 연령별 비율 정보를 확인하고 그래프로 표시합니다.\n\n\n\n                                                \n\n\n\n\n\n20대 유동인구가 많은 특징을 보이는 지역은 신촌, 홍대, 강남역, 신림역, 관악구입니다.\n선택된 지역들은 모두 20대 연령대가 높은 특징을 갖고 있으며 신촌역과 홍대입구역은 20대 연령대에 특화 되어 있으며 그외 지역은 20~30대에 좀 더 넓게 분포하고 있습니다. 대학가의 특징으로 발생하는 분석 결과로 보입니다.\n따라서 대학가 20대 연령에 대한 특징은 신촌, 홍대 상권가에서 두드러지게 보일 것으로 보이며 좀 더 일반적인 20대 연령에 대한 특징은 그 외 지역인 강남역, 신림역, 관악구에서 확인할 수 있을 것으로 보입니다.\n\n\n\n                                                \n\n\n\n\n\n40~50대 유동인구가 많은 특징을 보이는 지역은 충정로, 선릉역, 명동, 종로, 까치산, 망리단길입니다.\n선택된 지역들은 모두 40~50대 연령대가 높은 특징을 갖고 있으며 충정로역는 전체 중 55% 40~50대 연령대에 분포하여 해당 연령대 비율이 가장 높습니다. 선릉, 명동 역시 53%로 높은 비율을 보입니다.\n\n\n\n                                                \n\n\n궁금한 내용은 댓글로 알려주세요~"
  },
  {
    "objectID": "dashboard_blog/posts/commercial/commercial.html#상권-유동인구-분석",
    "href": "dashboard_blog/posts/commercial/commercial.html#상권-유동인구-분석",
    "title": "상권분석",
    "section": "",
    "text": "우리나라 상권 중 총 유동인구수가 높은 지역은 어디일까요? 상권 중 총 유동인구가 높은 지역을 확인하고 상위 10개 지역을 알아봅니다. 데이터는 2024년 1분기 총 유동인구를 표시합니다.\n\n\n\n                                                \n\n\n 총 유동인구수를 기준으로 정렬한 결과 종로/청계 관광특구가 1위를 차지 했습니다. 2위는 강남역입니다.\n상권과 함께 까치산역, 종로3가역, 수유역, 선릉역, 충정로역, 화곡역이 유동인구 상위 순위에 포함되었습니다. 해당 역의 유동인구과 상권을 분석하면 상권의 특징을 좀 더 자세히 알 수 있을 것 같습니다."
  },
  {
    "objectID": "dashboard_blog/posts/commercial/commercial.html#가설-설정",
    "href": "dashboard_blog/posts/commercial/commercial.html#가설-설정",
    "title": "상권분석",
    "section": "",
    "text": "상권에 대한 특징은 상권의 유동인구 정보로 이해할 수 있다.\n\n\n\n상권에 대한 특징을 알기 위해서 여러가지 정보를 확인할 수 있습니다. 그 중 연령별 유동인구를 사용하면 상권 정보를 잘 구분할 수 있을까요?"
  },
  {
    "objectID": "dashboard_blog/posts/commercial/commercial.html#연령별-유동인구-분석",
    "href": "dashboard_blog/posts/commercial/commercial.html#연령별-유동인구-분석",
    "title": "상권분석",
    "section": "",
    "text": "유동인구 수가 높은 상위 지역별 상권의 특징을 확인하기 위해서 상위 7개 지역에 대한 연령별 유동인구 수를 확인 합니다. 데이터의 특징을 분석하며 가설을 검증해 봅니다.\n총 유동인구가 많은 7개 지역의 연령대별 유동인구를 조사합니다. 7개 지역은 각각 종로/청계 관광특구, 강남역, 명동/남대문/무교동 관광특구, 신촌역, 종로3가, 까치산역, 수유역입니다.\n각 지역에서 어떤 연령대 비율이 많은지 비교하기 위해서 각 지역의 연령별 유동인구수를 총 유동인구 수로 나누어 연령별 비율 정보를 확인하고 그래프로 표시합니다."
  },
  {
    "objectID": "dashboard_blog/posts/commercial/commercial.html#대-유동인구",
    "href": "dashboard_blog/posts/commercial/commercial.html#대-유동인구",
    "title": "상권분석",
    "section": "",
    "text": "20대 유동인구가 많은 특징을 보이는 지역은 신촌, 홍대, 강남역, 신림역, 관악구입니다.\n선택된 지역들은 모두 20대 연령대가 높은 특징을 갖고 있으며 신촌역과 홍대입구역은 20대 연령대에 특화 되어 있으며 그외 지역은 20~30대에 좀 더 넓게 분포하고 있습니다. 대학가의 특징으로 발생하는 분석 결과로 보입니다.\n따라서 대학가 20대 연령에 대한 특징은 신촌, 홍대 상권가에서 두드러지게 보일 것으로 보이며 좀 더 일반적인 20대 연령에 대한 특징은 그 외 지역인 강남역, 신림역, 관악구에서 확인할 수 있을 것으로 보입니다."
  },
  {
    "objectID": "dashboard_blog/posts/commercial/commercial.html#대-유동인구-1",
    "href": "dashboard_blog/posts/commercial/commercial.html#대-유동인구-1",
    "title": "상권분석",
    "section": "",
    "text": "40~50대 유동인구가 많은 특징을 보이는 지역은 충정로, 선릉역, 명동, 종로, 까치산, 망리단길입니다.\n선택된 지역들은 모두 40~50대 연령대가 높은 특징을 갖고 있으며 충정로역는 전체 중 55% 40~50대 연령대에 분포하여 해당 연령대 비율이 가장 높습니다. 선릉, 명동 역시 53%로 높은 비율을 보입니다.\n\n\n\n                                                \n\n\n궁금한 내용은 댓글로 알려주세요~"
  },
  {
    "objectID": "blog/posts/2024/20240724.html",
    "href": "blog/posts/2024/20240724.html",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "GitHub Actions는 GitHub 저장소에서 CI/CD(Continuous Integration/Continuous Deployment) 파이프라인을 쉽게 설정하고 관리할 수 있는 강력한 도구입니다. 이 블로그 글에서는 GitHub Actions를 사용하여 CI/CD 파이프라인을 구축하는 방법을 단계별로 설명하겠습니다.\n\n\nGitHub Actions는 코드를 빌드, 테스트, 배포하는 워크플로우를 자동화할 수 있는 기능을 제공합니다. GitHub 저장소에 push, pull request, issue 등 이벤트가 발생할 때마다 워크플로우를 트리거할 수 있습니다.\n\n\n\n\n워크플로우(Workflow): 하나 이상의 작업으로 구성된 자동화 프로세스.\n잡(Job): 워크플로우 내에서 실행되는 개별 단위 작업.\n스텝(Step): 잡 내에서 실행되는 명령어 또는 액션.\n액션(Action): 재사용 가능한 커뮤니티 또는 사용자 정의 스크립트.\n\n\n\n\n워크플로우 파일은 .github/workflows 디렉토리에 YAML 형식으로 저장됩니다. 예를 들어, ci.yml 파일을 생성하여 기본적인 CI 설정을 할 수 있습니다.\n\n\nname: Node.js CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: npm install\n\n    - name: Run tests\n      run: npm test\n\n\n\n\nname: 워크플로우의 이름. 이 이름은 GitHub Actions 인터페이스에서 워크플로우를 식별하는 데 사용됩니다.\non: 워크플로우가 트리거되는 이벤트. 워크플로우를 트리거하는 이벤트를 정의합니다. 이 예제에서는 push와 pull_request 이벤트를 사용하여 워크플로우를 트리거합니다.\njobs: 워크플로우 내에서 실행되는 작업들.\nruns-on: 작업이 실행될 환경(예: ubuntu-latest). 작업이 실행될 환경을 지정합니다. 이 예제에서는 ubuntu-latest를 사용하여 최신 버전의 우분투에서 작업이 실행됩니다.\nsteps: 작업 내에서 실행되는 단계들. 작업 내에서 실행될 단계(Step)들을 정의합니다. 단계는 순차적으로 실행됩니다.\n\nuses: 특정 액션을 사용하는 단계. GitHub에서 제공하는 액션을 사용합니다.\n\nactions/checkout@v2는 GitHub 저장소를 체크아웃하는 액션입니다.\nactions/setup-node@v2는 Node.js를 설정하는 액션입니다.\n\nwith: 액션에 전달할 매개변수를 정의합니다. 여기서는 node-version: ’14’를 사용하여 Node.js 버전 14를 설정합니다.\nrun: 명령어를 실행하는 단계.\n\n\n\n\n\n\n\n\n반복적인 의존성 설치를 빠르게 하기 위해 캐싱을 사용할 수 있습니다.\n    - name: Cache dependencies\n      uses: actions/cache@v2\n      with:\n        path: ~/.npm\n        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n        restore-keys: |\n          ${{ runner.os }}-node-\n\n\n\n여러 환경에서 테스트를 실행하기 위해 매트릭스 전략을 사용할 수 있습니다.\n매트릭스 전략은 CI/CD 워크플로우에서 여러 가지 설정 조합을 테스트할 때 유용한 기능입니다. 이를 통해 코드가 다양한 환경에서 제대로 작동하는지 확인할 수 있습니다. 매트릭스 전략을 사용하면 여러 버전의 언어, 운영 체제, 그리고 기타 종속성 조합에서 빌드와 테스트를 자동화할 수 있습니다.\n매트릭스 전략은 jobs..strategy.matrix 속성을 사용하여 설정합니다. 매트릭스의 각 키는 여러 값을 가질 수 있으며, GitHub Actions는 각 조합에 대해 잡을 실행합니다.\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [12, 14, 16]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run: npm install\n\n    - name: Run tests\n      run: npm test\n\n\n\nCI 파이프라인이 성공하면 자동으로 배포할 수 있습니다.\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Deploy to server\n      run: |\n        ssh user@your-server 'bash -s' &lt; deploy-script.sh\n      env:\n        SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}\n\n\n\n\n배포 시 민감한 정보(예: API 키, 서버 비밀번호)는 GitHub Secrets를 통해 관리할 수 있습니다.\n\n저장소 페이지로 이동.\nSettings 탭 선택.\nSecrets 메뉴에서 New repository secret 버튼 클릭.\n이름과 값을 입력하고 저장.\n\n\n\n\n이제 GitHub Actions를 사용하여 간단한 CI/CD 파이프라인을 구축할 수 있게 되었습니다. GitHub Actions는 매우 유연하고 강력한 도구로, 다양한 요구사항에 맞게 확장할 수 있습니다. 더 많은 정보를 원하시면 GitHub Actions 공식 문서를 참고하세요."
  },
  {
    "objectID": "blog/posts/2024/20240724.html#github-actions-소개",
    "href": "blog/posts/2024/20240724.html#github-actions-소개",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "GitHub Actions는 코드를 빌드, 테스트, 배포하는 워크플로우를 자동화할 수 있는 기능을 제공합니다. GitHub 저장소에 push, pull request, issue 등 이벤트가 발생할 때마다 워크플로우를 트리거할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2024/20240724.html#기본-용어-이해하기",
    "href": "blog/posts/2024/20240724.html#기본-용어-이해하기",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "워크플로우(Workflow): 하나 이상의 작업으로 구성된 자동화 프로세스.\n잡(Job): 워크플로우 내에서 실행되는 개별 단위 작업.\n스텝(Step): 잡 내에서 실행되는 명령어 또는 액션.\n액션(Action): 재사용 가능한 커뮤니티 또는 사용자 정의 스크립트."
  },
  {
    "objectID": "blog/posts/2024/20240724.html#워크플로우-파일-생성",
    "href": "blog/posts/2024/20240724.html#워크플로우-파일-생성",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "워크플로우 파일은 .github/workflows 디렉토리에 YAML 형식으로 저장됩니다. 예를 들어, ci.yml 파일을 생성하여 기본적인 CI 설정을 할 수 있습니다.\n\n\nname: Node.js CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: npm install\n\n    - name: Run tests\n      run: npm test\n\n\n\n\nname: 워크플로우의 이름. 이 이름은 GitHub Actions 인터페이스에서 워크플로우를 식별하는 데 사용됩니다.\non: 워크플로우가 트리거되는 이벤트. 워크플로우를 트리거하는 이벤트를 정의합니다. 이 예제에서는 push와 pull_request 이벤트를 사용하여 워크플로우를 트리거합니다.\njobs: 워크플로우 내에서 실행되는 작업들.\nruns-on: 작업이 실행될 환경(예: ubuntu-latest). 작업이 실행될 환경을 지정합니다. 이 예제에서는 ubuntu-latest를 사용하여 최신 버전의 우분투에서 작업이 실행됩니다.\nsteps: 작업 내에서 실행되는 단계들. 작업 내에서 실행될 단계(Step)들을 정의합니다. 단계는 순차적으로 실행됩니다.\n\nuses: 특정 액션을 사용하는 단계. GitHub에서 제공하는 액션을 사용합니다.\n\nactions/checkout@v2는 GitHub 저장소를 체크아웃하는 액션입니다.\nactions/setup-node@v2는 Node.js를 설정하는 액션입니다.\n\nwith: 액션에 전달할 매개변수를 정의합니다. 여기서는 node-version: ’14’를 사용하여 Node.js 버전 14를 설정합니다.\nrun: 명령어를 실행하는 단계."
  },
  {
    "objectID": "blog/posts/2024/20240724.html#고급-설정",
    "href": "blog/posts/2024/20240724.html#고급-설정",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "반복적인 의존성 설치를 빠르게 하기 위해 캐싱을 사용할 수 있습니다.\n    - name: Cache dependencies\n      uses: actions/cache@v2\n      with:\n        path: ~/.npm\n        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n        restore-keys: |\n          ${{ runner.os }}-node-\n\n\n\n여러 환경에서 테스트를 실행하기 위해 매트릭스 전략을 사용할 수 있습니다.\n매트릭스 전략은 CI/CD 워크플로우에서 여러 가지 설정 조합을 테스트할 때 유용한 기능입니다. 이를 통해 코드가 다양한 환경에서 제대로 작동하는지 확인할 수 있습니다. 매트릭스 전략을 사용하면 여러 버전의 언어, 운영 체제, 그리고 기타 종속성 조합에서 빌드와 테스트를 자동화할 수 있습니다.\n매트릭스 전략은 jobs..strategy.matrix 속성을 사용하여 설정합니다. 매트릭스의 각 키는 여러 값을 가질 수 있으며, GitHub Actions는 각 조합에 대해 잡을 실행합니다.\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [12, 14, 16]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v2\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run: npm install\n\n    - name: Run tests\n      run: npm test\n\n\n\nCI 파이프라인이 성공하면 자동으로 배포할 수 있습니다.\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    - name: Deploy to server\n      run: |\n        ssh user@your-server 'bash -s' &lt; deploy-script.sh\n      env:\n        SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}"
  },
  {
    "objectID": "blog/posts/2024/20240724.html#github-secrets-사용",
    "href": "blog/posts/2024/20240724.html#github-secrets-사용",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "배포 시 민감한 정보(예: API 키, 서버 비밀번호)는 GitHub Secrets를 통해 관리할 수 있습니다.\n\n저장소 페이지로 이동.\nSettings 탭 선택.\nSecrets 메뉴에서 New repository secret 버튼 클릭.\n이름과 값을 입력하고 저장."
  },
  {
    "objectID": "blog/posts/2024/20240724.html#마무리",
    "href": "blog/posts/2024/20240724.html#마무리",
    "title": "GitHub Actions 시작하기",
    "section": "",
    "text": "이제 GitHub Actions를 사용하여 간단한 CI/CD 파이프라인을 구축할 수 있게 되었습니다. GitHub Actions는 매우 유연하고 강력한 도구로, 다양한 요구사항에 맞게 확장할 수 있습니다. 더 많은 정보를 원하시면 GitHub Actions 공식 문서를 참고하세요."
  },
  {
    "objectID": "blog/posts/2024/20240105.html",
    "href": "blog/posts/2024/20240105.html",
    "title": "SQL 정렬 명령 order by",
    "section": "",
    "text": "이 글에서는 SQL의 ORDER BY 구문을 사용하는 실제 예시를 살펴보겠습니다. 먼저, 간단한 가상의 데이터베이스 정보를 설정하고, 이를 기반으로 ORDER BY 구문을 사용하는 다양한 쿼리와 그 결과를 보여드리겠습니다. 이를 통해, ORDER BY 구문의 사용방법을 정리합니다.\n\n\n가상 데이터베이스 “StudentDB”를 사용하여 ORDER BY의 다중 정렬 기능을 살펴보겠습니다. “StudentDB”는 ‘Student’ 테이블을 포함하며, 이름, 나이, 전공 등의 정보를 담고 있습니다.\n\n\n\nID\nName\nAge\nMajor\n\n\n\n\n1\nJim\n20\nComputer Science\n\n\n2\nYuna\n19\nMathematics\n\n\n3\nHoseok\n20\nPhysics\n\n\n4\nSeong\n21\nEnglish Literature\n\n\n5\nMin\n20\nBiology\n\n\n\n\n\n\n전공 컬럼을 오름차순으로 정렬하는 코드입니다. 전체 컬럼 정보를 Student 테이블에서 선택하고 Major컬럼을 오름차순으로 정렬합니다.\nSELECT * FROM Student\nORDER BY Major ASC;\n\n\n\nID\nName\nAge\nMajor\n\n\n\n\n1\nJim\n20\nComputer Science\n\n\n5\nMin\n20\nBiology\n\n\n4\nSeong\n21\nEnglish Literature\n\n\n2\nYuna\n19\nMathematics\n\n\n3\nHoseok\n20\nPhysics\n\n\n\n\n\n\n나이 컬럼을 내림차순으로 정렬하는 코드입니다. Student 테이블에서 Name, Age컬럼을 선택하고 Age컬럼을 내림차순으로 정렬합니다.\nSELECT Name, Age FROM Student\nORDER BY Age DESC;\n\n\n\nName\nAge\n\n\n\n\nSeong\n21\n\n\nJim\n20\n\n\nHoseok\n20\n\n\nMin\n20\n\n\nYuna\n19\n\n\n\n\n\n\n나이로 오름차순 정렬 후, 동일 나이일 경우 이름으로 내림차순 정렬하는 코드입니다. Name과 Age 컬럼을 선택했습니다. 나이가 20인 Min, Jim, Hosok은 내림차순으로 정렬됩니다.\nSELECT Name, Age FROM Student\nORDER BY Age ASC, Name DESC;\n\n\n\nName\nAge\n\n\n\n\nYuna\n19\n\n\nMin\n20\n\n\nJim\n20\n\n\nHoseok\n20\n\n\nSeong\n21"
  },
  {
    "objectID": "blog/posts/2024/20240105.html#가상-데이터-구조",
    "href": "blog/posts/2024/20240105.html#가상-데이터-구조",
    "title": "SQL 정렬 명령 order by",
    "section": "",
    "text": "가상 데이터베이스 “StudentDB”를 사용하여 ORDER BY의 다중 정렬 기능을 살펴보겠습니다. “StudentDB”는 ‘Student’ 테이블을 포함하며, 이름, 나이, 전공 등의 정보를 담고 있습니다.\n\n\n\nID\nName\nAge\nMajor\n\n\n\n\n1\nJim\n20\nComputer Science\n\n\n2\nYuna\n19\nMathematics\n\n\n3\nHoseok\n20\nPhysics\n\n\n4\nSeong\n21\nEnglish Literature\n\n\n5\nMin\n20\nBiology"
  },
  {
    "objectID": "blog/posts/2024/20240105.html#전공major을-기준으로-오름차순-정렬",
    "href": "blog/posts/2024/20240105.html#전공major을-기준으로-오름차순-정렬",
    "title": "SQL 정렬 명령 order by",
    "section": "",
    "text": "전공 컬럼을 오름차순으로 정렬하는 코드입니다. 전체 컬럼 정보를 Student 테이블에서 선택하고 Major컬럼을 오름차순으로 정렬합니다.\nSELECT * FROM Student\nORDER BY Major ASC;\n\n\n\nID\nName\nAge\nMajor\n\n\n\n\n1\nJim\n20\nComputer Science\n\n\n5\nMin\n20\nBiology\n\n\n4\nSeong\n21\nEnglish Literature\n\n\n2\nYuna\n19\nMathematics\n\n\n3\nHoseok\n20\nPhysics"
  },
  {
    "objectID": "blog/posts/2024/20240105.html#나이age를-기준으로-내림차순-정렬",
    "href": "blog/posts/2024/20240105.html#나이age를-기준으로-내림차순-정렬",
    "title": "SQL 정렬 명령 order by",
    "section": "",
    "text": "나이 컬럼을 내림차순으로 정렬하는 코드입니다. Student 테이블에서 Name, Age컬럼을 선택하고 Age컬럼을 내림차순으로 정렬합니다.\nSELECT Name, Age FROM Student\nORDER BY Age DESC;\n\n\n\nName\nAge\n\n\n\n\nSeong\n21\n\n\nJim\n20\n\n\nHoseok\n20\n\n\nMin\n20\n\n\nYuna\n19"
  },
  {
    "objectID": "blog/posts/2024/20240105.html#한개이상-정보를-사용하여-정렬하기",
    "href": "blog/posts/2024/20240105.html#한개이상-정보를-사용하여-정렬하기",
    "title": "SQL 정렬 명령 order by",
    "section": "",
    "text": "나이로 오름차순 정렬 후, 동일 나이일 경우 이름으로 내림차순 정렬하는 코드입니다. Name과 Age 컬럼을 선택했습니다. 나이가 20인 Min, Jim, Hosok은 내림차순으로 정렬됩니다.\nSELECT Name, Age FROM Student\nORDER BY Age ASC, Name DESC;\n\n\n\nName\nAge\n\n\n\n\nYuna\n19\n\n\nMin\n20\n\n\nJim\n20\n\n\nHoseok\n20\n\n\nSeong\n21"
  },
  {
    "objectID": "blog/posts/2023/20231222.html",
    "href": "blog/posts/2023/20231222.html",
    "title": "Google Gemeni API Key 얻기",
    "section": "",
    "text": "Google Gemini에 대해서 알아보고 API키를 사용하는 방법을 정리합니다.\n\n\nGoogle Gemini는 Google DeepMind가 개발한 고도로 진보된 다중모달 AI 모델입니다. 텍스트, 코드, 오디오, 이미지 및 비디오와 같은 다양한 유형의 정보를 처리하고 이해할 수 있는 능력을 갖추고 있어, 기존의 많은 AI 모델보다 독특하고 다재다능합니다.\n이 모델은 Ultra, Pro, Nano라는 세 가지 버전으로 제공되며, 각각 다른 복잡성과 장치 호환성에 맞게 맞춤화되어 있습니다. Gemini Ultra는 가장 복잡한 작업을 위해 설계된 가장 큰 모델입니다. Gemini Pro는 다양한 응용 프로그램에서 확장 가능한 범위의 작업에 최적화되어 있습니다. Gemini Nano는 스마트폰과 같은 장치에서의 작업을 위해 고안된 가장 효율적인 모델입니다​. Gemini의 주요 강점 중 하나는 다양한 AI 벤치마크에서의 성능입니다. 특히 MMLU 벤치마크와 같은 테스트에서 인간 전문가를 능가하는 결과를 보여주었습니다.\n\n\n\nGemeni API를 사용할 수 있도록 Google Gemini API 페이지로 이동합니다. \n홈페이지에 들어가서 약관에 동의하면 Gemini를 사용할 수 있는 Use Google AI Studio, Develop in your own environment 두 가지 방법을 가이드 합니다. API를 생성하기 위해서 Develop in your own environment와 Create API key in new project를 선택합니다. 생성된 API키가 노출되지 않도록 잘 저장합니다.\n\n\n\nAPI를 파이썬에서 사용하기 위해서 라이브러리를 설치합니다.\npip install google-generativeai\nAPI키를 코드에 바로 사용하는 경우 API키가 노출될 수 있습니다. 환경변수에 KEY를 저장하고 환경변수를 이용해서 API키를 사용합니다. 환경변수(Environment Variable)는 운영 체제에서 사용되는 변수로, 프로그램이나 쉘(shell)이 실행되는 환경에 관한 정보를 포함합니다.\n\n\n\n\n\n\n\n\n운영 체제\n명령어\n설명\n\n\n\n\nWindows\nset API_KEY=12345678910\nWindows에서는 set 명령어를 사용하여 API_KEY라는 환경변수에 ‘12345678910’ 값을 설정합니다.\n\n\nUbuntu\nexport API_KEY=12345678910\nUbuntu에서는 export 명령어로 같은 환경변수를 설정합니다. 이 명령어는 터미널에서 사용됩니다.\n\n\n\n아래는 API 키가 12345678910인 경우 환경변수를 설정하는 코드입니다.\nexport API_KEY=12345678910\n이제 API키를 이용하여 간단한 테스트를 진행합니다. API통해 사용할 수 있는 모델 정보를 확인합니다.\nimport pathlib\nimport textwrap\nimport os\nimport google.generativeai as genai\n\nGOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\ngenai.configure(api_key=GOOGLE_API_KEY)\nfor model in genai.list_models():\n  if 'generateContent' in model.supported_generation_methods:\n    print(model.name)\nmodels/gemini-pro\nmodels/gemini-pro-vision\n위와 같이 gemini-pro와 gemini-pro-vision을 사용할 수 있습니다. Text 입력을 사용하는 gemini-pro를 사용합니다.\nmodel = genai.GenerativeModel('gemini-pro')\nresponse = model.generate_content(\"google의 AI gemini 에 대해서 알려줘\")\n출력은 Markdown으로 표현됩니다. markdown 형식을 표현하기 위해서 to_markdown()함수를 사용합니다.\nfrom IPython.display import Markdown\ndef to_markdown(text):\n  text = text.replace('•', '  *')\n  return Markdown( textwrap.indent(text, '&gt; ', predicate=lambda _: True) )\n\nto_markdown(response.text)\n\n구글의 AI 제미니(Gemini)는 제품의 전반적인 품질과 사용자 경험을 개선하기 위해 머신 러닝을 사용하는 AI 도구입니다. 제미니는 제품 테스터와 엔지니어가 거의 노력 없이 수백만 개의 자동화된 테스트를 실행하고, 문제를 식별하고, 이러한 문제를 해결할 수 있도록 돕습니다. 제미니는 다음과 같은 주요 기능을 제공합니다.\n\n자동화된 테스트: 제미니는 웹사이트, 모바일 앱, 하드웨어 제품을 포함한 다양한 유형의 제품에 대해 자동화된 테스트를 수행할 수 있습니다. 제미니는 사용자 입력, 인터페이스 요소, 성능 등 다양한 요소를 테스트할 수 있습니다.\n문제 식별: 제미니는 테스트 결과를 분석하고 문제를 식별합니다. 이러한 문제에는 버그, 성능 문제, 사용성 문제가 포함될 수 있습니다.\n문제 해결: 제미니는 문제를 식별한 후 해결할 수 있는 권장 사항을 제공합니다. 이러한 권장 사항은 코드 변경, 구성 변경 또는 사용자 인터페이스 변경일 수 있습니다.\n\n제미니는 다양한 업계에서 광범위한 제품을 테스트하는 데 사용되고 있습니다. 예를 들어, 제미니는 구글의 자체 제품인 안드로이드, 크롬, 구글 픽셀을 테스트하는 데 사용됩니다. 제미니는 또한 삼성, LG, 페이스북, 마이크로소프트 등의 기업에서 사용됩니다.\n제미니는 제품의 전반적인 품질과 사용자 경험을 개선하는 데 도움이 되는 강력한 도구입니다. 제미니는 자동화된 테스트, 문제 식별 및 문제 해결을 통해 제품 테스터와 엔지니어가 제품의 품질을 보다 빠르고 효율적으로 개선할 수 있도록 도와줍니다."
  },
  {
    "objectID": "blog/posts/2023/20231222.html#google-gemini는-무엇인가요",
    "href": "blog/posts/2023/20231222.html#google-gemini는-무엇인가요",
    "title": "Google Gemeni API Key 얻기",
    "section": "",
    "text": "Google Gemini는 Google DeepMind가 개발한 고도로 진보된 다중모달 AI 모델입니다. 텍스트, 코드, 오디오, 이미지 및 비디오와 같은 다양한 유형의 정보를 처리하고 이해할 수 있는 능력을 갖추고 있어, 기존의 많은 AI 모델보다 독특하고 다재다능합니다.\n이 모델은 Ultra, Pro, Nano라는 세 가지 버전으로 제공되며, 각각 다른 복잡성과 장치 호환성에 맞게 맞춤화되어 있습니다. Gemini Ultra는 가장 복잡한 작업을 위해 설계된 가장 큰 모델입니다. Gemini Pro는 다양한 응용 프로그램에서 확장 가능한 범위의 작업에 최적화되어 있습니다. Gemini Nano는 스마트폰과 같은 장치에서의 작업을 위해 고안된 가장 효율적인 모델입니다​. Gemini의 주요 강점 중 하나는 다양한 AI 벤치마크에서의 성능입니다. 특히 MMLU 벤치마크와 같은 테스트에서 인간 전문가를 능가하는 결과를 보여주었습니다."
  },
  {
    "objectID": "blog/posts/2023/20231222.html#gemini-api키-만들기",
    "href": "blog/posts/2023/20231222.html#gemini-api키-만들기",
    "title": "Google Gemeni API Key 얻기",
    "section": "",
    "text": "Gemeni API를 사용할 수 있도록 Google Gemini API 페이지로 이동합니다. \n홈페이지에 들어가서 약관에 동의하면 Gemini를 사용할 수 있는 Use Google AI Studio, Develop in your own environment 두 가지 방법을 가이드 합니다. API를 생성하기 위해서 Develop in your own environment와 Create API key in new project를 선택합니다. 생성된 API키가 노출되지 않도록 잘 저장합니다."
  },
  {
    "objectID": "blog/posts/2023/20231222.html#gemini-api키-python에서-사용하기",
    "href": "blog/posts/2023/20231222.html#gemini-api키-python에서-사용하기",
    "title": "Google Gemeni API Key 얻기",
    "section": "",
    "text": "API를 파이썬에서 사용하기 위해서 라이브러리를 설치합니다.\npip install google-generativeai\nAPI키를 코드에 바로 사용하는 경우 API키가 노출될 수 있습니다. 환경변수에 KEY를 저장하고 환경변수를 이용해서 API키를 사용합니다. 환경변수(Environment Variable)는 운영 체제에서 사용되는 변수로, 프로그램이나 쉘(shell)이 실행되는 환경에 관한 정보를 포함합니다.\n\n\n\n\n\n\n\n\n운영 체제\n명령어\n설명\n\n\n\n\nWindows\nset API_KEY=12345678910\nWindows에서는 set 명령어를 사용하여 API_KEY라는 환경변수에 ‘12345678910’ 값을 설정합니다.\n\n\nUbuntu\nexport API_KEY=12345678910\nUbuntu에서는 export 명령어로 같은 환경변수를 설정합니다. 이 명령어는 터미널에서 사용됩니다.\n\n\n\n아래는 API 키가 12345678910인 경우 환경변수를 설정하는 코드입니다.\nexport API_KEY=12345678910\n이제 API키를 이용하여 간단한 테스트를 진행합니다. API통해 사용할 수 있는 모델 정보를 확인합니다.\nimport pathlib\nimport textwrap\nimport os\nimport google.generativeai as genai\n\nGOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\ngenai.configure(api_key=GOOGLE_API_KEY)\nfor model in genai.list_models():\n  if 'generateContent' in model.supported_generation_methods:\n    print(model.name)\nmodels/gemini-pro\nmodels/gemini-pro-vision\n위와 같이 gemini-pro와 gemini-pro-vision을 사용할 수 있습니다. Text 입력을 사용하는 gemini-pro를 사용합니다.\nmodel = genai.GenerativeModel('gemini-pro')\nresponse = model.generate_content(\"google의 AI gemini 에 대해서 알려줘\")\n출력은 Markdown으로 표현됩니다. markdown 형식을 표현하기 위해서 to_markdown()함수를 사용합니다.\nfrom IPython.display import Markdown\ndef to_markdown(text):\n  text = text.replace('•', '  *')\n  return Markdown( textwrap.indent(text, '&gt; ', predicate=lambda _: True) )\n\nto_markdown(response.text)\n\n구글의 AI 제미니(Gemini)는 제품의 전반적인 품질과 사용자 경험을 개선하기 위해 머신 러닝을 사용하는 AI 도구입니다. 제미니는 제품 테스터와 엔지니어가 거의 노력 없이 수백만 개의 자동화된 테스트를 실행하고, 문제를 식별하고, 이러한 문제를 해결할 수 있도록 돕습니다. 제미니는 다음과 같은 주요 기능을 제공합니다.\n\n자동화된 테스트: 제미니는 웹사이트, 모바일 앱, 하드웨어 제품을 포함한 다양한 유형의 제품에 대해 자동화된 테스트를 수행할 수 있습니다. 제미니는 사용자 입력, 인터페이스 요소, 성능 등 다양한 요소를 테스트할 수 있습니다.\n문제 식별: 제미니는 테스트 결과를 분석하고 문제를 식별합니다. 이러한 문제에는 버그, 성능 문제, 사용성 문제가 포함될 수 있습니다.\n문제 해결: 제미니는 문제를 식별한 후 해결할 수 있는 권장 사항을 제공합니다. 이러한 권장 사항은 코드 변경, 구성 변경 또는 사용자 인터페이스 변경일 수 있습니다.\n\n제미니는 다양한 업계에서 광범위한 제품을 테스트하는 데 사용되고 있습니다. 예를 들어, 제미니는 구글의 자체 제품인 안드로이드, 크롬, 구글 픽셀을 테스트하는 데 사용됩니다. 제미니는 또한 삼성, LG, 페이스북, 마이크로소프트 등의 기업에서 사용됩니다.\n제미니는 제품의 전반적인 품질과 사용자 경험을 개선하는 데 도움이 되는 강력한 도구입니다. 제미니는 자동화된 테스트, 문제 식별 및 문제 해결을 통해 제품 테스터와 엔지니어가 제품의 품질을 보다 빠르고 효율적으로 개선할 수 있도록 도와줍니다."
  },
  {
    "objectID": "blog/posts/2023/20231115.html",
    "href": "blog/posts/2023/20231115.html",
    "title": "mkfifo를 이용한 IPC",
    "section": "",
    "text": "mkfifo 명령어는 리눅스 시스템에서 FIFO(First In, First Out) 파일을 생성하는 데 사용됩니다. FIFO는 프로세스 간 통신을 위한 특별한 파일 유형으로, 한 프로세스가 데이터를 쓰면 다른 프로세스가 그 데이터를 읽을 수 있습니다.\n\n\nmkfifo명령을 FIFO 파일을 생성합니다. pipe라는 이름으로 FIFO 파일을 생성했습니다.\nmkfifo pipe\n이제 pipe파일을 사용해서 프로세스간 통신을 구현할 수 있습니다. 한 프로세스에서 데이터를 쓰고 다른 프로세스에서 데이터를 읽을 수 있습니다. 새로운 터미널을 생성하고 각 터미널에서 아래의 명령을 수행합니다.\n# 터미널 1\necho \"Hello\" &gt; pipe\n\n# 터미널 2\ncat pipe\nHello\n터미널 2번에서 다른 프로세스에서 전달한 Hello를 확인할 수 있습니다.\n\n\n\n터미널 2번에서 전달받은 명령을 실행하는 연습을 합니다. ls명령을 파이프를 이용하여 다른 프로세스로 전달하고 명령을 실행합니다.\n# 터미널 1\necho \"ls\" &gt; pipe\n\n# 터미널 2\neval \"$(cat pipe)\"\nREADME.md  pipe\n명령을 전달받은 프로세스에서는 eval을 사용하여 명령을 수행합니다. 다른 프로세스에서 전달된 ls명령이 실행됩니다.\n\n\n\n명령을 읽어서 실행하는 과정을 계속 진행할 수 있도록 while을 사용합니다.\n# 터미널 1\necho \"ls -al\" &gt; pipe\n\n# 터미널 2\nwhile true; do eval \"$(cat pipe)\"; done\ndrwxr-xr-x 6 root root 4096 11월 15 23:04 .\ndrwxr-xr-x 4 root root 4096 11월 13 23:48 ..\n-rw-r--r-- 1 root root   14 11월 13 23:43 README.md\nprw-r--r-- 1 root root    0 11월 15 23:06 pipe\n터미널 2에서 전달 받은 ls -al명령이 실행됩니다. 실행 결과를 파일로 저장하기 위해서 아래의 명령을 사용할 수 있습니다.\nwhile true; do eval \"$(cat pipe)\" &&gt; result.log; done\n이제 명령을 전달하면 실행결과가 result.log파일에 저장됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231115.html#fifo-파일-생성-및-ipc-테스트",
    "href": "blog/posts/2023/20231115.html#fifo-파일-생성-및-ipc-테스트",
    "title": "mkfifo를 이용한 IPC",
    "section": "",
    "text": "mkfifo명령을 FIFO 파일을 생성합니다. pipe라는 이름으로 FIFO 파일을 생성했습니다.\nmkfifo pipe\n이제 pipe파일을 사용해서 프로세스간 통신을 구현할 수 있습니다. 한 프로세스에서 데이터를 쓰고 다른 프로세스에서 데이터를 읽을 수 있습니다. 새로운 터미널을 생성하고 각 터미널에서 아래의 명령을 수행합니다.\n# 터미널 1\necho \"Hello\" &gt; pipe\n\n# 터미널 2\ncat pipe\nHello\n터미널 2번에서 다른 프로세스에서 전달한 Hello를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231115.html#생성한-파이프를-이용해서-명령어-수행하기",
    "href": "blog/posts/2023/20231115.html#생성한-파이프를-이용해서-명령어-수행하기",
    "title": "mkfifo를 이용한 IPC",
    "section": "",
    "text": "터미널 2번에서 전달받은 명령을 실행하는 연습을 합니다. ls명령을 파이프를 이용하여 다른 프로세스로 전달하고 명령을 실행합니다.\n# 터미널 1\necho \"ls\" &gt; pipe\n\n# 터미널 2\neval \"$(cat pipe)\"\nREADME.md  pipe\n명령을 전달받은 프로세스에서는 eval을 사용하여 명령을 수행합니다. 다른 프로세스에서 전달된 ls명령이 실행됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231115.html#파이프에-전달받은-명령을-계속-읽기",
    "href": "blog/posts/2023/20231115.html#파이프에-전달받은-명령을-계속-읽기",
    "title": "mkfifo를 이용한 IPC",
    "section": "",
    "text": "명령을 읽어서 실행하는 과정을 계속 진행할 수 있도록 while을 사용합니다.\n# 터미널 1\necho \"ls -al\" &gt; pipe\n\n# 터미널 2\nwhile true; do eval \"$(cat pipe)\"; done\ndrwxr-xr-x 6 root root 4096 11월 15 23:04 .\ndrwxr-xr-x 4 root root 4096 11월 13 23:48 ..\n-rw-r--r-- 1 root root   14 11월 13 23:43 README.md\nprw-r--r-- 1 root root    0 11월 15 23:06 pipe\n터미널 2에서 전달 받은 ls -al명령이 실행됩니다. 실행 결과를 파일로 저장하기 위해서 아래의 명령을 사용할 수 있습니다.\nwhile true; do eval \"$(cat pipe)\" &&gt; result.log; done\n이제 명령을 전달하면 실행결과가 result.log파일에 저장됩니다."
  },
  {
    "objectID": "blog/posts/2023/20231009.html",
    "href": "blog/posts/2023/20231009.html",
    "title": "Github Pull Request 템플릿 적용하기",
    "section": "",
    "text": "Github의 Pull Request 진행 시 적용되는 문서 탬플릿을 작성하고 적용하는 방법을 정리합니다.\n\n\nPull Request 탬플릿을 작성하기 위해서 탬플릿 문서를 작성합니다.\n\n문서 생성을 위해서 위와 같이 Github 레포지토리 상단의 Add file &gt; Create new file 버튼을 선택합니다.\n\n버튼을 선택하면 파일의 내용과 파일명을 저장할 수 있는 Text Editor 페이지가 위와 같이 생성됩니다. 탬플릿 문서를 특정 위치에 저장됩니다. 이를 위해서 레포지토리 루트폴더에 .github 폴더를 만들고 이 폴더에 pull_request_template.md 파일을 생성합니다.\n이 문서 내부에 작성하는 내용은 Pull Request(PR) 을 작성하는 commiter가 PR을 작성하면 이 템플릿의 내용을 Text Editor에 자동으로 추가됩니다. 필요한 내용을 모두 작성했다면 Commit chages 버튼을 눌러 수정한 내용을 저장합니다.\n\n\n\nPR을 생성할 때 새롭게 작성한 템플릿 내용이 작성되었는 지 확인합니다. 이를 위해서 기본 레포지토리를 Fork해서 수정 내용을 작성하고 Pull Requset 를 진행합니다.\n\n위와같이 PR을 생성하면 템플릿으로 작성한 내용이 기본적으로 제공됩니다. 레포지토리에 머지를 요청할 때 전달할 내용과 확인이 필요한 내용을 탬플릿으로 작성하면 PR리뷰에 필요한 내용을 잘 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231009.html#pull-request-탬플릿-파일-생성",
    "href": "blog/posts/2023/20231009.html#pull-request-탬플릿-파일-생성",
    "title": "Github Pull Request 템플릿 적용하기",
    "section": "",
    "text": "Pull Request 탬플릿을 작성하기 위해서 탬플릿 문서를 작성합니다.\n\n문서 생성을 위해서 위와 같이 Github 레포지토리 상단의 Add file &gt; Create new file 버튼을 선택합니다.\n\n버튼을 선택하면 파일의 내용과 파일명을 저장할 수 있는 Text Editor 페이지가 위와 같이 생성됩니다. 탬플릿 문서를 특정 위치에 저장됩니다. 이를 위해서 레포지토리 루트폴더에 .github 폴더를 만들고 이 폴더에 pull_request_template.md 파일을 생성합니다.\n이 문서 내부에 작성하는 내용은 Pull Request(PR) 을 작성하는 commiter가 PR을 작성하면 이 템플릿의 내용을 Text Editor에 자동으로 추가됩니다. 필요한 내용을 모두 작성했다면 Commit chages 버튼을 눌러 수정한 내용을 저장합니다."
  },
  {
    "objectID": "blog/posts/2023/20231009.html#pull-request-템플릿-결과-확인",
    "href": "blog/posts/2023/20231009.html#pull-request-템플릿-결과-확인",
    "title": "Github Pull Request 템플릿 적용하기",
    "section": "",
    "text": "PR을 생성할 때 새롭게 작성한 템플릿 내용이 작성되었는 지 확인합니다. 이를 위해서 기본 레포지토리를 Fork해서 수정 내용을 작성하고 Pull Requset 를 진행합니다.\n\n위와같이 PR을 생성하면 템플릿으로 작성한 내용이 기본적으로 제공됩니다. 레포지토리에 머지를 요청할 때 전달할 내용과 확인이 필요한 내용을 탬플릿으로 작성하면 PR리뷰에 필요한 내용을 잘 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231113.html",
    "href": "blog/posts/2023/20231113.html",
    "title": "MongoDB 설치 및 명령어 정리하기",
    "section": "",
    "text": "MongoDB(몽고디비)는 NoSQL 데이터베이스 시스템의 하나로, 문서 지향(Document-Oriented) 데이터베이스입니다. 이것은 데이터를 BSON(Binary JSON) 형식의 문서로 저장하며, 이러한 문서는 키-값 쌍(key-value pairs)으로 이루어져 있습니다. MongoDB는 관계형 데이터베이스와는 달리 스키마가 정의되지 않아 유연성이 높고, 데이터 모델의 변화에 적응하기 쉽습니다.\nSQL의 database, table, row를 mongoDB의 구조와 비교해서 테이블로 표시합니다.\n\n\n\nMongoDB\nSQL\n\n\n\n\nDatabase\nDatabase\n\n\nCollection\nTable\n\n\nDocument\nRow\n\n\n\n\nCollection : MongoDB에서는 문서의 그룹을 컬랙션이라고 부르며 논리적으로 그룹화하는 방법입니다.\nDocument : MongoDB는 데이터를 문서로 저장합니다. 문서에는 필드 및 값의 쌍으로 구성되며 중첩되는 구조를 갖을 수 있습니다.\n\nmongoDB를 설치한 후 mongosh 명령을 실행하면 mongoDB 쉘에 접속할 수 있습니다. 버전에 따라서 mongo 명령을 사용합니다.\n\n\nmongo DB를 docker로 설치하는 방법을 정리합니다. 도커를 사용하여 DB를 설치하면 쉽게 DB를 연습할 수 있습니다.\nsudo service docker start\nsudo service docker status\ndocker pull mongo\ndocker images\nREPOSITORY    TAG       IMAGE ID       CREATED        SIZE\nmongo         latest    ee3b4d1239f1   5 weeks ago    748MB\nhello-world   latest    9c7a54a9a43c   6 months ago   13.3kB\nwsl로 docker를 사용할 때 docker가 정상적으로 실행되지 않는 경우 WSL에 docker설치를 확인하세요.\ndocker-compose를 이용하여 mongodb를 사용할 수 있습니다. mongo db 이미지의 버전정보는 몽고DB 도커사이트에서 확인할 수 있습니다.\nversion: \"3\"\n\nservices:\n  mongo-db:\n    image: mongo\n    container_name: mongo-db\n    restart: always\n    ports:\n      - 27017:27017\n    volumes:\n      - ./data:/data\n    environment:\n      - MONGO_INITDB_ROOT_USERNAME=DB admin 유저명&gt;\n      - MONGO_INITDB_ROOT_PASSWORD=DB admin 암호&gt;\n\n  mongoexpress:\n    image: mongo-express\n    container_name: mongo-express\n    restart: always\n    depends_on:\n      - mongo-db\n    ports: \n      - 8081:8081\n    environment:\n      - ME_CONFIG_MONGODB_ADMINUSERNAME=&lt;DB admin 유저명&gt;\n      - ME_CONFIG_MONGODB_ADMINPASSWORD=&lt;DB admin 암호\n      - ME_CONFIG_MONGODB_SERVER=mongo-db\n      - ME_CONFIG_BASICAUTH_USERNAME=&lt;mongo express 유저명&gt;\n      - ME_CONFIG_BASICAUTH_PASSWORD=&lt;mongo express 암호&gt;\n이제 0.0.0.0:8081로 접속해서 유저명과 암호를 입력하면 mongo express를 통해서 mongo db 정보를 확인할 수 있습니다.\n\n\n\nMongo DB에서 자주 사용하는 명령어를 정리합니다.\n\n\nMongo DB에 admin을 위한 id, password를 설정했다면 해당 정보를 이용하여 DB에 접속해야 합니다.\nmongo admin -u username -p 'password'\n\n\n\ntest&gt; show dbs\nadmin   40.00 KiB\nconfig  60.00 KiB\nlocal   40.00 KiB\n\n\n\nDB를 생성해도 data가 없는 경우 데이터베이스가 표시되지 않습니다.\ntest&gt; use testdb\nswitched to db testdb\n\ntestdb&gt; show dbs\nadmin   40.00 KiB\nconfig  60.00 KiB\nlocal   40.00 KiB\n\n\n\n정보를 확인할 db를 use명령으로 결정하고 stats명령을 db의 상세 정보를 확인할 수 있습니다.\ntestdb&gt; use admin\nswitched to db admin\nadmin&gt; db.stats()\n{\n  db: 'admin',\n  collections: Long(\"1\"),\n  views: Long(\"0\"),\n  objects: Long(\"1\"),\n  avgObjSize: 59,\n  dataSize: 59,\n  storageSize: 20480,\n  indexes: Long(\"1\"),\n  indexSize: 20480,\n  totalSize: 40960,\n  scaleFactor: Long(\"1\"),\n  fsUsedSize: 57764601856,\n  fsTotalSize: 1081101176832,\n  ok: 1\n}\n\n\n\ntestdb에 collection을 생성하는 명령을 정리합니다.\nadmin&gt; use testdb\nswitched to db testdb\n\ntestdb&gt; db.createCollection(\"mydoc\")\n{ ok: 1 }\n\ntestdb&gt; show collections\nmydoc\n\n\n\ncollection 이름을 사용하여 단일 문서 삽입 시 insertOne명령을 사용합니다.\ntestdb&gt; show collections\nmydoc\n\ntestdb&gt; db.mydoc.insertOne({name: \"john\", age:30})\n{\n  acknowledged: true,\n  insertedId: ObjectId(\"655228d0dc1f13e70f4fcc12\")\n}\n여러문서를 한 번에 삽입하려면 insertMany메서드를 사용합니다. 데이터는 리스트로 전달합니다.\ntestdb&gt; db.mydoc.insertMany([{name: \"mike\", age:10}, {name: \"tony\", age:51}])\n{\n  acknowledged: true,\n  insertedIds: {\n    '0': ObjectId(\"65522a45dc1f13e70f4fcc13\"),\n    '1': ObjectId(\"65522a45dc1f13e70f4fcc14\")\n  }\n}\n\n\n\nMongoDB에서 데이터를 확인하고 검색하기 위해서는 find 명령어나 그와 유사한 메서드를 사용합니다. MongoDB의 셸에서 데이터를 확인하는 기본적인 방법은 다음과 같습니다.\n# 모든 문서 조회\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 }\n]\n\n# 조건에 따른 문서조회\ntestdb&gt; db.mydoc.find({ name: 'john' })\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 }\n]\n\n# 정렬을 사용한 결과정렬\n# age를 오름차순으로 정렬합니다.\ntestdb&gt; db.mydoc.find().sort({ age: 1})\n[\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 },\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 }\n]\n\n# 제한된 수의 데이터만 출력합니다.\ntestdb&gt; db.mydoc.find().limit(2)\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 }\n]\n\n\n\n문서를 삭제하기 위해서 deleteOne, deleteMany명령을 사용할 수 있습니다.\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 }\n]\n\ntestdb&gt; db.mydoc.deleteOne({name: \"mike\"})\n{ acknowledged: true, deletedCount: 1 }\n\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 }\n]\ndeleteMany명령은 조건에 맞는 모든 데이터를 삭제합니다. 테스트를 위해서 동일한 나이를 갖는 데이터를 만듭니다.\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 },\n  { _id: ObjectId(\"65522dfadc1f13e70f4fcc16\"), name: 'a', age: 15 },\n  { _id: ObjectId(\"65522dfedc1f13e70f4fcc17\"), name: 'b', age: 15 },\n  { _id: ObjectId(\"65522e01dc1f13e70f4fcc18\"), name: 'c', age: 15 },\n  { _id: ObjectId(\"65522e04dc1f13e70f4fcc19\"), name: 'd', age: 15 }\n]\n\ntestdb&gt; db.mydoc.deleteMany({age: 15})\n{ acknowledged: true, deletedCount: 4 }\n\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 }\n]\ndeleteMany명령을 사용해서 age가 15인 document 4개가 모두 삭제되었습니다.\n\n\n\nDB에서 query로 탐색한 정보 중 특정 key정보만 출력하고 싶은 경우 사용합니다. 선택한 collection의 전체 document 중 date 키 정보만 출력됩니다.\ndb.test_collection.find({}, {'date':1})"
  },
  {
    "objectID": "blog/posts/2023/20231113.html#mongodb-도커로-설치하기",
    "href": "blog/posts/2023/20231113.html#mongodb-도커로-설치하기",
    "title": "MongoDB 설치 및 명령어 정리하기",
    "section": "",
    "text": "mongo DB를 docker로 설치하는 방법을 정리합니다. 도커를 사용하여 DB를 설치하면 쉽게 DB를 연습할 수 있습니다.\nsudo service docker start\nsudo service docker status\ndocker pull mongo\ndocker images\nREPOSITORY    TAG       IMAGE ID       CREATED        SIZE\nmongo         latest    ee3b4d1239f1   5 weeks ago    748MB\nhello-world   latest    9c7a54a9a43c   6 months ago   13.3kB\nwsl로 docker를 사용할 때 docker가 정상적으로 실행되지 않는 경우 WSL에 docker설치를 확인하세요.\ndocker-compose를 이용하여 mongodb를 사용할 수 있습니다. mongo db 이미지의 버전정보는 몽고DB 도커사이트에서 확인할 수 있습니다.\nversion: \"3\"\n\nservices:\n  mongo-db:\n    image: mongo\n    container_name: mongo-db\n    restart: always\n    ports:\n      - 27017:27017\n    volumes:\n      - ./data:/data\n    environment:\n      - MONGO_INITDB_ROOT_USERNAME=DB admin 유저명&gt;\n      - MONGO_INITDB_ROOT_PASSWORD=DB admin 암호&gt;\n\n  mongoexpress:\n    image: mongo-express\n    container_name: mongo-express\n    restart: always\n    depends_on:\n      - mongo-db\n    ports: \n      - 8081:8081\n    environment:\n      - ME_CONFIG_MONGODB_ADMINUSERNAME=&lt;DB admin 유저명&gt;\n      - ME_CONFIG_MONGODB_ADMINPASSWORD=&lt;DB admin 암호\n      - ME_CONFIG_MONGODB_SERVER=mongo-db\n      - ME_CONFIG_BASICAUTH_USERNAME=&lt;mongo express 유저명&gt;\n      - ME_CONFIG_BASICAUTH_PASSWORD=&lt;mongo express 암호&gt;\n이제 0.0.0.0:8081로 접속해서 유저명과 암호를 입력하면 mongo express를 통해서 mongo db 정보를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231113.html#mongodb의-명령어-정리",
    "href": "blog/posts/2023/20231113.html#mongodb의-명령어-정리",
    "title": "MongoDB 설치 및 명령어 정리하기",
    "section": "",
    "text": "Mongo DB에서 자주 사용하는 명령어를 정리합니다.\n\n\nMongo DB에 admin을 위한 id, password를 설정했다면 해당 정보를 이용하여 DB에 접속해야 합니다.\nmongo admin -u username -p 'password'\n\n\n\ntest&gt; show dbs\nadmin   40.00 KiB\nconfig  60.00 KiB\nlocal   40.00 KiB\n\n\n\nDB를 생성해도 data가 없는 경우 데이터베이스가 표시되지 않습니다.\ntest&gt; use testdb\nswitched to db testdb\n\ntestdb&gt; show dbs\nadmin   40.00 KiB\nconfig  60.00 KiB\nlocal   40.00 KiB\n\n\n\n정보를 확인할 db를 use명령으로 결정하고 stats명령을 db의 상세 정보를 확인할 수 있습니다.\ntestdb&gt; use admin\nswitched to db admin\nadmin&gt; db.stats()\n{\n  db: 'admin',\n  collections: Long(\"1\"),\n  views: Long(\"0\"),\n  objects: Long(\"1\"),\n  avgObjSize: 59,\n  dataSize: 59,\n  storageSize: 20480,\n  indexes: Long(\"1\"),\n  indexSize: 20480,\n  totalSize: 40960,\n  scaleFactor: Long(\"1\"),\n  fsUsedSize: 57764601856,\n  fsTotalSize: 1081101176832,\n  ok: 1\n}\n\n\n\ntestdb에 collection을 생성하는 명령을 정리합니다.\nadmin&gt; use testdb\nswitched to db testdb\n\ntestdb&gt; db.createCollection(\"mydoc\")\n{ ok: 1 }\n\ntestdb&gt; show collections\nmydoc\n\n\n\ncollection 이름을 사용하여 단일 문서 삽입 시 insertOne명령을 사용합니다.\ntestdb&gt; show collections\nmydoc\n\ntestdb&gt; db.mydoc.insertOne({name: \"john\", age:30})\n{\n  acknowledged: true,\n  insertedId: ObjectId(\"655228d0dc1f13e70f4fcc12\")\n}\n여러문서를 한 번에 삽입하려면 insertMany메서드를 사용합니다. 데이터는 리스트로 전달합니다.\ntestdb&gt; db.mydoc.insertMany([{name: \"mike\", age:10}, {name: \"tony\", age:51}])\n{\n  acknowledged: true,\n  insertedIds: {\n    '0': ObjectId(\"65522a45dc1f13e70f4fcc13\"),\n    '1': ObjectId(\"65522a45dc1f13e70f4fcc14\")\n  }\n}\n\n\n\nMongoDB에서 데이터를 확인하고 검색하기 위해서는 find 명령어나 그와 유사한 메서드를 사용합니다. MongoDB의 셸에서 데이터를 확인하는 기본적인 방법은 다음과 같습니다.\n# 모든 문서 조회\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 }\n]\n\n# 조건에 따른 문서조회\ntestdb&gt; db.mydoc.find({ name: 'john' })\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 }\n]\n\n# 정렬을 사용한 결과정렬\n# age를 오름차순으로 정렬합니다.\ntestdb&gt; db.mydoc.find().sort({ age: 1})\n[\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 },\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 }\n]\n\n# 제한된 수의 데이터만 출력합니다.\ntestdb&gt; db.mydoc.find().limit(2)\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 }\n]\n\n\n\n문서를 삭제하기 위해서 deleteOne, deleteMany명령을 사용할 수 있습니다.\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc13\"), name: 'mike', age: 10 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 }\n]\n\ntestdb&gt; db.mydoc.deleteOne({name: \"mike\"})\n{ acknowledged: true, deletedCount: 1 }\n\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 }\n]\ndeleteMany명령은 조건에 맞는 모든 데이터를 삭제합니다. 테스트를 위해서 동일한 나이를 갖는 데이터를 만듭니다.\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 },\n  { _id: ObjectId(\"65522dfadc1f13e70f4fcc16\"), name: 'a', age: 15 },\n  { _id: ObjectId(\"65522dfedc1f13e70f4fcc17\"), name: 'b', age: 15 },\n  { _id: ObjectId(\"65522e01dc1f13e70f4fcc18\"), name: 'c', age: 15 },\n  { _id: ObjectId(\"65522e04dc1f13e70f4fcc19\"), name: 'd', age: 15 }\n]\n\ntestdb&gt; db.mydoc.deleteMany({age: 15})\n{ acknowledged: true, deletedCount: 4 }\n\ntestdb&gt; db.mydoc.find()\n[\n  { _id: ObjectId(\"655228d0dc1f13e70f4fcc12\"), name: 'john', age: 30 },\n  { _id: ObjectId(\"65522a45dc1f13e70f4fcc14\"), name: 'tony', age: 51 },\n  { _id: ObjectId(\"65522be8dc1f13e70f4fcc15\"), name: 'mike', age: 12 }\n]\ndeleteMany명령을 사용해서 age가 15인 document 4개가 모두 삭제되었습니다.\n\n\n\nDB에서 query로 탐색한 정보 중 특정 key정보만 출력하고 싶은 경우 사용합니다. 선택한 collection의 전체 document 중 date 키 정보만 출력됩니다.\ndb.test_collection.find({}, {'date':1})"
  },
  {
    "objectID": "blog/posts/2023/20231127.html",
    "href": "blog/posts/2023/20231127.html",
    "title": "우분투 docker, docker-compse 설치",
    "section": "",
    "text": "sudo apt-get update\nsudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common\n\n\n\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"\n\n\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io"
  },
  {
    "objectID": "blog/posts/2023/20231127.html#필요한-패키지-설치",
    "href": "blog/posts/2023/20231127.html#필요한-패키지-설치",
    "title": "우분투 docker, docker-compse 설치",
    "section": "",
    "text": "sudo apt-get update\nsudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common"
  },
  {
    "objectID": "blog/posts/2023/20231127.html#docker의-공식-gpg키와-저장소-추가",
    "href": "blog/posts/2023/20231127.html#docker의-공식-gpg키와-저장소-추가",
    "title": "우분투 docker, docker-compse 설치",
    "section": "",
    "text": "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\""
  },
  {
    "objectID": "blog/posts/2023/20231127.html#docker-설치",
    "href": "blog/posts/2023/20231127.html#docker-설치",
    "title": "우분투 docker, docker-compse 설치",
    "section": "",
    "text": "sudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io"
  },
  {
    "objectID": "blog/posts/2023/20230910.html",
    "href": "blog/posts/2023/20230910.html",
    "title": "Quarto Callout Block",
    "section": "",
    "text": "Quarto를 이용해 문서를 작성하는 과정에서 강조할 내용이 있는 경우 Callout Block을 사용하는 것이 좋습니다. 자산이 작성한 글에 집중이 필요한 내용을 명확하게 나타낼 수 있습니다. 공부한 내용을 정리합니다."
  },
  {
    "objectID": "blog/posts/2023/20230910.html#callout-종류",
    "href": "blog/posts/2023/20230910.html#callout-종류",
    "title": "Quarto Callout Block",
    "section": "Callout 종류",
    "text": "Callout 종류\nCallout Block은 총 아래의 note, warning, important, tip, caution 5가지 종류를 갖습니다. 실제 어떻게 적용되는지 아래에서 살펴보세요.\n\n\n\n\n\n\nNote\n\n\n\nCallout note 타입을 사용합니다.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCallout warning 타입을 사용합니다.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nCallout important 타입을 사용합니다.\n\n\n\n\n\n\n\n\nTip\n\n\n\nCallout tip 타입을 사용합니다.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nCallout caution 타입을 사용합니다.\n\n\nMarkdown으로 어떻게 구현하는 지 확인해봅시다. ::: 키워드를 사용했고 Callout Block형식은 {}로 표시합니다.\n::: {.callout-caution}\n# 제목을 추가합니다.\nCallout `caution` 타입을 사용합니다.\n:::\n\n\n\n\n\n\n제목을 추가합니다.\n\n\n\nCallout caution 타입을 사용합니다."
  },
  {
    "objectID": "blog/posts/2023/20230910.html#다양한-사용자-설정",
    "href": "blog/posts/2023/20230910.html#다양한-사용자-설정",
    "title": "Quarto Callout Block",
    "section": "다양한 사용자 설정",
    "text": "다양한 사용자 설정\n\n제목 추가하기\n아이콘은 유지하고 제목을 변경하고 싶은 경우가 있습니다. 이 경우 header 마크다운을 사용합니다.\n::: {.callout-caution}\n# 제목을 추가합니다.\nCallout `caution` 타입을 사용합니다.\n:::\n\n\n\n\n\n\n제목을 추가합니다.\n\n\n\nCallout caution 타입을 사용합니다.\n\n\n\n\n형태 변경하기\nCallout Block의 외형은 default, simple, minimam 형태를 지원합니다. 각각이 어떻게 표현되는지 알아봅니다.\n\n\n\n\n\n\nDefault 외형\n\n\n\ndefault 외형을 확인합니다.\n\n\n\n\n\n\n\n\nsimple 외형\n\n\n\nsimple 외형을 확인합니다.\n\n\n\n\n\n\n\n\nminimal 외형\n\n\n\nminimal 외형을 확인합니다.\n\n\n코드는 아래와 같이 사용합니다. appearance가 추가되었습니다.\n::: {.callout-note appearance=\"minimal\"}\n# Default 외형\ndefault 외형을 확인합니다.\n:::"
  },
  {
    "objectID": "blog/posts/2023/20231114.html",
    "href": "blog/posts/2023/20231114.html",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "Pymongo를 사용하기위해서 mongo DB를 설치해야합니다. docker를 이용해서 mongo DB를 설치합니다.\n# mongo image 다운로드\ndocker pull mongo\n\n# 다운로드한 docker image 확인\ndocker images\nREPOSITORY    TAG       IMAGE ID       CREATED        SIZE\nmongo         latest    ee3b4d1239f1   4 weeks ago    748MB\nhello-world   latest    9c7a54a9a43c   6 months ago   13.3kB\n도커 이미지가 다운로드 완료되면 docker images명령으로 mongo이미지가 다운로드 된 것을 확인할 수 있습니다. VSCODE에서 docker extension을 설치하면 container를 쉽게 실행할 수 있습니다.\n# --name : 컨테이너에 이름 부여\n# -p : 호스트와 컨테이너 간의 포터의 배포/바인드를 위해 사용\n# -e : 컨테이너의 환경변수 설정\n# ex) docker run -e FOO=bar python\n# -v : 호스트와 컨테이너 간의 볼륨 설정을 위해 사용\n# -w : 도커의 작업 디렉토리를 변경\n# ex) docker run -w /etc python (컨테이너의 작업 디렉토리를 /etc로 변경)\n# -d : 도커를 백그라운드에서 사용하는 경우\ndocker run -p 27017:27017 --name mongodb -v .:/data/db -d mongo\n이제 백그라운드로 실해되고 있는 mongodb container에 접속합니다.\ndocker exec -it mongodb bash\n\n\nDB에 연결할 수 있는 clinet를 생성합니다.\n\nimport pymongo\nclient = pymongo.MongoClient(host=\"localhost\", port=27017)\n\nadmin 암호를 설정한 DB에 접속 시 유저명과 암호가 없는 경우 아래와 같은 에러가 발생합니다.\nOperationFailure: Command listDatabases requires authentication, full error: {'ok': 0.0, 'errmsg': 'Command listDatabases requires authentication', 'code': 13, 'codeName': 'Unauthorized'}\nDB 접근에 필요한 유저명과 이름을 함께 전달합니다.\n\nclient = pymongo.MongoClient(host=\"localhost\", username='root', password='1234', port=27017)\n\n\n\n\n\ntry:\n  db = client['test_db']\n  collection = db['test_collection']\n\n  collection.drop()\nexcept:\n  print(\"fail\")\n\n\n\n\n생성된 데이터 베이스의 삭제는 drop_database를 사용합니다. 테스트을 위해 생성할 test_db가 있다면 데이터베이스를 삭제합니다.\n\ntry:\n  client.drop_database('test_db')\nexcept e:\n  print(e)\n\n\n\n\n새로운 데이터베이스는 client의 key로 생성할 수 있습니다. 새롭게 testdb를 생성했지만 db에 데이터가 없는 경우 db가 표시되지 않습니다. testdb가 표시되지 않습니다.\n\ntry:\n  db = client['test_db']\nexcept:\n  print(fail)\n\nfor item in client.list_databases():\n  print(item)\n\n\n\n\n\ndb = client['test_db']\ncollection = db['test_collection']\n\nfor item in db.list_collections():\n  print(item)\n\n\n\n\nMongoClient를 생성하고 데이터베이스 정보를 list_databases로 확인합니다. 기본적으로 생성된 데이터베이스를 확인할 수 있습니다.\n\nfor item in client.list_databases():\n  print(item)\n\n\n\n\n새롭게 생성한 데이터베이스에 collection을 생성하고 document를 추가합니다. document가 추가되면 데이터베이스가 표시됩니다. document가 추가된 후 다시 데이터베이스를 확인하면 데이터베이스가 생성됨을 확인할 수 있습니다.\n\ntry:\n  db = client['test_db']\n  collection = db['test_collection']\nexcept e:\n  print(e)\ndocument = {\"name\": \"tony\", \"age\": 20}\nresult = collection.insert_one(document)\n\nfor item in client.list_databases():\n  print(item)\n\n\ndocument가 추가되었으니 데이터베이스를 다시 확인합니다. 새롭게 생성된 test_db를 확인할 수 있습니다.\n\n\n\ndb에 생성된 collection을 확인하는 방법을 정리합니다. testdb에 생성된 collection 정보를 확인합니다.\n\ntry:\n  db = client['test_db']\nexcept:\n  print(\"fail\")\n\ncollection_names = db.list_collection_names()\nfor name in collection_names:\n    print(name)\n\n\n\n\n\nPyMongo를 사용하여 MongoDB에서 문서(document)를 확인하는 방법은 find() 메서드를 사용하는 것입니다. 아래는 예시 코드입니다\n\ntry:\n  db = client['test_db']\n  collection = db['test_collection']\n  documents = collection.find({})\nexcept:\n  print(\"fail\")\n\nfor document in documents:\n  print(document)\n\n\n특정 조건을 만족하는 document만 확인하는 방법은 query정보를 딕셔너리 형태로 전달합니다. 검색조건 확인을 위해서 document를 조금 더 추가합니다. 3개의 document가 생성됩니다.\n\ndocument = {\"name\": \"mike\", \"age\": 30}\ncollection.insert_one(document)\n\ndocument = {\"name\": \"mike\", \"age\": 30}\ncollection.insert_one(document)\n\ndocument = {\"name\": \"bill\", \"age\": 51}\ncollection.insert_one(document)\n\ndocuments = collection.find()\nfor document in documents:\n  print(document)\n\n\ncollection에서 검색하는 document중 하나만 선택 시 find_one을 사용합니다.\n\ndocument = collection.find_one({\"name\":\"mike\"})\nprint(document)\n\n\n\n\n\nage 필드에서 나이가 30에 이상이 document를 찾는 경우 $gte를 사용할 수 있습니다.\n\ndocuments = collection.find({\"age\":{\"$gte\":30}})\nfor doc in documents:\n  print(doc)\n\n\nage 필드의 값이 30 또는 51을 포함한 document를 찾는 경우 $in을 사용합니다.\n\ndocuments = collection.find({\"age\":{\"$in\":[30, 51]}})\nfor doc in documents:\n  print(doc)\n\n\nage 필드의 값이 30 또는 51을 포함하지 않는 document를 찾는 경우 $nin을 사용합니다.\n\ndocuments = collection.find({\"age\":{\"$nin\":[30, 51]}})\nfor doc in documents:\n  print(doc)\n\n\nQuery Operators는 아래와 같습니다.\n\n\n\n\n\n\n\n\nQuery Operator\n\nCol2\n\n\n\n\n$eq\nx = value (equal)\n{ &lt;field&gt;: { $eq: &lt;value&gt;} }\n\n\n$gte\nx &gt;= value (grater than or equal)\n{ &lt;field&gt;: { $gte: &lt;value&gt;} }\n\n\n$gt\nx &gt; value (greter than)\n{ &lt;field&gt;: { $gt: &lt;value&gt;} }\n\n\n$lte\nx &lt;= value (less then or equal)\n{ &lt;field&gt;: { $lte: &lt;value&gt;} }\n\n\n$lt\nx &lt; value (less then)\n{ &lt;field&gt;: { $lt: &lt;value&gt;} }\n\n\n$in\ncompares each parameter to each document in the collection\n{ field: { $in: [, , …  ] } }\n\n\n$nin\nselect the documents whose field holds an array with no element equal to a value in the specified array.\n{ field: { $nin: [, , …  ] } }"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#mongodb-서버에-연결",
    "href": "blog/posts/2023/20231114.html#mongodb-서버에-연결",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "DB에 연결할 수 있는 clinet를 생성합니다.\n\nimport pymongo\nclient = pymongo.MongoClient(host=\"localhost\", port=27017)\n\nadmin 암호를 설정한 DB에 접속 시 유저명과 암호가 없는 경우 아래와 같은 에러가 발생합니다.\nOperationFailure: Command listDatabases requires authentication, full error: {'ok': 0.0, 'errmsg': 'Command listDatabases requires authentication', 'code': 13, 'codeName': 'Unauthorized'}\nDB 접근에 필요한 유저명과 이름을 함께 전달합니다.\n\nclient = pymongo.MongoClient(host=\"localhost\", username='root', password='1234', port=27017)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#collection-삭제",
    "href": "blog/posts/2023/20231114.html#collection-삭제",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "try:\n  db = client['test_db']\n  collection = db['test_collection']\n\n  collection.drop()\nexcept:\n  print(\"fail\")"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#데이터-베이스-삭제",
    "href": "blog/posts/2023/20231114.html#데이터-베이스-삭제",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "생성된 데이터 베이스의 삭제는 drop_database를 사용합니다. 테스트을 위해 생성할 test_db가 있다면 데이터베이스를 삭제합니다.\n\ntry:\n  client.drop_database('test_db')\nexcept e:\n  print(e)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#데이터-베이스-생성",
    "href": "blog/posts/2023/20231114.html#데이터-베이스-생성",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "새로운 데이터베이스는 client의 key로 생성할 수 있습니다. 새롭게 testdb를 생성했지만 db에 데이터가 없는 경우 db가 표시되지 않습니다. testdb가 표시되지 않습니다.\n\ntry:\n  db = client['test_db']\nexcept:\n  print(fail)\n\nfor item in client.list_databases():\n  print(item)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#collection-생성",
    "href": "blog/posts/2023/20231114.html#collection-생성",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "db = client['test_db']\ncollection = db['test_collection']\n\nfor item in db.list_collections():\n  print(item)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#데이터베이스-확인",
    "href": "blog/posts/2023/20231114.html#데이터베이스-확인",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "MongoClient를 생성하고 데이터베이스 정보를 list_databases로 확인합니다. 기본적으로 생성된 데이터베이스를 확인할 수 있습니다.\n\nfor item in client.list_databases():\n  print(item)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#collection-및-document-생성",
    "href": "blog/posts/2023/20231114.html#collection-및-document-생성",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "새롭게 생성한 데이터베이스에 collection을 생성하고 document를 추가합니다. document가 추가되면 데이터베이스가 표시됩니다. document가 추가된 후 다시 데이터베이스를 확인하면 데이터베이스가 생성됨을 확인할 수 있습니다.\n\ntry:\n  db = client['test_db']\n  collection = db['test_collection']\nexcept e:\n  print(e)\ndocument = {\"name\": \"tony\", \"age\": 20}\nresult = collection.insert_one(document)\n\nfor item in client.list_databases():\n  print(item)\n\n\ndocument가 추가되었으니 데이터베이스를 다시 확인합니다. 새롭게 생성된 test_db를 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231114.html#collection-확인하기",
    "href": "blog/posts/2023/20231114.html#collection-확인하기",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "db에 생성된 collection을 확인하는 방법을 정리합니다. testdb에 생성된 collection 정보를 확인합니다.\n\ntry:\n  db = client['test_db']\nexcept:\n  print(\"fail\")\n\ncollection_names = db.list_collection_names()\nfor name in collection_names:\n    print(name)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#document-확인하기",
    "href": "blog/posts/2023/20231114.html#document-확인하기",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "PyMongo를 사용하여 MongoDB에서 문서(document)를 확인하는 방법은 find() 메서드를 사용하는 것입니다. 아래는 예시 코드입니다\n\ntry:\n  db = client['test_db']\n  collection = db['test_collection']\n  documents = collection.find({})\nexcept:\n  print(\"fail\")\n\nfor document in documents:\n  print(document)\n\n\n특정 조건을 만족하는 document만 확인하는 방법은 query정보를 딕셔너리 형태로 전달합니다. 검색조건 확인을 위해서 document를 조금 더 추가합니다. 3개의 document가 생성됩니다.\n\ndocument = {\"name\": \"mike\", \"age\": 30}\ncollection.insert_one(document)\n\ndocument = {\"name\": \"mike\", \"age\": 30}\ncollection.insert_one(document)\n\ndocument = {\"name\": \"bill\", \"age\": 51}\ncollection.insert_one(document)\n\ndocuments = collection.find()\nfor document in documents:\n  print(document)\n\n\ncollection에서 검색하는 document중 하나만 선택 시 find_one을 사용합니다.\n\ndocument = collection.find_one({\"name\":\"mike\"})\nprint(document)"
  },
  {
    "objectID": "blog/posts/2023/20231114.html#조건으로-document-확인하기",
    "href": "blog/posts/2023/20231114.html#조건으로-document-확인하기",
    "title": "Pymongo 명령어 정리하기",
    "section": "",
    "text": "age 필드에서 나이가 30에 이상이 document를 찾는 경우 $gte를 사용할 수 있습니다.\n\ndocuments = collection.find({\"age\":{\"$gte\":30}})\nfor doc in documents:\n  print(doc)\n\n\nage 필드의 값이 30 또는 51을 포함한 document를 찾는 경우 $in을 사용합니다.\n\ndocuments = collection.find({\"age\":{\"$in\":[30, 51]}})\nfor doc in documents:\n  print(doc)\n\n\nage 필드의 값이 30 또는 51을 포함하지 않는 document를 찾는 경우 $nin을 사용합니다.\n\ndocuments = collection.find({\"age\":{\"$nin\":[30, 51]}})\nfor doc in documents:\n  print(doc)\n\n\nQuery Operators는 아래와 같습니다.\n\n\n\n\n\n\n\n\nQuery Operator\n\nCol2\n\n\n\n\n$eq\nx = value (equal)\n{ &lt;field&gt;: { $eq: &lt;value&gt;} }\n\n\n$gte\nx &gt;= value (grater than or equal)\n{ &lt;field&gt;: { $gte: &lt;value&gt;} }\n\n\n$gt\nx &gt; value (greter than)\n{ &lt;field&gt;: { $gt: &lt;value&gt;} }\n\n\n$lte\nx &lt;= value (less then or equal)\n{ &lt;field&gt;: { $lte: &lt;value&gt;} }\n\n\n$lt\nx &lt; value (less then)\n{ &lt;field&gt;: { $lt: &lt;value&gt;} }\n\n\n$in\ncompares each parameter to each document in the collection\n{ field: { $in: [, , …  ] } }\n\n\n$nin\nselect the documents whose field holds an array with no element equal to a value in the specified array.\n{ field: { $nin: [, , …  ] } }"
  },
  {
    "objectID": "blog/posts/2023/20230928.html",
    "href": "blog/posts/2023/20230928.html",
    "title": "Plotly 마커 모양 변경하기",
    "section": "",
    "text": "Plotly 차트의 마커 모양을 변경하면 집중이 필요한 데이터를 강조할 수 있습니다. 마커의 색과 모양을 변경하는 방법을 정리합니다.\n\nimport plotly.express as px\n\ndf = px.data.iris()\ndf.sample(3)\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\nspecies_id\n\n\n\n\n77\n6.7\n3.0\n5.0\n1.7\nversicolor\n2\n\n\n119\n6.0\n2.2\n5.0\n1.5\nvirginica\n3\n\n\n140\n6.7\n3.1\n5.6\n2.4\nvirginica\n3\n\n\n\n\n\n\n\n연습을 위해 사용할 데이터프레임을 알아봅니다. 붓꽃(Irises)의 종류를 구분하기 위해 사용되는 iris데이터입니다. 케글 데이터 셋에서 데이터셋의 자세한 내용을 확인할 수 있습니다.\n\ndf['species'].unique()\n\narray(['setosa', 'versicolor', 'virginica'], dtype=object)\n\n\n데이터셋의 3가지 붓꽃 종의 이름을 확인하기 위해서 species 컬럼의 중복을 제외한 unique한 데이터를 확인합니다. setosa, versicolor, virginica의 3개의 붓꽃 종이 있음을 알 수 있습니다.\n\n\nscatter plot을 이용해서 데이터를 시각화합니다. x축과 y축에는 각각 sepal_width와 sepal_length를 사용합니다.\n\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n\nfig.show()\n\n\n                                                \n\n\ncolor에 species컬럼 정보를 전달해서 3개의 종의 데이터가 서로다른 색으로 시각화됐습니다.\n\n\n\nupdate_traces에 marker에 마커 모양을 위한 딕셔너리 정보를 전달하여 마커의 모양을 변경합니다.\n\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n\nfig.update_traces(marker=dict(size=12,\n                              line=dict(width=2,\n                                        color='DarkSlateGrey')),\n                  selector=dict(mode='markers'))\nfig.show()\n\n\n                                                \n\n\n마커의 size는 12이고 마커의 외곽선은 width는 2, 색은 DarkSlateGrey로 수정했습니다. selector에는 mode를 markers로 전달해서 style이 적용될 영역을 선택합니다.\n\n\n\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(\n  go.Scatter(\n    mode = 'markers', # line, markers, text\n    x = [1,2,3],\n    y = [10,20,30],\n    marker=dict(\n        color='LightSkyBlue',\n        size=20,\n        line=dict(\n            color='MediumPurple',\n            width=2)\n      ),\n    name= 'Marker Style 1'\n  )\n)\n\nfig.add_trace(\n  go.Scatter(\n    mode = 'lines',\n    x = [1,2,3],\n    y = [30,20,10],\n    line=dict(\n      color='Blue',\n      width=5\n    ),\n    name= 'Marker Style 2'\n  )\n)\n\nfig.add_trace(\n  go.Scatter(\n    mode = 'markers',\n    x = [1,2,3],\n    y = [50,50,50],\n    marker=dict(\n        color='Orange',\n        size=20,\n        line=dict(\n            color='Blue',\n            width=2)\n      ),\n    name= 'Marker Style 3'\n  )\n)\n\n\n\nfig.show()\n\n\n                                                \n\n\n차트에 여러 개의 그래프를 추가하기 위해서 add_trace()를 사용했습니다. 각 그래프의 마커 스타일은 go.Scatter함수 mode에 전달한 정보에 따라 다릅니다.\nmarkers모드인 경우 마커의 sytle을 marker로 전달한 정보로 변경합니다. line모드의 경우 line옵션에 style정보를 전달합니다."
  },
  {
    "objectID": "blog/posts/2023/20230928.html#scatter-plot으로-그리기",
    "href": "blog/posts/2023/20230928.html#scatter-plot으로-그리기",
    "title": "Plotly 마커 모양 변경하기",
    "section": "",
    "text": "scatter plot을 이용해서 데이터를 시각화합니다. x축과 y축에는 각각 sepal_width와 sepal_length를 사용합니다.\n\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n\nfig.show()\n\n\n                                                \n\n\ncolor에 species컬럼 정보를 전달해서 3개의 종의 데이터가 서로다른 색으로 시각화됐습니다."
  },
  {
    "objectID": "blog/posts/2023/20230928.html#마커-변경하기",
    "href": "blog/posts/2023/20230928.html#마커-변경하기",
    "title": "Plotly 마커 모양 변경하기",
    "section": "",
    "text": "update_traces에 marker에 마커 모양을 위한 딕셔너리 정보를 전달하여 마커의 모양을 변경합니다.\n\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n\nfig.update_traces(marker=dict(size=12,\n                              line=dict(width=2,\n                                        color='DarkSlateGrey')),\n                  selector=dict(mode='markers'))\nfig.show()\n\n\n                                                \n\n\n마커의 size는 12이고 마커의 외곽선은 width는 2, 색은 DarkSlateGrey로 수정했습니다. selector에는 mode를 markers로 전달해서 style이 적용될 영역을 선택합니다."
  },
  {
    "objectID": "blog/posts/2023/20230928.html#여러개의-그래프에-마커변경하기",
    "href": "blog/posts/2023/20230928.html#여러개의-그래프에-마커변경하기",
    "title": "Plotly 마커 모양 변경하기",
    "section": "",
    "text": "import plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(\n  go.Scatter(\n    mode = 'markers', # line, markers, text\n    x = [1,2,3],\n    y = [10,20,30],\n    marker=dict(\n        color='LightSkyBlue',\n        size=20,\n        line=dict(\n            color='MediumPurple',\n            width=2)\n      ),\n    name= 'Marker Style 1'\n  )\n)\n\nfig.add_trace(\n  go.Scatter(\n    mode = 'lines',\n    x = [1,2,3],\n    y = [30,20,10],\n    line=dict(\n      color='Blue',\n      width=5\n    ),\n    name= 'Marker Style 2'\n  )\n)\n\nfig.add_trace(\n  go.Scatter(\n    mode = 'markers',\n    x = [1,2,3],\n    y = [50,50,50],\n    marker=dict(\n        color='Orange',\n        size=20,\n        line=dict(\n            color='Blue',\n            width=2)\n      ),\n    name= 'Marker Style 3'\n  )\n)\n\n\n\nfig.show()\n\n\n                                                \n\n\n차트에 여러 개의 그래프를 추가하기 위해서 add_trace()를 사용했습니다. 각 그래프의 마커 스타일은 go.Scatter함수 mode에 전달한 정보에 따라 다릅니다.\nmarkers모드인 경우 마커의 sytle을 marker로 전달한 정보로 변경합니다. line모드의 경우 line옵션에 style정보를 전달합니다."
  },
  {
    "objectID": "blog/posts/2023/20231130.html",
    "href": "blog/posts/2023/20231130.html",
    "title": "python datetime 사용법 정리",
    "section": "",
    "text": "Python의 datetime 모듈은 날짜와 시간을 다루기 위한 다양한 함수와 클래스를 제공합니다. 시간 데이터를 관리하기 위한 datetime정보를 정리합니다.\n\n\n\nimport datetime as dt\nnow = dt.datetime.now()\nnow\n\ndatetime.datetime(2024, 6, 24, 22, 41, 32, 250632)\n\n\ndatetime의 현재 시간정보를 보여준다. 시간 정보는 datetime 형태로 표현됩니다. 날짜에서 원하는 시간정보를 가져올 수 있습니다.\n\nnow = dt.datetime.now()\nprint(f\"{now}\")\nprint(f\"{now.year}\")\nprint(f\"{now.month}\")\nprint(f\"{now.day}\")\nprint(f\"{now.hour}\")\nprint(f\"{now.minute}\")\nprint(f\"{now.second}\")\nprint(f\"{now.microsecond}\")\n\n2024-06-24 22:41:32.258487\n2024\n6\n24\n22\n41\n32\n258487\n\n\n\n\n\n시간을 원하는 형태의 문자열 형태로 표현하는 경우가 많습니다. strftime 메서드를 이용해서 날짜를 표현할 표현형식을 변경합니다.\n\nprint(now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n2024-06-24 22:41:32\n\n\n\n\n\n정해진 기간의 시간을 더하거나 빼는 경우 timedelta를 사용합니다.\n\nprint(f\"now: {now}\")\nprint(f\"{now + dt.timedelta(days=1)} + 1 day\")\nprint(f\"{now + dt.timedelta(hours=1)} + 1 hour\")\nprint(f\"{now + dt.timedelta(minutes=1)} + 1 min\")\nprint(f\"{now + dt.timedelta(seconds=1)} + 1 sec\")\nprint(f\"{now + dt.timedelta(microseconds=1)} + 1 micro sec\")\n\nnow: 2024-06-24 22:41:32.258487\n2024-06-25 22:41:32.258487 + 1 day\n2024-06-24 23:41:32.258487 + 1 hour\n2024-06-24 22:42:32.258487 + 1 min\n2024-06-24 22:41:33.258487 + 1 sec\n2024-06-24 22:41:32.258488 + 1 micro sec"
  },
  {
    "objectID": "blog/posts/2023/20231130.html#현재-시간-확인하기",
    "href": "blog/posts/2023/20231130.html#현재-시간-확인하기",
    "title": "python datetime 사용법 정리",
    "section": "",
    "text": "import datetime as dt\nnow = dt.datetime.now()\nnow\n\ndatetime.datetime(2024, 6, 24, 22, 41, 32, 250632)\n\n\ndatetime의 현재 시간정보를 보여준다. 시간 정보는 datetime 형태로 표현됩니다. 날짜에서 원하는 시간정보를 가져올 수 있습니다.\n\nnow = dt.datetime.now()\nprint(f\"{now}\")\nprint(f\"{now.year}\")\nprint(f\"{now.month}\")\nprint(f\"{now.day}\")\nprint(f\"{now.hour}\")\nprint(f\"{now.minute}\")\nprint(f\"{now.second}\")\nprint(f\"{now.microsecond}\")\n\n2024-06-24 22:41:32.258487\n2024\n6\n24\n22\n41\n32\n258487"
  },
  {
    "objectID": "blog/posts/2023/20231130.html#원하는-형태의-문자로-변경",
    "href": "blog/posts/2023/20231130.html#원하는-형태의-문자로-변경",
    "title": "python datetime 사용법 정리",
    "section": "",
    "text": "시간을 원하는 형태의 문자열 형태로 표현하는 경우가 많습니다. strftime 메서드를 이용해서 날짜를 표현할 표현형식을 변경합니다.\n\nprint(now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n2024-06-24 22:41:32"
  },
  {
    "objectID": "blog/posts/2023/20231130.html#시간-변경하기",
    "href": "blog/posts/2023/20231130.html#시간-변경하기",
    "title": "python datetime 사용법 정리",
    "section": "",
    "text": "정해진 기간의 시간을 더하거나 빼는 경우 timedelta를 사용합니다.\n\nprint(f\"now: {now}\")\nprint(f\"{now + dt.timedelta(days=1)} + 1 day\")\nprint(f\"{now + dt.timedelta(hours=1)} + 1 hour\")\nprint(f\"{now + dt.timedelta(minutes=1)} + 1 min\")\nprint(f\"{now + dt.timedelta(seconds=1)} + 1 sec\")\nprint(f\"{now + dt.timedelta(microseconds=1)} + 1 micro sec\")\n\nnow: 2024-06-24 22:41:32.258487\n2024-06-25 22:41:32.258487 + 1 day\n2024-06-24 23:41:32.258487 + 1 hour\n2024-06-24 22:42:32.258487 + 1 min\n2024-06-24 22:41:33.258487 + 1 sec\n2024-06-24 22:41:32.258488 + 1 micro sec"
  },
  {
    "objectID": "blog/posts/2023/20231128.html",
    "href": "blog/posts/2023/20231128.html",
    "title": "mongoDB 서비스 시작/종료/상태확인",
    "section": "",
    "text": "mongodb 서비스 실행/종료/상태 확인 방법을 정리합니다.\n\n\n자신의 사용하는 운영체제에 설치된 mongodb 서비스의 상태확인 방법을 정리합니다.\nservice mongodb start # mongodb 서비스 실행\nservice mongodb status # mongodb 서비스 상태확인\nservice mongodb stop # mongodb 서비스 정지\n\n\n\n도커로 실행된 mongodb의 상태를 확인하는 방법을 정리합니다. docker ps로 실행 중인 컨테이너 정보를 확인할 수 있습니다. -a옵션을 사용하면 현재 실행되지 않는 컨테이너 정보도 모두 출력됩니다.\ndocker ps\nCONTAINER ID   IMAGE           COMMAND                   CREATED        STATUS          PORTS                                                  NAMES\n8d45ded6e5ef   mongo           \"docker-entrypoint.s…\"   10 hours ago   Up 10 minutes   0.0.0.0:27017-&gt;27017/tcp, :::27017-&gt;27017/tcp          mongodb\n몽고 db 컨테이너에 접속을 위해 아래 명령을 사용합니다. 실행할 컨테이너 이름은 docker ps정보의 NAMES에서 확인할 수 있습니다.\ndocker exec -it mongodb bash\n컨테이너에 진입 후 ps -ef | grep mongodb를 실행하면 현재 실행 중인 mongodb 프로세스를 확인할 수 있습니다.\nps -ef | grep mongodb\nroot@8d45ded6e5ef:/# ps -ef | grep mongodb\nmongodb        1       0  0 Nov28 ?        00:00:06 mongod --auth --bind_ip_all\nroot         206     196  0 00:12 pts/0    00:00:00 grep mongodb"
  },
  {
    "objectID": "blog/posts/2023/20231128.html#로컬-서비스-상태확인",
    "href": "blog/posts/2023/20231128.html#로컬-서비스-상태확인",
    "title": "mongoDB 서비스 시작/종료/상태확인",
    "section": "",
    "text": "자신의 사용하는 운영체제에 설치된 mongodb 서비스의 상태확인 방법을 정리합니다.\nservice mongodb start # mongodb 서비스 실행\nservice mongodb status # mongodb 서비스 상태확인\nservice mongodb stop # mongodb 서비스 정지"
  },
  {
    "objectID": "blog/posts/2023/20231128.html#mongodb-docker-상태-확인하기",
    "href": "blog/posts/2023/20231128.html#mongodb-docker-상태-확인하기",
    "title": "mongoDB 서비스 시작/종료/상태확인",
    "section": "",
    "text": "도커로 실행된 mongodb의 상태를 확인하는 방법을 정리합니다. docker ps로 실행 중인 컨테이너 정보를 확인할 수 있습니다. -a옵션을 사용하면 현재 실행되지 않는 컨테이너 정보도 모두 출력됩니다.\ndocker ps\nCONTAINER ID   IMAGE           COMMAND                   CREATED        STATUS          PORTS                                                  NAMES\n8d45ded6e5ef   mongo           \"docker-entrypoint.s…\"   10 hours ago   Up 10 minutes   0.0.0.0:27017-&gt;27017/tcp, :::27017-&gt;27017/tcp          mongodb\n몽고 db 컨테이너에 접속을 위해 아래 명령을 사용합니다. 실행할 컨테이너 이름은 docker ps정보의 NAMES에서 확인할 수 있습니다.\ndocker exec -it mongodb bash\n컨테이너에 진입 후 ps -ef | grep mongodb를 실행하면 현재 실행 중인 mongodb 프로세스를 확인할 수 있습니다.\nps -ef | grep mongodb\nroot@8d45ded6e5ef:/# ps -ef | grep mongodb\nmongodb        1       0  0 Nov28 ?        00:00:06 mongod --auth --bind_ip_all\nroot         206     196  0 00:12 pts/0    00:00:00 grep mongodb"
  },
  {
    "objectID": "blog/posts/2023/20230917.html",
    "href": "blog/posts/2023/20230917.html",
    "title": "Plotly Bubble chart 만들기",
    "section": "",
    "text": "Plotly로 Bubble 차트 만들기를 연습합니다. 연습을 위한 데이터는 Plotly Express에서 제공하는 데이터를 사용합니다. gapminder.org에서 제공하는 데이터를 데이터프레임으로 불러옵니다. 데이터 구조를 확인하기 위해서 처음 3개의 데이터를 확인하겠습니다.\n\nimport plotly.express as px\ndf = px.data.gapminder()\ndf.sample(3)\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n332\nCongo, Dem. Rep.\nAfrica\n1992\n45.548\n41672143\n457.719181\nCOD\n180\n\n\n712\nIndonesia\nAsia\n1972\n49.203\n121282000\n1111.107907\nIDN\n360\n\n\n489\nEquatorial Guinea\nAfrica\n1997\n48.245\n439971\n2814.480755\nGNQ\n226\n\n\n\n\n\n\n\n여러 국가에 대한 정보를 연도별로 정리한 데이터입니다. 대한민국에 대한 데이터를 살펴보면 좀 더 의미있고 재미있는 시각화가 될 것 같습니다. country컬럼의 값이 Korea, Rep.인 데이터만 추출합니다.\n\ndf_korea = df[df['country'] == 'Korea, Rep.']\ndisplay(df_korea.head(3))\ndisplay(df['year'].describe())\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n840\nKorea, Rep.\nAsia\n1952\n47.453\n20947571\n1030.592226\nKOR\n410\n\n\n841\nKorea, Rep.\nAsia\n1957\n52.681\n22611552\n1487.593537\nKOR\n410\n\n\n842\nKorea, Rep.\nAsia\n1962\n55.292\n26420307\n1536.344387\nKOR\n410\n\n\n\n\n\n\n\ncount    1704.00000\nmean     1979.50000\nstd        17.26533\nmin      1952.00000\n25%      1965.75000\n50%      1979.50000\n75%      1993.25000\nmax      2007.00000\nName: year, dtype: float64\n\n\n데이터프레임의 year컬럼의 통계정보를 describe()함수로 확인하여 데이터가 1952년 부터 2007년까지 있음을 확인합니다. 버블차트를 이용하여 인구의 변화 양상을 시각화하겠습니다.\n\n\n데이터프레임의 인구를 버블차트로 표현합니다. y축에는 기대수명을 표시하고 scatter 차트를 버블차트로 표현하기 위해서 size에 인구정보를 전달했습니다. 이제 새로운 차트에서는 버블의 크기로 인구를 표시합니다..\n\nimport numpy as np\n\nfig = px.scatter(df.query(\"country== 'Korea, Rep.'\"), x= 'year', y='lifeExp', size=\"pop\")\nfig.show()\n\n\n                                                \n\n\n버블차트를 살펴보면 1950년, 1970년 이후 기대수명이 크게 올라가는 것을 알 수 있습니다. 추가로 버블의 크기를 통해서 인구 증가폭이 2007년에 가까워 지면서 인구수의 변화가 작아짐을 알 수 있습니다.\n\n\n\n버블차트는 버블의 크기와 색상으로 각각 정보를 표현할 수 있습니다. 이번엔 버블에 색상을 추가하여 총 4개의 정보를 표현합니다. 각 컬럼정보gdpPercap은 1인당 GDP를 의미하고 lifeExp는 기대 수명을 의미합니다. 1인당 GDP 변화에 따른 기대수명과 인구를 대륙별로 비교합니다.\n\nfig = px.scatter(df.query(\"year==2007\"), x=\"gdpPercap\", y=\"lifeExp\",\n                  size=\"pop\", color=\"continent\",\n                hover_name=\"country\", log_x=True, size_max=60)\nfig.show()\n\n\n                                                \n\n\n우선 색상으로 대륙별 기대수명과 인구를 비교할 수 있습니다. 초록색의 아프리카 대륙은 좌측 하단에 주로 위치하고 있어 인구수와 기대수명이 낮을 것을 알 수 있습니다. 아시아 국가는 버블의 크기도 다양하고 1인당 GDP도 넓은 분포를 보여주고 1인당 GDP가 높은 국가로는 일본, 한국, 싱가포르등이 있는 것을 알 수 있습니다.\n\n\n\n\nhttps://plotly.com/python/bubble-charts/"
  },
  {
    "objectID": "blog/posts/2023/20230917.html#버블차트-만들기",
    "href": "blog/posts/2023/20230917.html#버블차트-만들기",
    "title": "Plotly Bubble chart 만들기",
    "section": "",
    "text": "데이터프레임의 인구를 버블차트로 표현합니다. y축에는 기대수명을 표시하고 scatter 차트를 버블차트로 표현하기 위해서 size에 인구정보를 전달했습니다. 이제 새로운 차트에서는 버블의 크기로 인구를 표시합니다..\n\nimport numpy as np\n\nfig = px.scatter(df.query(\"country== 'Korea, Rep.'\"), x= 'year', y='lifeExp', size=\"pop\")\nfig.show()\n\n\n                                                \n\n\n버블차트를 살펴보면 1950년, 1970년 이후 기대수명이 크게 올라가는 것을 알 수 있습니다. 추가로 버블의 크기를 통해서 인구 증가폭이 2007년에 가까워 지면서 인구수의 변화가 작아짐을 알 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20230917.html#버블차트-색상-설정하기",
    "href": "blog/posts/2023/20230917.html#버블차트-색상-설정하기",
    "title": "Plotly Bubble chart 만들기",
    "section": "",
    "text": "버블차트는 버블의 크기와 색상으로 각각 정보를 표현할 수 있습니다. 이번엔 버블에 색상을 추가하여 총 4개의 정보를 표현합니다. 각 컬럼정보gdpPercap은 1인당 GDP를 의미하고 lifeExp는 기대 수명을 의미합니다. 1인당 GDP 변화에 따른 기대수명과 인구를 대륙별로 비교합니다.\n\nfig = px.scatter(df.query(\"year==2007\"), x=\"gdpPercap\", y=\"lifeExp\",\n                  size=\"pop\", color=\"continent\",\n                hover_name=\"country\", log_x=True, size_max=60)\nfig.show()\n\n\n                                                \n\n\n우선 색상으로 대륙별 기대수명과 인구를 비교할 수 있습니다. 초록색의 아프리카 대륙은 좌측 하단에 주로 위치하고 있어 인구수와 기대수명이 낮을 것을 알 수 있습니다. 아시아 국가는 버블의 크기도 다양하고 1인당 GDP도 넓은 분포를 보여주고 1인당 GDP가 높은 국가로는 일본, 한국, 싱가포르등이 있는 것을 알 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20230917.html#참조",
    "href": "blog/posts/2023/20230917.html#참조",
    "title": "Plotly Bubble chart 만들기",
    "section": "",
    "text": "https://plotly.com/python/bubble-charts/"
  },
  {
    "objectID": "blog/posts/2023/20231118.html",
    "href": "blog/posts/2023/20231118.html",
    "title": "docker-compose로 airflow 설치하기",
    "section": "",
    "text": "airflow 공식홈페이지에서는 airflow 설치를 위한 다양한 방법을 제공합니다.\nProduction 도커 이미지를 사용하는 방법은 Container/Docker 스택에 익숙할 때 유용합니다. 종속성을 쉽게 유지 관리하여 동일한 물리적 또는 가상 머신에서 실행되는 다른 소프트웨어와 별도로 Airflow 구성 요소를 실행하는 기능을 제공합니다.\n이 설치 방법은 Container/Docker 스택에 익숙할 뿐만 아니라 Kubernetes를 사용하고 Helm 차트를 통해 커뮤니티 관리 Kubernetes 설치 메커니즘을 사용하여 Airflow를 설치 및 유지 관리하려는 경우에 유용합니다.\n설치를 위해서 - Docker Compose v1.29.1 또는 최신버전을 설치해야합니다.\n\n\nAirflow docker compose를 사용하기 위해서 yaml파일을 다운로드 합니다.\ncurl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml'\n이 파일에는 아래의 서비스를 포함합니다.\n\nairflow-scheduler - 스케줄러는 모든 작업과 DAG를 모니터링하고 실행합니다.\nairflow-webserver - http://localhost:8080 에서 실행되는 웹서버\nairflow-worker - 스케쥴러가 제공하는 작업을 실행합니다.\nairflow-triggerer - 지연될 수 있는 작업에 대한 이벤트 루프를 생성합니다.\nairflow-init - 서비스를 초기화 합니다.\npostgres - 데이터베이스\nredis - The redis - 스케줄러에서 작업자에게 메세지를 전달하는 브로커입니다.\n\nairflow를 설치할 위치에서 도커 이미지의 airflow 폴더와 싱크되는 폴더를 생성합니다.\nmkdir -p ./dags ./logs ./plugins ./config\necho -e \"AIRFLOW_UID=$(id -u)\"  . env\nairflow에서 사용하는 환경변수에서 세부내용을 확인할 수 있습니다.\n\n\n\n데이터베이스 마이그레이션을 실행하고 첫 번째 사용자 계정을 생성해야 합니다. 아래의 airflow-init을 수행합니다. 초기 설정되는 ID와 PW는 모두 airflow로 설정됩니다.\ndocker compose up airflow-init\n\n\n\n도커 서비스를 실행합니다.\ndocker compose up\n\ndocker compose에서 사용되는 명령어를 함께 정리합니다. 백그라운드에서 airflow를 동작하는 경우 docker compose up -d를 사용합니다.\n\n\n\n\n\n\n\n명령어\n의미\n\n\n\n\ndocker compose build &lt;service&gt;\ndocker-compose.yaml 파일의 build로 표현된 서비스를 빌드합니다.\n\n\ndocker compose up\ndocker-compose.yml 파일을 기반으로 서비스를 시작합니다.\n\n\ndocker compose up -d\n백그라운드에서 서비스를 시작합니다.\n\n\ndocker compose down\n서비스를 중지하고 관련된 리소스(컨테이너, 네트워크, 볼륨 등)를 제거합니다.\n\n\ndocker-compose logs [service]\n지정된 서비스의 로그를 표시합니다. 서비스를 지정하지 않으면 모든 서비스의 로그를 표시합니다.\n\n\ndocker-compose start\n중지된 서비스를 시작합니다.\n\n\ndocker-compose stop\n지정된 서비스를 중지합니다.\n\n\ndocker-compose restart\n지정된 서비스를 재시작합니다."
  },
  {
    "objectID": "blog/posts/2023/20231118.html#docker-compose-yaml-다운로드",
    "href": "blog/posts/2023/20231118.html#docker-compose-yaml-다운로드",
    "title": "docker-compose로 airflow 설치하기",
    "section": "",
    "text": "Airflow docker compose를 사용하기 위해서 yaml파일을 다운로드 합니다.\ncurl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml'\n이 파일에는 아래의 서비스를 포함합니다.\n\nairflow-scheduler - 스케줄러는 모든 작업과 DAG를 모니터링하고 실행합니다.\nairflow-webserver - http://localhost:8080 에서 실행되는 웹서버\nairflow-worker - 스케쥴러가 제공하는 작업을 실행합니다.\nairflow-triggerer - 지연될 수 있는 작업에 대한 이벤트 루프를 생성합니다.\nairflow-init - 서비스를 초기화 합니다.\npostgres - 데이터베이스\nredis - The redis - 스케줄러에서 작업자에게 메세지를 전달하는 브로커입니다.\n\nairflow를 설치할 위치에서 도커 이미지의 airflow 폴더와 싱크되는 폴더를 생성합니다.\nmkdir -p ./dags ./logs ./plugins ./config\necho -e \"AIRFLOW_UID=$(id -u)\"  . env\nairflow에서 사용하는 환경변수에서 세부내용을 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231118.html#데이터-베이스-초기화",
    "href": "blog/posts/2023/20231118.html#데이터-베이스-초기화",
    "title": "docker-compose로 airflow 설치하기",
    "section": "",
    "text": "데이터베이스 마이그레이션을 실행하고 첫 번째 사용자 계정을 생성해야 합니다. 아래의 airflow-init을 수행합니다. 초기 설정되는 ID와 PW는 모두 airflow로 설정됩니다.\ndocker compose up airflow-init"
  },
  {
    "objectID": "blog/posts/2023/20231118.html#도커-실행",
    "href": "blog/posts/2023/20231118.html#도커-실행",
    "title": "docker-compose로 airflow 설치하기",
    "section": "",
    "text": "도커 서비스를 실행합니다.\ndocker compose up\n\ndocker compose에서 사용되는 명령어를 함께 정리합니다. 백그라운드에서 airflow를 동작하는 경우 docker compose up -d를 사용합니다.\n\n\n\n\n\n\n\n명령어\n의미\n\n\n\n\ndocker compose build &lt;service&gt;\ndocker-compose.yaml 파일의 build로 표현된 서비스를 빌드합니다.\n\n\ndocker compose up\ndocker-compose.yml 파일을 기반으로 서비스를 시작합니다.\n\n\ndocker compose up -d\n백그라운드에서 서비스를 시작합니다.\n\n\ndocker compose down\n서비스를 중지하고 관련된 리소스(컨테이너, 네트워크, 볼륨 등)를 제거합니다.\n\n\ndocker-compose logs [service]\n지정된 서비스의 로그를 표시합니다. 서비스를 지정하지 않으면 모든 서비스의 로그를 표시합니다.\n\n\ndocker-compose start\n중지된 서비스를 시작합니다.\n\n\ndocker-compose stop\n지정된 서비스를 중지합니다.\n\n\ndocker-compose restart\n지정된 서비스를 재시작합니다."
  },
  {
    "objectID": "blog/posts/2023/20230922.html",
    "href": "blog/posts/2023/20230922.html",
    "title": "Plotly Line Plot만들기",
    "section": "",
    "text": "Plotly Line plot 연습을 위해서 gapminder 데이터를 사용합니다. 데이터를 살펴보기 위해서 sample 데이터 3개를 확인합니다.\n\nimport plotly.express as px\ndf = px.data.gapminder()\ndf.sample(3)\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n1140\nNorway\nEurope\n1952\n72.670\n3327728\n10095.421720\nNOR\n578\n\n\n1214\nPhilippines\nAsia\n1962\n54.757\n30325264\n1649.552153\nPHL\n608\n\n\n1339\nSerbia\nEurope\n1987\n71.218\n9230783\n15870.878510\nSRB\n688\n\n\n\n\n\n\n\n각 국가의 기대수명, 인구 등 여러 정보를 시간에 표시됩니다. Line Plot으로 표시하기에는 많은 데이터이기 때문에 Asia대륙에 대한 정보만 표시하겠습니다.\n\ndf_asia = df.query(\"continent == 'Asia'\")\ndf_asia\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\nAFG\n4\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\nAFG\n4\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\nAFG\n4\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\nAFG\n4\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\nAFG\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1675\nYemen, Rep.\nAsia\n1987\n52.922\n11219340\n1971.741538\nYEM\n887\n\n\n1676\nYemen, Rep.\nAsia\n1992\n55.599\n13367997\n1879.496673\nYEM\n887\n\n\n1677\nYemen, Rep.\nAsia\n1997\n58.020\n15826497\n2117.484526\nYEM\n887\n\n\n1678\nYemen, Rep.\nAsia\n2002\n60.308\n18701257\n2234.820827\nYEM\n887\n\n\n1679\nYemen, Rep.\nAsia\n2007\n62.698\n22211743\n2280.769906\nYEM\n887\n\n\n\n\n396 rows × 8 columns\n\n\n\nquery함수로 continent가 Asia인 정보만 다시 표시합니다. 396개의 데이터로 줄었습니다.\n\nfig = px.line(df_asia, x='year', y='lifeExp', color='country')\nfig.show()\n\n\n                                                \n\n\n이 데이터를 Line Plot으로 표시합니다. x축을 year로 표시하고 y축을 기대수명을 나타내는 lifeExp로 표시합니다. 각 line의 색은 country에 따라 결정됩니다.\n아직 데이터가 많으니 평균기대수명보다 높고 1인당 GDP가 평균 이상인 국가만 다시 필터링하겠습니다.\n\nlifeExp_avg = df['lifeExp'].mean()\ngdpPercap_avg = df['gdpPercap'].mean()\ndisplay(lifeExp_avg)\ndf_result = df.query(\"continent == 'Asia' and lifeExp &gt; @lifeExp_avg and gdpPercap &gt; @gdpPercap_avg\")\ndf_result\n\n59.474439366197174\n\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n87\nBahrain\nAsia\n1967\n59.923\n202182\n14804.672700\nBHR\n48\n\n\n88\nBahrain\nAsia\n1972\n63.300\n230800\n18268.658390\nBHR\n48\n\n\n89\nBahrain\nAsia\n1977\n65.593\n297410\n19340.101960\nBHR\n48\n\n\n90\nBahrain\nAsia\n1982\n69.052\n377967\n19211.147310\nBHR\n48\n\n\n91\nBahrain\nAsia\n1987\n70.750\n454612\n18524.024060\nBHR\n48\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1508\nTaiwan\nAsia\n1992\n74.260\n20686918\n15215.657900\nTWN\n158\n\n\n1509\nTaiwan\nAsia\n1997\n75.250\n21628605\n20206.820980\nTWN\n158\n\n\n1510\nTaiwan\nAsia\n2002\n76.990\n22454239\n23235.423290\nTWN\n158\n\n\n1511\nTaiwan\nAsia\n2007\n78.400\n23174294\n28718.276840\nTWN\n158\n\n\n1535\nThailand\nAsia\n2007\n70.616\n65068149\n7458.396327\nTHA\n764\n\n\n\n\n95 rows × 8 columns\n\n\n\n\n\n이제 시점을 좀 더 확실히 보기 위해서 markers를 사용하여 마커를 적용합니다.\n\nfig = px.line(df_result, x='year', y='lifeExp', color='country', markers=True)\nfig.show()\n\n\n                                                \n\n\n각 라인에 서로다른 마커 심볼을 적용하기 위해서 symbol에 country정보를 전달합니다. 각 라인은 서로 다른 마커 심볼로 표시됩니다.\n\nfig = px.line(df_result, x='year', y='lifeExp', color='country', symbol='country', markers=True)\nfig.show()\n\n\n                                                \n\n\n\n\n\n날짜 정보를 갖는 데이터를 Line Plot으로 표시하는 방법을 정리합니다. stock()함수로 주식정보를 불러옵니다.\n\ndf = px.data.stocks()\ndf\n\n\n\n\n\n\n\n\ndate\nGOOG\nAAPL\nAMZN\nFB\nNFLX\nMSFT\n\n\n\n\n0\n2018-01-01\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n1\n2018-01-08\n1.018172\n1.011943\n1.061881\n0.959968\n1.053526\n1.015988\n\n\n2\n2018-01-15\n1.032008\n1.019771\n1.053240\n0.970243\n1.049860\n1.020524\n\n\n3\n2018-01-22\n1.066783\n0.980057\n1.140676\n1.016858\n1.307681\n1.066561\n\n\n4\n2018-01-29\n1.008773\n0.917143\n1.163374\n1.018357\n1.273537\n1.040708\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n100\n2019-12-02\n1.216280\n1.546914\n1.425061\n1.075997\n1.463641\n1.720717\n\n\n101\n2019-12-09\n1.222821\n1.572286\n1.432660\n1.038855\n1.421496\n1.752239\n\n\n102\n2019-12-16\n1.224418\n1.596800\n1.453455\n1.104094\n1.604362\n1.784896\n\n\n103\n2019-12-23\n1.226504\n1.656000\n1.521226\n1.113728\n1.567170\n1.802472\n\n\n104\n2019-12-30\n1.213014\n1.678000\n1.503360\n1.098475\n1.540883\n1.788185\n\n\n\n\n105 rows × 7 columns\n\n\n\n데이터를 살펴보면 회사들의 주가를 시간에 따라서 저장하고 있습니다. y축에 표시할 데이터는 리스트 형태로 정보를 전달합니다. 마커사이즈는 marker_size를 이용해서 설정합니다.\n\nfig = px.line(df, x='date', y=[\"GOOG\", \"AAPL\", \"FB\"], markers=True)\nfig.update_traces(marker_size=10)\n\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230922.html#line-plot에-마커-적용하기",
    "href": "blog/posts/2023/20230922.html#line-plot에-마커-적용하기",
    "title": "Plotly Line Plot만들기",
    "section": "",
    "text": "이제 시점을 좀 더 확실히 보기 위해서 markers를 사용하여 마커를 적용합니다.\n\nfig = px.line(df_result, x='year', y='lifeExp', color='country', markers=True)\nfig.show()\n\n\n                                                \n\n\n각 라인에 서로다른 마커 심볼을 적용하기 위해서 symbol에 country정보를 전달합니다. 각 라인은 서로 다른 마커 심볼로 표시됩니다.\n\nfig = px.line(df_result, x='year', y='lifeExp', color='country', symbol='country', markers=True)\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20230922.html#마커-사이즈-설정하기",
    "href": "blog/posts/2023/20230922.html#마커-사이즈-설정하기",
    "title": "Plotly Line Plot만들기",
    "section": "",
    "text": "날짜 정보를 갖는 데이터를 Line Plot으로 표시하는 방법을 정리합니다. stock()함수로 주식정보를 불러옵니다.\n\ndf = px.data.stocks()\ndf\n\n\n\n\n\n\n\n\ndate\nGOOG\nAAPL\nAMZN\nFB\nNFLX\nMSFT\n\n\n\n\n0\n2018-01-01\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n1\n2018-01-08\n1.018172\n1.011943\n1.061881\n0.959968\n1.053526\n1.015988\n\n\n2\n2018-01-15\n1.032008\n1.019771\n1.053240\n0.970243\n1.049860\n1.020524\n\n\n3\n2018-01-22\n1.066783\n0.980057\n1.140676\n1.016858\n1.307681\n1.066561\n\n\n4\n2018-01-29\n1.008773\n0.917143\n1.163374\n1.018357\n1.273537\n1.040708\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n100\n2019-12-02\n1.216280\n1.546914\n1.425061\n1.075997\n1.463641\n1.720717\n\n\n101\n2019-12-09\n1.222821\n1.572286\n1.432660\n1.038855\n1.421496\n1.752239\n\n\n102\n2019-12-16\n1.224418\n1.596800\n1.453455\n1.104094\n1.604362\n1.784896\n\n\n103\n2019-12-23\n1.226504\n1.656000\n1.521226\n1.113728\n1.567170\n1.802472\n\n\n104\n2019-12-30\n1.213014\n1.678000\n1.503360\n1.098475\n1.540883\n1.788185\n\n\n\n\n105 rows × 7 columns\n\n\n\n데이터를 살펴보면 회사들의 주가를 시간에 따라서 저장하고 있습니다. y축에 표시할 데이터는 리스트 형태로 정보를 전달합니다. 마커사이즈는 marker_size를 이용해서 설정합니다.\n\nfig = px.line(df, x='date', y=[\"GOOG\", \"AAPL\", \"FB\"], markers=True)\nfig.update_traces(marker_size=10)\n\nfig.show()"
  },
  {
    "objectID": "blog/posts/2023/20231205.html",
    "href": "blog/posts/2023/20231205.html",
    "title": "crontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신",
    "section": "",
    "text": "crontab은 Unix 및 Unix 계열 운영 체제에서 주기적으로 실행되는 작업을 예약하는 데 사용되는 시스템 유틸리티입니다. crontab은 “크론 테이블”의 줄임말로, 사용자가 일정한 간격으로 명령을 실행하도록 예약할 수 있게 해줍니다. 이는 주기적으로 반복되는 작업을 자동화하는 데 유용합니다.\n\n\n-e옵션으로 텍스트 폅집기로 명령을 수정하거나 추가할 수 있습니다.\ncrontab -e\n예제로 crontabb에 certbot을 이용하여 인증서를 갱신하는 명령을 추가합니다. crontab의 format은 아래와 같습니다.\n0   1    *   *     1       sudo certbot renew --nginx\n|   |    |   |     |       |\nmin hour day month weekday 명령어\n                  (0은 일요일)\ncrontab guru를 이용하면 시간 format의 주기를 확인할 수 있습니다. 위의 시간은 At 01:00 on Monday을 의미합니다.\n\n\n\n-l옵션으로 텍스트 폅집기로 명령을 확인할 수 있습니다.\ncrontab -l\n0 1 * * 1 sudo certbot renew --nginx\n\n\n\n크론탭의 명령어를 추가하거나 변경했다면 crontab을 재시작해야 합니다. 아래 명령을 이용해서 cron 데몬의 상태 시작/중지/재시작 및 상태를 확인할 수 있습니다.\nservice cron start\nservice cron stop\nservice cron restart\nservice cron status\n\n\n\n--dry-run옵션을 사용하면 실제 갱신 명령을 수행전에 오류를 확인할 수 있습니다. 갱신은 갱신종료일 20일 전에 가능합니다.\nsudo certbot renew --dry-run\n\n\n\n갱신 명령을 수행하면 갱신 종료일이 얼마나 남았는 지 확인할 수 있습니다. 갱신종료까지 62일 남은 것을 알 수 있습니다.\ncertbot certificates\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nFound the following certs:\n  Certificate Name: ...\n    Expiry Date: 2024-02-05 17:01:07+00:00 (VALID: 62 days)\n갱신을 위한 명령을 추가합니다.\n0 1 * * 1 sudo certbot renew --nginx &gt; ~/crontab-result.log\n매주 월요일 1시에 renew 명령을 수행합니다. 실행 결과는 crontab-result.log에서 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231205.html#crontab-새로운-명령어-만들기",
    "href": "blog/posts/2023/20231205.html#crontab-새로운-명령어-만들기",
    "title": "crontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신",
    "section": "",
    "text": "-e옵션으로 텍스트 폅집기로 명령을 수정하거나 추가할 수 있습니다.\ncrontab -e\n예제로 crontabb에 certbot을 이용하여 인증서를 갱신하는 명령을 추가합니다. crontab의 format은 아래와 같습니다.\n0   1    *   *     1       sudo certbot renew --nginx\n|   |    |   |     |       |\nmin hour day month weekday 명령어\n                  (0은 일요일)\ncrontab guru를 이용하면 시간 format의 주기를 확인할 수 있습니다. 위의 시간은 At 01:00 on Monday을 의미합니다."
  },
  {
    "objectID": "blog/posts/2023/20231205.html#crontab-명령어-확인하기",
    "href": "blog/posts/2023/20231205.html#crontab-명령어-확인하기",
    "title": "crontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신",
    "section": "",
    "text": "-l옵션으로 텍스트 폅집기로 명령을 확인할 수 있습니다.\ncrontab -l\n0 1 * * 1 sudo certbot renew --nginx"
  },
  {
    "objectID": "blog/posts/2023/20231205.html#crontab-시작중지재시작",
    "href": "blog/posts/2023/20231205.html#crontab-시작중지재시작",
    "title": "crontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신",
    "section": "",
    "text": "크론탭의 명령어를 추가하거나 변경했다면 crontab을 재시작해야 합니다. 아래 명령을 이용해서 cron 데몬의 상태 시작/중지/재시작 및 상태를 확인할 수 있습니다.\nservice cron start\nservice cron stop\nservice cron restart\nservice cron status"
  },
  {
    "objectID": "blog/posts/2023/20231205.html#인증서-갱신-테스트",
    "href": "blog/posts/2023/20231205.html#인증서-갱신-테스트",
    "title": "crontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신",
    "section": "",
    "text": "--dry-run옵션을 사용하면 실제 갱신 명령을 수행전에 오류를 확인할 수 있습니다. 갱신은 갱신종료일 20일 전에 가능합니다.\nsudo certbot renew --dry-run"
  },
  {
    "objectID": "blog/posts/2023/20231205.html#인증서-갱신-날짜-확인하기",
    "href": "blog/posts/2023/20231205.html#인증서-갱신-날짜-확인하기",
    "title": "crontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신",
    "section": "",
    "text": "갱신 명령을 수행하면 갱신 종료일이 얼마나 남았는 지 확인할 수 있습니다. 갱신종료까지 62일 남은 것을 알 수 있습니다.\ncertbot certificates\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nFound the following certs:\n  Certificate Name: ...\n    Expiry Date: 2024-02-05 17:01:07+00:00 (VALID: 62 days)\n갱신을 위한 명령을 추가합니다.\n0 1 * * 1 sudo certbot renew --nginx &gt; ~/crontab-result.log\n매주 월요일 1시에 renew 명령을 수행합니다. 실행 결과는 crontab-result.log에서 확인할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231004.html",
    "href": "blog/posts/2023/20231004.html",
    "title": "Plotly 차트의 축 tick 회전 및 폰트 변경하기",
    "section": "",
    "text": "Plotly x축 tick 회전시키기\n차트의 축에 표시될 tick 값의 길이가 긴 경우 tick을 회전 시키는 것이 좋습니다.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scatter(\n    mode = \"lines+markers\",\n    y = [4, 1, 3, 1, 10, 3, 7, 11, 5, 7, 8, 2],\n    x = [ \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\",]))\n\nfig.show()\n\n\n                                                \n\n\nx축과 y축의 tick의 fontsize와 회전을 적용합니다.\n\nfig = go.Figure(go.Scatter(\n    mode = \"lines+markers\",\n    y = [4, 1, 3, 1, 10, 3, 7, 11, 5, 7, 8, 2],\n    x = [ \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\",]))\n\nfig.update_xaxes(\n        tickangle = 70,\n        tickfont = {\"size\": 14},\n        title_text = \"Month\",\n        title_font = {\"size\": 20},\n        title_standoff = 25)\n\nfig.update_yaxes(\n        title_text = \"Temperature\",\n        title_standoff = 25)\n\n\n                                                \n\n\ntickfont로 x축의 tick의 글자크기를 설정합니다. title_font는 축 타이틀의 크기를 결정하고 title_standoff는 축과 title사이의 거리를 결정합니다."
  },
  {
    "objectID": "blog/posts/2023/20230912.html",
    "href": "blog/posts/2023/20230912.html",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "마크다운은 텍스트를 이용해 문서를 작성하는 도구입니다. 일반 텍스트를 이용해서 Table, 링크 등 다양한 문서형태를 작성할 수 있습니다. Quart는 Pandoc을 기반으로 하고 있으며 Markdown으로 문서를 작성합니다. 자주 사용하는 Markdown 문법을 정리합니다.\n\n\n텍스트의 형태를 변경하는 다양한 문법을 확인합니다.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n*italics*, **bold**, ***bold italics***\nitalics, bold, bold italics\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n~~strikethrough~~\nstrikethrough\n\n\n\n\n\n\n링크에 보일 글자와 함께 링크정보를 표시합니다.\n# 링크 연결\n&lt;https://quarto.org&gt;\n[Quarto](https://quarto/org)\nhttps://quarto.org Quarto\n# 이미지표시\n![Caption](cover.png)\n\n\n\n\nMarkdown으로 table을 구성하는 방법을 정리합니다.\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\nQuarto에서 소스코드를 추가하는 방법을 정리힙니다.\n코드의 처음과 마지막에 ```를 이용해서 코드 영역을 표시합니다.\n```\ncode\n```\n코드에 맞는 언어를 표시하여 언어별 코드 하이라이트를 적용할 수 있습니다.\n```python\n1 + 1\n```\nPandoc에서 지원하는 하이라이트 기능을 사용할 수 있습니다. 140 언어 지원 정보를 확인하세요. 만약 지원하는 언어가 없다면 default를 사용할 수 있습니다.\n```default\ncode\n```\n\n\n\n$ 구분기호를 이용하여 인라인 수식을 추가하고 $$ 구분기호를 이용하여 수식만 표현할 수 있습니다.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n인라인 수식: $E = mc^{2}$\n인라인 수식: \\(E=mc^{2}\\)\n\n\n수식 단독표현:\n\n$$E = mc^{2}$$\n수식 단독표현:\n\\[E = mc^{2}\\]\n\n\n\n\n\n\nQuarto는 Mermaid와 Graphviz 다이어그램을 지원합니다. 플로우차트, 시퀀스 다이어그램, 스테이트 다이어그램, 간트차트등을 그릴 수 있습니다. Mermaid를 이용해서 플로우 차트를 생성합니다.\n\n```{mermaid}\nflowchart LR\n  A[입력] --&gt; B(전처리)\n  B --&gt; C{판단로직}\n  C --&gt; D[성공]\n  C --&gt; E[실패]\n```\n\n\n\nflowchart LR\n  A[입력] --&gt; B(전처리)\n  B --&gt; C{판단로직}\n  C --&gt; D[성공]\n  C --&gt; E[실패]\n\n\n\n\n\n\n\n\n문서 내부에 동영상을 연결할 수 있습니다. {{&lt; video &gt;}} 를 이용해서 유튜브 동영상은 연결할 수 있습니다.\n{{&lt; video https://www.youtube.com/embed/wo9vZccmqwc &gt;}}\n\n\n\n\nHTML의 div 블럭을 만들 수 있습니다. class 정보를 border로 정의합니다.\n::: {#special .border}\nclass를 \"border\"로 정의한 div block으로 변환됩니다.\n:::\nQuarto를 렌터링하고 나면 아래의 HTML 코드로 변경됩니다.\n&lt;div id=\"special\" class=\"border\"&gt;\n  &lt;p&gt;class를 \"border\"로 정의한 div block으로 변환됩니다.&lt;/p&gt;\n&lt;/div&gt;\n대괄호 []로 표현된 문자열은 span으로 변환됩니다.\n[테스트 *SPAN* 코드입니다.]{.class key=\"val\"}\n&lt;span class=\"class\" data-key=\"val\"&gt;\n  테스트 &lt;em&gt;SPAN&lt;/em&gt; 코드입니다.\n&lt;/span&gt;\n\n\n\n\nhttps://quarto.org/docs/authoring/markdown-basics.html"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#text-formatting",
    "href": "blog/posts/2023/20230912.html#text-formatting",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "텍스트의 형태를 변경하는 다양한 문법을 확인합니다.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n*italics*, **bold**, ***bold italics***\nitalics, bold, bold italics\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n~~strikethrough~~\nstrikethrough"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#link-및-이미지-연결",
    "href": "blog/posts/2023/20230912.html#link-및-이미지-연결",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "링크에 보일 글자와 함께 링크정보를 표시합니다.\n# 링크 연결\n&lt;https://quarto.org&gt;\n[Quarto](https://quarto/org)\nhttps://quarto.org Quarto\n# 이미지표시\n![Caption](cover.png)"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#table",
    "href": "blog/posts/2023/20230912.html#table",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "Markdown으로 table을 구성하는 방법을 정리합니다.\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#소스-코드",
    "href": "blog/posts/2023/20230912.html#소스-코드",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "Quarto에서 소스코드를 추가하는 방법을 정리힙니다.\n코드의 처음과 마지막에 ```를 이용해서 코드 영역을 표시합니다.\n```\ncode\n```\n코드에 맞는 언어를 표시하여 언어별 코드 하이라이트를 적용할 수 있습니다.\n```python\n1 + 1\n```\nPandoc에서 지원하는 하이라이트 기능을 사용할 수 있습니다. 140 언어 지원 정보를 확인하세요. 만약 지원하는 언어가 없다면 default를 사용할 수 있습니다.\n```default\ncode\n```"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#수식",
    "href": "blog/posts/2023/20230912.html#수식",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "$ 구분기호를 이용하여 인라인 수식을 추가하고 $$ 구분기호를 이용하여 수식만 표현할 수 있습니다.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n인라인 수식: $E = mc^{2}$\n인라인 수식: \\(E=mc^{2}\\)\n\n\n수식 단독표현:\n\n$$E = mc^{2}$$\n수식 단독표현:\n\\[E = mc^{2}\\]"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#다이어그램",
    "href": "blog/posts/2023/20230912.html#다이어그램",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "Quarto는 Mermaid와 Graphviz 다이어그램을 지원합니다. 플로우차트, 시퀀스 다이어그램, 스테이트 다이어그램, 간트차트등을 그릴 수 있습니다. Mermaid를 이용해서 플로우 차트를 생성합니다.\n\n```{mermaid}\nflowchart LR\n  A[입력] --&gt; B(전처리)\n  B --&gt; C{판단로직}\n  C --&gt; D[성공]\n  C --&gt; E[실패]\n```\n\n\n\nflowchart LR\n  A[입력] --&gt; B(전처리)\n  B --&gt; C{판단로직}\n  C --&gt; D[성공]\n  C --&gt; E[실패]"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#동영상-연결",
    "href": "blog/posts/2023/20230912.html#동영상-연결",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "문서 내부에 동영상을 연결할 수 있습니다. {{&lt; video &gt;}} 를 이용해서 유튜브 동영상은 연결할 수 있습니다.\n{{&lt; video https://www.youtube.com/embed/wo9vZccmqwc &gt;}}"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#html-코드-divs-spans",
    "href": "blog/posts/2023/20230912.html#html-코드-divs-spans",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "HTML의 div 블럭을 만들 수 있습니다. class 정보를 border로 정의합니다.\n::: {#special .border}\nclass를 \"border\"로 정의한 div block으로 변환됩니다.\n:::\nQuarto를 렌터링하고 나면 아래의 HTML 코드로 변경됩니다.\n&lt;div id=\"special\" class=\"border\"&gt;\n  &lt;p&gt;class를 \"border\"로 정의한 div block으로 변환됩니다.&lt;/p&gt;\n&lt;/div&gt;\n대괄호 []로 표현된 문자열은 span으로 변환됩니다.\n[테스트 *SPAN* 코드입니다.]{.class key=\"val\"}\n&lt;span class=\"class\" data-key=\"val\"&gt;\n  테스트 &lt;em&gt;SPAN&lt;/em&gt; 코드입니다.\n&lt;/span&gt;"
  },
  {
    "objectID": "blog/posts/2023/20230912.html#참고",
    "href": "blog/posts/2023/20230912.html#참고",
    "title": "Markdown문법 정리하기",
    "section": "",
    "text": "https://quarto.org/docs/authoring/markdown-basics.html"
  },
  {
    "objectID": "blog/posts/2023/20231126.html",
    "href": "blog/posts/2023/20231126.html",
    "title": "AWS 호스팅 EC2 와 Lightsail의 차이",
    "section": "",
    "text": "블로그용 AWS, EC2와 Lightsail의 차이\nAWS는 어플리케이션이나 블로그의 호스팅을 원하는 사용자를 위해서 EC2(Amazon Elastic Compute Cloud)와 Lightsail을 제공합니다. 두 개의 서비스가 어떤 차이가 있는 지 정리합니다.\nEC2에는 여러 서비스가 혼합되어 있으며 단일 아키텍처를 생성하는 데 사용되는 고유한 개별 기능을 가지고 있으며 소규모 내지 복잡한 아키텍처에 적합합니다. 반면 Lightsail은 AWS에서 제공하는 통합 서비스 제품으로 Lightsail은 소규모 내지 중간 규모의 워크로드에 더 적합합니다. 주요 차이점을 표로 정리해서 비교합니다.\n\n\n\n\n\n\n\n\n\nLightsail\nEC2\n\n\n\n\n사용\n사용자 지정 코드 및 일반 CMS를 포함한 간단한 웹 애플리케이션 및 웹 사이트에 사용됩니다.\nHPC, 빅 데이터 및 분석 워크로드와 같은 소규모 내지 엔터프라이즈 애플리케이션에 사용됩니다.\n\n\n관리 지원\nLightsail에서는 시스템 관리자와 시스템 아키텍트의 수고를 덜 수 있습니다.\n환경 유형에 따라 관리에 필요한 노력이 달라집니다. EC2의 대부분의 서비스는 구성 요소에 대한 철저한 이해가 필요합니다.\n\n\n확장성\nLightsail에서 자동 인스턴스 확장성은 지원되지 않습니다.시작 후에는 인스턴스를 수정할 수 없습니다. 플랜을 변경하려면 새 인스턴스를 시작해야 합니다.\nAmazon EC2 Auto Scaling 그룹을 사용하여 인스턴스를 자동으로 크기 조정할 수 있습니다.EC2 인스턴스는 새로운 유형 또는 새로운 가상화로 수정할 수 있습니다.\n\n\n탄력적 볼륨\n지원되지 않음\n지원됨\n\n\n로드 밸런싱\nLightsail 인스턴스에서는 Lightsail 로드 밸런서를 사용할 수 있습니다.\n여러 유형의 로드 밸런서를 사용할 수 있습니다.\n\n\n\n표에서 알 수 있듯이 EC는 블로그나 간단한 어플리케이션 운영을 위해서라면 Lightsail이 적합한 호스팅 서비스로 보입니다. 하지만 장기적으로 다양한 서비스와 연동될 수 있는 확장성에 대한 고려가 필요하다면 EC2를 고려하면 좋을 것 같습니다.\n주의해야 할 기능은 탄력적 볼륨인 것 같습니다. 이 기능은 필요에 따라서 데이터 용량이너 성능 요구사항의 변경이 필요할 때 유용한 기능입니다. 고려하는 서비스가 특정 기간에 서비스 요청이 늘어날 것을 예상한다면 선택에 중요한 요소가 될 수 있습니다.\n\n\nReferences\n\nhttps://repost.aws/ko/knowledge-center/lightsail-differences-from-ec2"
  },
  {
    "objectID": "blog/posts/2023/20231223.html",
    "href": "blog/posts/2023/20231223.html",
    "title": "ChatGPT3.5와 ChatGPT4의 차이점",
    "section": "",
    "text": "ChatGPT-4는 유료로 사용할 수 있는 OpenAI의 챗봇입니다. ChatGPT-3.5는 무료이기 때문에 어떤 차이가 있는 지 궁금하여 내용을 정리합니다. GPTI를 통해서 정리한 큰 차이점은 아래와 같습니다.\n\n모델 크기 및 처리 능력: ChatGPT-4는 ChatGPT-3.5보다 크고 고급화된 모델로, 더 많은 데이터를 학습하고 더 복잡한 문제를 처리할 수 있습니다.\n이해도 및 반응의 정확성: ChatGPT-4는 더 정확하고 세밀한 대응을 할 수 있으며, 다양한 주제에 대한 더 깊은 이해를 보여줍니다.\n다양한 언어 처리 능력: ChatGPT-4는 더 많은 언어를 지원하고, 특히 다양한 언어에서의 뉘앙스와 문화적 맥락을 더 잘 이해합니다.\n멀티모달 기능: ChatGPT-4는 텍스트뿐만 아니라 이미지를 포함한 멀티모달 입력을 처리할 수 있는 능력을 갖추고 있습니다.\n\n쉬운 비교를 위해 표로 정리합니다.\n\n\n\n기능\nChatGPT-3.5\nChatGPT-4\n\n\n\n\n모델 크기 및 처리 능력\n작음\n큼\n\n\n이해도 및 반응의 정확성\n높지만 제한적\n매우 높음\n\n\n다양한 언어 처리 능력\n제한적\n향상됨\n\n\n멀티모달 기능\n없음\n있음\n\n\n\n성능의 차이를 제외하면 멀티모달 기능을 지원하는 점이 가장 큰 차이점입니다. 그럼 멀티모달 기능이 무엇일까요?\n\n\n컴퓨터나 인공지능 분야에서 멀티모달이라는 말은 이러한 다양한 형태의 정보를 모두 처리할 수 있는 기술을 의미해요. 즉, 텍스트(글), 이미지(사진), 오디오(소리), 비디오(동영상) 등 다양한 유형의 데이터를 이해하고, 그 정보를 통합해서 더 풍부하고 정확한 분석이나 반응을 할 수 있는 능력을 가리킵니다.\nChatGPT4는 멀티모달 기능을 지원하기 때문에 글로 된 질문에 답하는 것뿐만 아니라, 이미지를 분석하거나 이미지와 관련된 질문에도 답할 수 있습니다. 그럼 ChatGPT4에서는 어떤 멀티모달 기능을 지원할까요?\n\n이미지 기반 질문 응답 : 사용자가 제공한 이미지에 대한 질문에 답변할 수 있습니다. 예를 들어, 특정 사진에 대한 설명을 요청하거나 사진 속 개체를 식별하는 질문에 답할 수 있습니다.\n이미지와 텍스트의 통합 이해 : 이미지와 관련된 텍스트 정보를 함께 분석하여, 두 입력 유형 간의 관계를 이해하고 관련된 답변을 제공합니다. 예를 들어, 특정 이미지와 관련된 설명을 요청할 때, 이미지의 내용을 바탕으로 한 텍스트 설명을 제공합니다.\n이미지 생성 : 사용자의 텍스트 설명을 바탕으로 새로운 이미지를 생성하는 기능도 포함됩니다. 예를 들어, 사용자가 제공한 상세한 설명에 따라 이미지를 생성할 수 있습니다.\n\n\n\n\nChatGPT4는 특정 조건 하에서 웹 정보를 이용하여 답변을 제공할 수 있습니다. 이를 위해 “브라우저” 기능이라는 특별한 도구가 ChatGPT4 모델에 통합되어 있습니다. 이 도구를 사용하여, ChatGPT-4는 웹을 검색하고 최신 정보를 찾아 사용자의 질문에 답변할 수 있습니다.\n이 기능은 특히 최신 정보가 필요한 경우 또는 특정 주제에 대한 최근 데이터나 통계가 필요할 때 유용합니다. 예를 들어, 최신 뉴스 이벤트, 최근 연구 결과, 현재 스포츠 점수, 날씨 업데이트 등의 정보를 제공받을 수 있습니다.\n그러나 모든 상황에서 웹 검색 기능을 사용할 수 있는 것은 아니며, 사용자의 요청과 상황에 따라 이 기능의 사용 여부가 결정됩니다. 웹 검색은 실시간으로 정보를 검색하고, 다양한 웹 페이지에서 정보를 수집하여 답변을 제공하는 과정을 포함합니다. 이러한 접근 방식은 최신의 정보를 제공하는 데 유용하며, 특히 변화하는 데이터나 최근의 사건에 대한 질문에 효과적입니다.\n\n\n\n“MyGPT” 기능은 사용자의 대화를 개인화하여 맞춤형 경험을 제공하는 기능입니다. 이를 통해 사용자의 이전 대화 기록을 기억하고, 특정 주제에 대해 더 많은 정보를 제공하며, 사용자의 선호도와 설정에 맞춘 맞춤형 응답을 만들 수 있습니다. MyGPT는 시간이 지남에 따라 사용자의 관심사와 선호를 반영하여 더 풍부한 대화 경험을 제공하며, 사용자의 개인 정보 보호를 철저히 고려합니다.\n실제 사용예를 확인하면 차이점을 좀 더 쉽게 이해할 수 있습니다.\n\n언어 학습 보조\n\n사용자가 영어를 배우고 있다고 가정해봅시다. MyGPT는 사용자가 이전 대화에서 어려움을 겪었던 문법 포인트를 기억하고, 향후 대화에서 해당 문법을 중심으로 추가 연습 기회를 제공할 수 있습니다. 또한, 사용자가 관심을 보인 특정 주제에 대한 대화를 통해 언어 학습을 더욱 흥미롭고 효과적으로 만들 수 있습니다.\n\n건강 및 운동 일지\n\n사용자가 건강과 운동에 중점을 두고 있다고 가정해 봅시다. MyGPT는 사용자의 운동 목표, 진행 상황, 건강 관련 질문 등을 기억하여, 시간이 지남에 따라 맞춤형 운동 조언이나 건강 정보를 제공할 수 있습니다. 사용자의 진행 상황을 추적하며, 개선점이나 새로운 운동 방법에 대한 제안을 할 수도 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231223.html#멀티모달이-뭔가요",
    "href": "blog/posts/2023/20231223.html#멀티모달이-뭔가요",
    "title": "ChatGPT3.5와 ChatGPT4의 차이점",
    "section": "",
    "text": "컴퓨터나 인공지능 분야에서 멀티모달이라는 말은 이러한 다양한 형태의 정보를 모두 처리할 수 있는 기술을 의미해요. 즉, 텍스트(글), 이미지(사진), 오디오(소리), 비디오(동영상) 등 다양한 유형의 데이터를 이해하고, 그 정보를 통합해서 더 풍부하고 정확한 분석이나 반응을 할 수 있는 능력을 가리킵니다.\nChatGPT4는 멀티모달 기능을 지원하기 때문에 글로 된 질문에 답하는 것뿐만 아니라, 이미지를 분석하거나 이미지와 관련된 질문에도 답할 수 있습니다. 그럼 ChatGPT4에서는 어떤 멀티모달 기능을 지원할까요?\n\n이미지 기반 질문 응답 : 사용자가 제공한 이미지에 대한 질문에 답변할 수 있습니다. 예를 들어, 특정 사진에 대한 설명을 요청하거나 사진 속 개체를 식별하는 질문에 답할 수 있습니다.\n이미지와 텍스트의 통합 이해 : 이미지와 관련된 텍스트 정보를 함께 분석하여, 두 입력 유형 간의 관계를 이해하고 관련된 답변을 제공합니다. 예를 들어, 특정 이미지와 관련된 설명을 요청할 때, 이미지의 내용을 바탕으로 한 텍스트 설명을 제공합니다.\n이미지 생성 : 사용자의 텍스트 설명을 바탕으로 새로운 이미지를 생성하는 기능도 포함됩니다. 예를 들어, 사용자가 제공한 상세한 설명에 따라 이미지를 생성할 수 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231223.html#실시간-웹검색-기능",
    "href": "blog/posts/2023/20231223.html#실시간-웹검색-기능",
    "title": "ChatGPT3.5와 ChatGPT4의 차이점",
    "section": "",
    "text": "ChatGPT4는 특정 조건 하에서 웹 정보를 이용하여 답변을 제공할 수 있습니다. 이를 위해 “브라우저” 기능이라는 특별한 도구가 ChatGPT4 모델에 통합되어 있습니다. 이 도구를 사용하여, ChatGPT-4는 웹을 검색하고 최신 정보를 찾아 사용자의 질문에 답변할 수 있습니다.\n이 기능은 특히 최신 정보가 필요한 경우 또는 특정 주제에 대한 최근 데이터나 통계가 필요할 때 유용합니다. 예를 들어, 최신 뉴스 이벤트, 최근 연구 결과, 현재 스포츠 점수, 날씨 업데이트 등의 정보를 제공받을 수 있습니다.\n그러나 모든 상황에서 웹 검색 기능을 사용할 수 있는 것은 아니며, 사용자의 요청과 상황에 따라 이 기능의 사용 여부가 결정됩니다. 웹 검색은 실시간으로 정보를 검색하고, 다양한 웹 페이지에서 정보를 수집하여 답변을 제공하는 과정을 포함합니다. 이러한 접근 방식은 최신의 정보를 제공하는 데 유용하며, 특히 변화하는 데이터나 최근의 사건에 대한 질문에 효과적입니다."
  },
  {
    "objectID": "blog/posts/2023/20231223.html#mygpt를-통한-개인화된-gpt-사용",
    "href": "blog/posts/2023/20231223.html#mygpt를-통한-개인화된-gpt-사용",
    "title": "ChatGPT3.5와 ChatGPT4의 차이점",
    "section": "",
    "text": "“MyGPT” 기능은 사용자의 대화를 개인화하여 맞춤형 경험을 제공하는 기능입니다. 이를 통해 사용자의 이전 대화 기록을 기억하고, 특정 주제에 대해 더 많은 정보를 제공하며, 사용자의 선호도와 설정에 맞춘 맞춤형 응답을 만들 수 있습니다. MyGPT는 시간이 지남에 따라 사용자의 관심사와 선호를 반영하여 더 풍부한 대화 경험을 제공하며, 사용자의 개인 정보 보호를 철저히 고려합니다.\n실제 사용예를 확인하면 차이점을 좀 더 쉽게 이해할 수 있습니다.\n\n언어 학습 보조\n\n사용자가 영어를 배우고 있다고 가정해봅시다. MyGPT는 사용자가 이전 대화에서 어려움을 겪었던 문법 포인트를 기억하고, 향후 대화에서 해당 문법을 중심으로 추가 연습 기회를 제공할 수 있습니다. 또한, 사용자가 관심을 보인 특정 주제에 대한 대화를 통해 언어 학습을 더욱 흥미롭고 효과적으로 만들 수 있습니다.\n\n건강 및 운동 일지\n\n사용자가 건강과 운동에 중점을 두고 있다고 가정해 봅시다. MyGPT는 사용자의 운동 목표, 진행 상황, 건강 관련 질문 등을 기억하여, 시간이 지남에 따라 맞춤형 운동 조언이나 건강 정보를 제공할 수 있습니다. 사용자의 진행 상황을 추적하며, 개선점이나 새로운 운동 방법에 대한 제안을 할 수도 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231212.html",
    "href": "blog/posts/2023/20231212.html",
    "title": "23년 허깅페이스 헤커톤 운영후기",
    "section": "",
    "text": "인공지능에 관심 있는 분이라면 ’트랜스포머’와 ’허깅페이스’라는 용어를 들어보셨을 겁니다. 허깅페이스는 AI와 머신러닝에 쉽게 접근하고 활용할 수 있는 플랫폼입니다. 저희 허깅페이스 KREW팀은 이 플랫폼을 공부하는 사람들의 모임이며, 문서 번역을 시작으로 다양한 스터디 활동을 진행해왔습니다.\n공식 문서를 번역하며 허깅페이스에 기여했고, 이를 계기로 ’2023 Everyday AI Hackathon’을 운영하게 되었습니다. 이 글에서는 대회 운영을 통해 느낀 점들을 나누고자 합니다.\n\n\n이번 행사를 처음으로 운영하며 많은 도전이 있었습니다. 특히 헤커톤의 주제를 결정하는 과정이 어려웠습니다. 저희는 허깅페이스 KREW 번역 과정에서 느낀 서로를 응원하고 함께 목표를 달성하는 경험을 참가자들과 공유하고자 했습니다.\n\n\n\n헤커톤 홈페이지\n\n\n홈페이지 제작도 쉽지 않았지만, 원형님 덕분에 한글과 영문을 모두 지원하는 사이트를 구축할 수 있었습니다. 소현님의 귀여운 허깅페이스 이모티콘은 홈페이지 왼쪽을 멋지게 장식했습니다. 헤커톤 당일 준비된 스티커도 매우 예뻤습니다.\n상대적 경쟁보다는 서로를 응원하는 경험을 제공하는 것이 중요하다고 생각했으며, 허깅페이스를 통해 더 많은 사람들이 AI를 일상에 적용할 수 있도록 돕고 싶었습니다.\n\n\n\n대회가 시작되면서 해외 참가자들의 관심도 높았습니다. 한국어와 영어로 진행된 프로젝트들은 다양했습니다. 한국 참가자들은 경제 기사 요약, 교육용 GPT 활용, 개인 이미지 생성 등의 데모를 제작했습니다.\n\n\n\n허깅페이스 디스코드 채널\n\n\n허깅페이스 Discord 채널에서는 영어와 한국어로 다양한 논의가 진행되었습니다. 해외 참가자들의 주제가 매우 흥미로워 즐겁게 들었습니다.\n\n\n\n2023년 허깅페이스 해커톤은 슈도랩과 함께 진행되었습니다. 오프라인 시작을 어떻게 할지 고민했지만, 우준님께서 허깅페이스에 대한 소개자료를 만들어 공유해주셨습니다.\n\n\n\n\n\n깃헙과 허깅페이스 이모티콘과 함께 실제 코드로 설명해 주셨지만, 제가 잘 몰라서 혹은 글로 쓰기 귀찮아서 그런 것은 아닙니다….\n\n\n\n\n\n\n\n\n실제로 동작하는 데모를 만들며 배우는 경험이 가장 큰 장점이었습니다. 점진적으로 성장하는 과정의 중요성을 깨달았고, AI와 머신러닝을 실용적으로 활용하는 데 많은 도움이 되었습니다.\n오프라인 발표에서 데모에 대한 관심이 높았으며, 발표자료를 원하는 요청이 많았습니다. 대회 후 발표자들의 허락을 받아 홈페이지에 자료를 업로드할 수 있었습니다.\n\n\n\n발표자 자료 리스트\n\n\n사람들 앞에서 발표하는 것은 준비가 필요하고 긴장되지만, 매우 보람찬 경험입니다. 다음에는 더 많은 참가자들이 이런 경험을 할 수 있도록 돕고 싶습니다.\n\n\n\n헤커톤 발표자들의 자료는 대회 홈페이지에서 확인할 수 있습니다. 발표자료를 만들고 공유해준 모든 발표자분들께 감사드립니다. 대회에는 상금이 없었지만, 데모를 만드는 뿌듯함과 허깅페이스 수료증을 위해 많은 참가자와 발표자들이 노력했습니다. 홈페이지에서 자세한 내용을 확인해보세요.\n여러분도 허깅페이스를 활용해 사용자 친화적인 AI 프로젝트를 만들어보세요. AI는 단지 기술적인 도구가 아니라, 실생활 속 문제 해결의 열쇠입니다. 이 흥미로운 여정에 여러분도 함께해보세요."
  },
  {
    "objectID": "blog/posts/2023/20231212.html#쉽지-않은-대회-운영",
    "href": "blog/posts/2023/20231212.html#쉽지-않은-대회-운영",
    "title": "23년 허깅페이스 헤커톤 운영후기",
    "section": "",
    "text": "이번 행사를 처음으로 운영하며 많은 도전이 있었습니다. 특히 헤커톤의 주제를 결정하는 과정이 어려웠습니다. 저희는 허깅페이스 KREW 번역 과정에서 느낀 서로를 응원하고 함께 목표를 달성하는 경험을 참가자들과 공유하고자 했습니다.\n\n\n\n헤커톤 홈페이지\n\n\n홈페이지 제작도 쉽지 않았지만, 원형님 덕분에 한글과 영문을 모두 지원하는 사이트를 구축할 수 있었습니다. 소현님의 귀여운 허깅페이스 이모티콘은 홈페이지 왼쪽을 멋지게 장식했습니다. 헤커톤 당일 준비된 스티커도 매우 예뻤습니다.\n상대적 경쟁보다는 서로를 응원하는 경험을 제공하는 것이 중요하다고 생각했으며, 허깅페이스를 통해 더 많은 사람들이 AI를 일상에 적용할 수 있도록 돕고 싶었습니다."
  },
  {
    "objectID": "blog/posts/2023/20231212.html#다양한-국가의-참가자들과-협업하기",
    "href": "blog/posts/2023/20231212.html#다양한-국가의-참가자들과-협업하기",
    "title": "23년 허깅페이스 헤커톤 운영후기",
    "section": "",
    "text": "대회가 시작되면서 해외 참가자들의 관심도 높았습니다. 한국어와 영어로 진행된 프로젝트들은 다양했습니다. 한국 참가자들은 경제 기사 요약, 교육용 GPT 활용, 개인 이미지 생성 등의 데모를 제작했습니다.\n\n\n\n허깅페이스 디스코드 채널\n\n\n허깅페이스 Discord 채널에서는 영어와 한국어로 다양한 논의가 진행되었습니다. 해외 참가자들의 주제가 매우 흥미로워 즐겁게 들었습니다."
  },
  {
    "objectID": "blog/posts/2023/20231212.html#오프라인-발표",
    "href": "blog/posts/2023/20231212.html#오프라인-발표",
    "title": "23년 허깅페이스 헤커톤 운영후기",
    "section": "",
    "text": "2023년 허깅페이스 해커톤은 슈도랩과 함께 진행되었습니다. 오프라인 시작을 어떻게 할지 고민했지만, 우준님께서 허깅페이스에 대한 소개자료를 만들어 공유해주셨습니다.\n\n\n\n\n\n깃헙과 허깅페이스 이모티콘과 함께 실제 코드로 설명해 주셨지만, 제가 잘 몰라서 혹은 글로 쓰기 귀찮아서 그런 것은 아닙니다…."
  },
  {
    "objectID": "blog/posts/2023/20231212.html#대회를-통해-얻은-것",
    "href": "blog/posts/2023/20231212.html#대회를-통해-얻은-것",
    "title": "23년 허깅페이스 헤커톤 운영후기",
    "section": "",
    "text": "실제로 동작하는 데모를 만들며 배우는 경험이 가장 큰 장점이었습니다. 점진적으로 성장하는 과정의 중요성을 깨달았고, AI와 머신러닝을 실용적으로 활용하는 데 많은 도움이 되었습니다.\n오프라인 발표에서 데모에 대한 관심이 높았으며, 발표자료를 원하는 요청이 많았습니다. 대회 후 발표자들의 허락을 받아 홈페이지에 자료를 업로드할 수 있었습니다.\n\n\n\n발표자 자료 리스트\n\n\n사람들 앞에서 발표하는 것은 준비가 필요하고 긴장되지만, 매우 보람찬 경험입니다. 다음에는 더 많은 참가자들이 이런 경험을 할 수 있도록 돕고 싶습니다."
  },
  {
    "objectID": "blog/posts/2023/20231212.html#헤커톤-데모가-궁금하신가요",
    "href": "blog/posts/2023/20231212.html#헤커톤-데모가-궁금하신가요",
    "title": "23년 허깅페이스 헤커톤 운영후기",
    "section": "",
    "text": "헤커톤 발표자들의 자료는 대회 홈페이지에서 확인할 수 있습니다. 발표자료를 만들고 공유해준 모든 발표자분들께 감사드립니다. 대회에는 상금이 없었지만, 데모를 만드는 뿌듯함과 허깅페이스 수료증을 위해 많은 참가자와 발표자들이 노력했습니다. 홈페이지에서 자세한 내용을 확인해보세요.\n여러분도 허깅페이스를 활용해 사용자 친화적인 AI 프로젝트를 만들어보세요. AI는 단지 기술적인 도구가 아니라, 실생활 속 문제 해결의 열쇠입니다. 이 흥미로운 여정에 여러분도 함께해보세요."
  },
  {
    "objectID": "blog/posts/2023/20231231-1.html",
    "href": "blog/posts/2023/20231231-1.html",
    "title": "우분투와 윈도우 파일 공유하기 (samba)",
    "section": "",
    "text": "우분투와 윈도우 운영체제 사이에 파일을 공유하는 방법을 정리합니다.\n\n\n다양한 운영체제 간의 호환성은 파일 공유의 업무 효율성을 올려줍니다. 우리가 흔히 사용하는 윈도우, 맥OS, 리눅스(예: 우분투) 등은 각기 다른 파일 시스템을 사용하기 때문에 파일 공유를 위해서는 특정 도구나 소프트웨어(예: SAMBA)가 필요합니다. 저의 경우 윈도우 노트북에서 리눅스 서버 사이의 파일 공유를 위해 Samba를 사용하고 있습니다.\n파일 공유를 이야기 하면 가장먼저 떠오르는 방식은 FTP(File Transper Protocol)입니다. FTP는 주로 대용량 파일 전송이나 웹사이트 파일 관리 등에 사용되고 FTP 클라이언트를 통해서 접속이 가능합니다. 윈도우와 우분투 운영체제 사이의 파일공유는 SAMBA가 편리합니다. 파일 및 프린트 공유가 가능하며 FTP와 달리 FTP클라이언트 설치없이 사용가능한 장점이 있습니다.\n\n\n\n우분투에 SAMBA를 설치하여 윈도우에서 우분투 공유 폴더를 접속할 수 있습니다. 설치를 위해서 우분투 시스템의 패키지를 최신 상태로 업데이트 합니다. (우분투에서 패키지는 소프트웨어나 어플리케이션을 설치하고 관리하기 위한 정보의 모음) 아래의 명령으로 패키지 업데이트와 samba설치를 진행합니다.\nsudo apt update && sudo apt upgrade\nsudo apt install samba\n설치가 완료되었는 지 확인을 위해 아래 명령으로 서비스 상태를 확인합니다.\nsudo systemctl status smbd\nActive: active (running) since Sun 2023-12-31 13:24:19 KST; 1h 53min ago\n서비스 동작 상태가 정상적으로 Active로 동작하도록 설치를 완료 했습니다.\n\n\n\nSAMBA를 통한 공유폴더 및 프린트를 네트워크에 공유하는 과정에 보안을 위해서 SAMBA이 설정정보를 업데이트 해야합니다. 우선 기존 SAMBA 설정파일을 백업하고 smb.conf설정 파일을 수정합니다.\nsudo cp /etc/samba/smb.conf /etc/samba/smb.conf.backup\nsudo vi /etc/samba/smb.conf\n설정파일인 smb.conf의 가장 하단에 공유를 위한 폴더위치 및 세부 정보를 아래와 같이 작성합니다. 공유폴더 이름은 MyShareFolder로 정했습니다. path에는 자신이 공유할 폴더위치를 사용하세요~\n[SharedFolder]\npath = /home/[자신의유저명]/MyShareFolder\nread only = no\nbrowsable = yes\nwritable = yes\npublic = no:writable\n변경된 설정정보를 적용하가 위해서 SAMBA 서비스를 재시작 합니다.\nsudo systemctl restart smbd\n이제 폴더에 접근가능한 유저정보를 정의합니다.\nsudo smbpasswd -a [사용할 사용자명]\n[사용할 사용자명]은 우분투 시스템의 사용자 명입니다. 이 명령어는 해당 사용자는 SAMBA 사용자로 추가합니다. 생성되면 암호를 물어봅니다. SAMBA접속 시 필요한 내용이니 잘 정리해두세요.\n\n\n\n윈도우에서는 우분투에 생성된 SAMBA 공유폴더에 접근할 수 있습니다. 접근할 공유폴더가 생성된 우분투의 ip정보를 확인합니다. 우분투에서 ip a명령을 사용하면 우분투 서버의 ip주소를 확인할 수 있습니다. 예시로 작성한 아래 코드에선 192.123.123.123이 우분투 서버 주소입니다.\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp4s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 74:11:11:11:11:f0 brd ff:ff:ff:ff:ff:ff\n    inet 192.123.123.123/24 brd 192.123.123.255 scope global dynamic noprefixroute enp4s0\n       valid_lft 78753sec preferred_lft 78753sec\n    inet6 fe80::e78b:acd3:ea2a:cafb/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n윈도우 탐색기에서 \\\\192.123.123.123 주소를 입력하면 삼바 공유폴더로 설정한 폴더가 보이고 선택 시 설정한 SAMBA 유저명과 암호로 접속 가능합니다."
  },
  {
    "objectID": "blog/posts/2023/20231231-1.html#왜-samba를-사용해야-하나요",
    "href": "blog/posts/2023/20231231-1.html#왜-samba를-사용해야-하나요",
    "title": "우분투와 윈도우 파일 공유하기 (samba)",
    "section": "",
    "text": "다양한 운영체제 간의 호환성은 파일 공유의 업무 효율성을 올려줍니다. 우리가 흔히 사용하는 윈도우, 맥OS, 리눅스(예: 우분투) 등은 각기 다른 파일 시스템을 사용하기 때문에 파일 공유를 위해서는 특정 도구나 소프트웨어(예: SAMBA)가 필요합니다. 저의 경우 윈도우 노트북에서 리눅스 서버 사이의 파일 공유를 위해 Samba를 사용하고 있습니다.\n파일 공유를 이야기 하면 가장먼저 떠오르는 방식은 FTP(File Transper Protocol)입니다. FTP는 주로 대용량 파일 전송이나 웹사이트 파일 관리 등에 사용되고 FTP 클라이언트를 통해서 접속이 가능합니다. 윈도우와 우분투 운영체제 사이의 파일공유는 SAMBA가 편리합니다. 파일 및 프린트 공유가 가능하며 FTP와 달리 FTP클라이언트 설치없이 사용가능한 장점이 있습니다."
  },
  {
    "objectID": "blog/posts/2023/20231231-1.html#우분투에-samba-설치하기",
    "href": "blog/posts/2023/20231231-1.html#우분투에-samba-설치하기",
    "title": "우분투와 윈도우 파일 공유하기 (samba)",
    "section": "",
    "text": "우분투에 SAMBA를 설치하여 윈도우에서 우분투 공유 폴더를 접속할 수 있습니다. 설치를 위해서 우분투 시스템의 패키지를 최신 상태로 업데이트 합니다. (우분투에서 패키지는 소프트웨어나 어플리케이션을 설치하고 관리하기 위한 정보의 모음) 아래의 명령으로 패키지 업데이트와 samba설치를 진행합니다.\nsudo apt update && sudo apt upgrade\nsudo apt install samba\n설치가 완료되었는 지 확인을 위해 아래 명령으로 서비스 상태를 확인합니다.\nsudo systemctl status smbd\nActive: active (running) since Sun 2023-12-31 13:24:19 KST; 1h 53min ago\n서비스 동작 상태가 정상적으로 Active로 동작하도록 설치를 완료 했습니다."
  },
  {
    "objectID": "blog/posts/2023/20231231-1.html#samba-설정하기",
    "href": "blog/posts/2023/20231231-1.html#samba-설정하기",
    "title": "우분투와 윈도우 파일 공유하기 (samba)",
    "section": "",
    "text": "SAMBA를 통한 공유폴더 및 프린트를 네트워크에 공유하는 과정에 보안을 위해서 SAMBA이 설정정보를 업데이트 해야합니다. 우선 기존 SAMBA 설정파일을 백업하고 smb.conf설정 파일을 수정합니다.\nsudo cp /etc/samba/smb.conf /etc/samba/smb.conf.backup\nsudo vi /etc/samba/smb.conf\n설정파일인 smb.conf의 가장 하단에 공유를 위한 폴더위치 및 세부 정보를 아래와 같이 작성합니다. 공유폴더 이름은 MyShareFolder로 정했습니다. path에는 자신이 공유할 폴더위치를 사용하세요~\n[SharedFolder]\npath = /home/[자신의유저명]/MyShareFolder\nread only = no\nbrowsable = yes\nwritable = yes\npublic = no:writable\n변경된 설정정보를 적용하가 위해서 SAMBA 서비스를 재시작 합니다.\nsudo systemctl restart smbd\n이제 폴더에 접근가능한 유저정보를 정의합니다.\nsudo smbpasswd -a [사용할 사용자명]\n[사용할 사용자명]은 우분투 시스템의 사용자 명입니다. 이 명령어는 해당 사용자는 SAMBA 사용자로 추가합니다. 생성되면 암호를 물어봅니다. SAMBA접속 시 필요한 내용이니 잘 정리해두세요."
  },
  {
    "objectID": "blog/posts/2023/20231231-1.html#윈도우에서-우분투-공유폴더-접근하기",
    "href": "blog/posts/2023/20231231-1.html#윈도우에서-우분투-공유폴더-접근하기",
    "title": "우분투와 윈도우 파일 공유하기 (samba)",
    "section": "",
    "text": "윈도우에서는 우분투에 생성된 SAMBA 공유폴더에 접근할 수 있습니다. 접근할 공유폴더가 생성된 우분투의 ip정보를 확인합니다. 우분투에서 ip a명령을 사용하면 우분투 서버의 ip주소를 확인할 수 있습니다. 예시로 작성한 아래 코드에선 192.123.123.123이 우분투 서버 주소입니다.\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp4s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 74:11:11:11:11:f0 brd ff:ff:ff:ff:ff:ff\n    inet 192.123.123.123/24 brd 192.123.123.255 scope global dynamic noprefixroute enp4s0\n       valid_lft 78753sec preferred_lft 78753sec\n    inet6 fe80::e78b:acd3:ea2a:cafb/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n윈도우 탐색기에서 \\\\192.123.123.123 주소를 입력하면 삼바 공유폴더로 설정한 폴더가 보이고 선택 시 설정한 SAMBA 유저명과 암호로 접속 가능합니다."
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "Blog",
    "section": "",
    "text": "Robots.txt 작성방법\n\n\nRobots.txt 작성방법\n\n\n\n\nWeb\n\n\n\n\nRobots.txt 작성방법\n\n\n\n\n\n\nNov 6, 2025\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nGitHub Actions 시작하기\n\n\nGitHub Actions 시작하기\n\n\n\n\nWeb\n\n\n\n\nGitHub Actions 시작하기\n\n\n\n\n\n\nJul 24, 2024\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nSQL 정렬 명령 order by\n\n\nSQL 정렬 명령 order by\n\n\n\n\nDatabase\n\n\n\n\nSQL 정렬 명령 order by\n\n\n\n\n\n\nJan 5, 2024\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nJavascript의 defer 속성은 왜 사용하는가?\n\n\nJavascript의 defer 속성은 왜 사용하는가?\n\n\n\n\nWeb\n\n\n\n\nJavascript의 defer 속성은 왜 사용하는가?\n\n\n\n\n\n\nJan 3, 2024\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\n코루틴(coroutine)과 이벤트 루프\n\n\n코루틴(coroutine)과 이벤트 루프\n\n\n\n\nPython\n\n\n\n\n코루틴(coroutine)과 이벤트 루프\n\n\n\n\n\n\nJan 1, 2024\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\n우분투와 윈도우 파일 공유하기 (samba)\n\n\n우분투와 윈도우 파일 공유하기 (samba)\n\n\n\n\nDevOps\n\n\n\n\n우분투와 윈도우 파일 공유하기 (samba)\n\n\n\n\n\n\nDec 31, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nChatGPT3.5와 ChatGPT4의 차이점\n\n\nChatGPT3.5와 ChatGPT4의 차이점\n\n\n\n\nAI\n\n\n\n\nChatGPT3.5와 ChatGPT4의 차이점\n\n\n\n\n\n\nDec 23, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nGoogle Gemeni API Key 얻기\n\n\nGoogle Gemeni API Key 얻기\n\n\n\n\nAI\n\n\n\n\nGoogle Gemeni API Key 얻기\n\n\n\n\n\n\nDec 22, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nRAG(Retrieval Argumented Generation) 정리하기\n\n\nRAG(Retrieval Argumented Generation) 정리하기\n\n\n\n\nAI\n\n\n\n\nRAG(Retrieval Argumented Generation) 정리하기\n\n\n\n\n\n\nDec 14, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\n23년 허깅페이스 헤커톤 운영후기\n\n\n23년 허깅페이스 헤커톤 운영후기\n\n\n\n\nHuggingFace\n\n\n\n\n23년 허깅페이스 헤커톤 운영후기\n\n\n\n\n\n\nDec 12, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nMySQL 도커로 설치하고 테스트 DB 사용하기\n\n\nMySQL 도커로 설치하고 테스트 DB 사용하기\n\n\n\n\nDatabase\n\n\n\n\nMySQL 도커로 설치하고 테스트 DB 사용하기\n\n\n\n\n\n\nDec 6, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\ncrontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신\n\n\ncrontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신\n\n\n\n\nDevOps\n\n\n\n\ncrontab을 이용해서 Let’s Encrypt SSL 인증서 자동갱신\n\n\n\n\n\n\nDec 5, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nvite를 이용한 react 개발환경 세팅\n\n\nvite를 이용한 react 개발환경 세팅\n\n\n\n\nWeb\n\n\n\n\nvite를 이용한 react 개발환경 세팅\n\n\n\n\n\n\nDec 3, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nDataframe을 Dict로 생성 및 변환\n\n\nDataframe을 Dict로 생성 및 변환\n\n\n\n\nPandas\n\n\n\n\nDataframe을 Dict로 생성 및 변환\n\n\n\n\n\n\nNov 30, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\npython datetime 사용법 정리\n\n\npython datetime 사용법 정리\n\n\n\n\nPandas\n\n\n\n\npython datetime 사용법 정리\n\n\n\n\n\n\nNov 29, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nmongoDB 서비스 시작/종료/상태확인\n\n\nmongoDB 서비스 시작/종료/상태확인\n\n\n\n\nDatabase\n\n\n\n\nmongoDB 서비스 시작/종료/상태확인\n\n\n\n\n\n\nNov 28, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\n우분투 docker, docker-compse 설치\n\n\n우분투 docker, docker-compse 설치\n\n\n\n\nDevOps\n\n\n\n\n우분투 docker, docker-compse 설치\n\n\n\n\n\n\nNov 27, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nAWS 호스팅 EC2 와 Lightsail의 차이\n\n\nAWS 호스팅 EC2 와 Lightsail의 차이\n\n\n\n\nDevOps\n\n\n\n\nAWS 호스팅 EC2 와 Lightsail의 차이\n\n\n\n\n\n\nNov 26, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nwsl 이미지 저장 위치 변경 및 백업\n\n\nwsl 이미지 저장 위치 변경 및 백업\n\n\n\n\nDevOps\n\n\n\n\nwsl 이미지 저장 위치 변경 및 백업\n\n\n\n\n\n\nNov 20, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nairflow postgresoperator 사용하기\n\n\nairflow postgresoperator 사용하기\n\n\n\n\nDevOps\n\n\n\n\nairflow postgresoperator 사용하기\n\n\n\n\n\n\nNov 20, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\ndocker-compose로 airflow 설치하기\n\n\ndocker-compose로 airflow 설치하기\n\n\n\n\nDevOps\n\n\n\n\ndocker-compose로 airflow 설치하기\n\n\n\n\n\n\nNov 18, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nMongoDB 설치 및 명령어 정리하기\n\n\nMongoDB 설치 및 명령어 정리하기\n\n\n\n\nDatabase\n\n\n\n\nMongoDB 설치 및 명령어 정리하기\n\n\n\n\n\n\nNov 15, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nwsl2에 docker 설치하기\n\n\nwsl2에 docker 설치하기\n\n\n\n\nDevOps\n\n\n\n\nwsl2에 docker 설치하기\n\n\n\n\n\n\nNov 15, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nmkfifo를 이용한 IPC\n\n\nmkfifo를 이용한 IPC\n\n\n\n\nDevOps\n\n\n\n\nmkfifo를 이용한 IPC\n\n\n\n\n\n\nNov 15, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPymongo 명령어 정리하기\n\n\nPymongo 명령어 정리하기\n\n\n\n\nDatabase\n\n\n\n\nPymongo 명령어 정리하기\n\n\n\n\n\n\nNov 14, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nGithub Pull Request 템플릿 적용하기\n\n\nGithub Pull Request 템플릿 적용하기\n\n\n\n\nDevOps\n\n\n\n\nGithub Pull Request 템플릿을 적용하는 방법을 정리합니다.\n\n\n\n\n\n\nOct 9, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly line, shape 그리기\n\n\nPlotly line, shape 그리기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly line, shape를 그리는 방법에 대해서 정리합니다.\n\n\n\n\n\n\nOct 8, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Funnel(깔대기) 차트 만들기\n\n\nPlotly Funnel(깔대기) 차트 만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Funnel(깔대기) 차트를 만드는 방법에 대해서 정리합니다.\n\n\n\n\n\n\nOct 5, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly 차트의 축 tick 회전 및 폰트 변경하기\n\n\nPlotly x축 tick 회전 및 폰트 변경하기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly의 x축 tick을 변경하는 방법에 대해서 정리합니다.\n\n\n\n\n\n\nOct 4, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly 불릿차트\n\n\nPlotly 불릿차트\n\n\n\n\nData Visualization\n\n\n\n\nPlotly 불릿차트에 대해서 정리합니다.\n\n\n\n\n\n\nOct 3, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Hover 설정하기\n\n\nPlotly Hover 설정하기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Hover 레이블을 설정하는 방법을 정리합니다.\n\n\n\n\n\n\nOct 2, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Axis 포멧 변경하기\n\n\nPlotly Axis 포멧 변경하기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Axis 포멧 변경하기\n\n\n\n\n\n\nSep 30, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly 마커 모양 변경하기\n\n\nPlotly 마커 모양 변경하기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly 마커 모양을 변경하는 방법을 정리합니다.\n\n\n\n\n\n\nSep 28, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Time Series 날짜 범위 UI 사용하기\n\n\nPlotly Time Series 날짜 범위 UI 사용하기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Time Series 날짜 범위를 지정하는 방법을 정리합니다.\n\n\n\n\n\n\nSep 25, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Line Plot만들기\n\n\nPlotly Line Plot만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Line Plot의 사용방법을 정리합니다.\n\n\n\n\n\n\nSep 22, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Histogram Plot만들기\n\n\nPlotly Histogram Plot만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Histogram Plot의 사용방법을 정리합니다.\n\n\n\n\n\n\nSep 21, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Animation 만들기\n\n\nPlotly Animation 만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Animation의 사용방법을 정리합니다.\n\n\n\n\n\n\nSep 18, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Box Plot만들기\n\n\nPlotly Box Plot만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Bar Plot의 사용방법을 정리합니다.\n\n\n\n\n\n\nSep 18, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Treemap 만들기\n\n\nPlotly Treemap 만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Treemap의 사용방법과 생상변경 방법을 정리합니다.\n\n\n\n\n\n\nSep 17, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Bubble chart 만들기\n\n\nPlotly Bubble chart 만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Bubble chart의 사용방법을 정리합니다.\n\n\n\n\n\n\nSep 17, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPandas 중복 데이터 제거하기\n\n\nPandas 중복 데이터 제거하기\n\n\n\n\nPandas\n\n\n\n\nPandas 중복 데이터 제거하기\n\n\n\n\n\n\nSep 14, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nPlotly Subpolt 만들기\n\n\nPlotly Subpolt 만들기\n\n\n\n\nData Visualization\n\n\n\n\nPlotly Subplt 만들기\n\n\n\n\n\n\nSep 13, 2023\n\n\n양성모\n\n\n\n\n\n\n  \n\n\n\n\nMarkdown문법 정리하기\n\n\nMarkdown문법 정리하기\n\n\n\n\nQuarto\n\n\n\n\nMarkdown문법을 정리합니다.\n\n\n\n\n\n\nSep 12, 2023\n\n\ngabriel yang\n\n\n\n\n\n\n  \n\n\n\n\nQuarto Callout Block\n\n\nCallout Block으로 내용 강조하기\n\n\n\n\nQuarto\n\n\n\n\nQuarto Callout으로 내용 강조하는 방법을 정리합니다.\n\n\n\n\n\n\nSep 10, 2023\n\n\ngabriel yang\n\n\n\n\n\n\nNo matching items"
  }
]